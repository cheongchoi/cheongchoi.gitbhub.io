---
title: "meta"
author: "Cheon Geun Choi"
date: "2023-01-11"
mainfont: NanumGothic
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document:
    latex_engine: xelatex
editor_options:
  chunk_output_type: inline
---


# 1. 메타분석

## 1.1. 참고자료

* 참고사이트: https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/



## 1.2. R과 메타분석 관련 패키지

메타분석을 위한 R 패키지는 meta 와 metafor 가 대표적이다. 두 패키지는 매우 유사하며 거의 비슷한 형식과 기능을 가지고 있다. 패키지는 meta는 교과서 Schwarzer, Carpenter, and Rücker (2015) 의 부록으로 나온 것이다. 패키지는 metafor 는 홈페이지 에 다양한 예제가 소개되어 있어 유용하다.

여기서는 패키지는 metafor의 홈페이지에 나와있는 2개의 예제를 간단하게 소개하고 R을 이용한 기초적인 메타분석의 방법을 소개하고자 한다.

## 1.3. Introduction

![Fig1](balloon.jpg)
메타 분석을 적용하면 동일한 질문을 다루는 다양한 과학적 연구를 분석할 수 있습니다. 모든 개별 연구에는 어느 정도의 오류가 포함되어 있다고 가정합니다. 예를 들어, 연구는 특정 질병에 대한 두 가지 치료법의 사망률이 될 수 있습니다. 목표는 개별 연구 간의 이질성을 고려하여 개별 연구로부터 통합된 요약 추정치를 얻는 것입니다. 개별 연구에서 집계된 데이터는 더 높은 통계적 힘으로 이어집니다.

## 1.4. 절차

* (1) 연구문제 정의

* (2) 선별된 개별 연구에 대한 포함/제외 기준을 정의합니다.

* (3) 문헌 검색

* (4) 적격 연구 선택

* (5) 데이터 수집

* (6) 연구 전반에 걸쳐 결과를 종합하고 효과 크기에 대한 합동 추정치를 얻습니다.

* (7) 포함된 연구의 이질성 평가

* (8) 민감도 및 하위군 분석 수행


# 2. 효과 크기

![Fig2](effect_sizes.jpg)



## 2.1. (표준화) 평균 차이

### 그룹 간 평균 차이
그룹 간 평균 차이 $MD_{between}$는 두 독립 그룹 간 평균의 표준화되지 않은 원시 차이로 정의됩니다. 그룹 간 평균 차이는 일반적으로 대조 시험이나 다른 유형의 실험 연구의 경우처럼 연구에 두 개 이상의 그룹이 포함된 경우 계산할 수 있습니다. 메타 분석에서 평균 차이는 모든 연구가 정확히 동일한 규모로 관심 결과를 측정한 경우에만 사용할 수 있습니다. 예를 들어, 무게는 과학 연구에서 거의 항상 킬로그램 단위로 측정됩니다. 당뇨병학에서는 $HbA_{1c}$ 값이 일반적으로 혈당을 측정하는 데 사용됩니다.

평균 차이는 그룹 1의 평균 $\overline x_1$에서 그룹 2의 평균 $\overline x_2$을 뺀 값으로 정의됩니다.

$$ \begin{equation}
\text{MD}_{\text{between}} = \bar{x}_1 - \bar{x}_2
\tag{3.14}
\end{equation} $$


표준 오차는 다음 공식을 사용하여 얻을 수 있습니다.

$$\begin{equation}
SE_{\text{MD}_{\text{between}}} = s_{\text{pooled}}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\tag{3.15}
\end{equation}$$


공식에서 $n_1$은 그룹 1의 표본 크기를 나타내고, $n_2$는 그룹 2의 표본 크기이고 $s_pooled$는 두 그룹의 합동 표준 편차입니다. 그룹 1($\overline s_1$)과 그룹 2($\overline s_2$)의 표준 편차를 사용하여 $s_{pooled}$ 값을 다음과 같이 계산할 수 있습니다.
 
$$\begin{align}
s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}
\tag{3.16}
\end{align}$$

다음은 R에서 평균 차이와 표준 오차를 계산하는 방법의 예입니다.

```{r}
# Generate two random variables with different population means
set.seed(123)
x1 <- rnorm(n = 20, mean = 10, sd = 3)
x2 <- rnorm(n = 20, mean = 15, sd = 3)

# Calculate values we need for the formulas
s1 <- sd(x1)
s2 <- sd(x2)
n1 <- 20
n2 <- 20

# Calculate the mean difference
MD <- mean(x1) - mean(x2)
MD
```

```{r}
# Calculate s_pooled
s_pooled <- sqrt(
  (((n1-1)*s1^2) + ((n2-1)*s2^2))/
    ((n1-1)+(n2-1))
)

# Calculate the standard error
se <- s_pooled*sqrt((1/n1)+(1/n2))
se
```

일반적으로 이러한 계산을 수동으로 수행할 필요는 없습니다. 평균 차이에 대한 메타 분석을 위해서는 데이터 세트에서 다음 열만 준비하면 됩니다.

* n.e. 개입/실험 그룹의 관찰 수입니다.

* mean.e. 개입/실험 그룹의 평균입니다.

* sd.e. 개입/실험 그룹의 표준 편차입니다.

* n.c. 통제그룹의 관측치 수입니다.

* mean.c. 통제그룹의 평균입니다.

* SD.C. 통제그룹의 표준편차입니다.


### 그룹 간 표준화 평균 차이

표준화된 그룹 간 평균 차이 $SMD_{between}$는 통합 표준 편차 $s_{pooled}$로 표준화된 두 독립 그룹 간의 평균 차이로 정의됩니다. 문헌에서는 표준화된 평균 차이를 심리학자이자 통계학자인 Jacob Cohen의 이름을 따서 Cohen의 $d$라고도 합니다.

표준화되지 않은 평균 차이와 달리 $SMD_{between}$
 두 그룹 간의 차이를 표준편차 단위로 표현합니다. 이는 두 그룹의 합동 표준 편차 $s_{pooled}$를 통해 두 그룹 $\overline x_1$ 및 $\overline x_2$의 원시 평균 차이를 나누어서 얻을 수 있습니다.

$$\begin{equation}
\text{SMD}_{\text{between}} = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}
\tag{3.17}
\end{equation}$$

$s_{pooled}$는 3.3.1.1장에서 이미 다룬 것과 동일한 공식(3.16)을 사용하여 계산됩니다. 표준화된 평균 차이는 표준화되지 않은 평균 차이보다 메타 분석에서 훨씬 더 자주 사용됩니다. 동일한 도구를 사용하여 관심 결과를 측정하지 않은 연구라도 $SMD_{between}$을 연구 간 비교할 수 있기 때문입니다.

표준화는 $SMD_{between}= 1$이 항상 두 그룹의 평균이 서로 하나의 표본 표준 편차만큼 떨어져 있음을 의미한다는 효과를 갖습니다(그림 3.3 참조). $SMD_{between}=2$는 2 표준 편차의 차이를 나타냅니다.

 
![Fig33](fig1.png)


그림 3.3: 표준화된 평균 차이 1(정규성, 동일한 표준 편차 및 두 그룹의 표본 크기가 동일하다고 가정)

표준화를 통해 평균 차이의 크기를 평가하는 것이 훨씬 쉬워졌습니다. 표준화된 평균 차이는 종종 Cohen(1988)의 관례를 사용하여 해석됩니다.


* $SMD \approx 0.20$: small effect.

* $SMD \approx 0.50$: moderate effect.

* $SMD \approx 0.80$: large effect.


Pearson 곱적률 상관관계(3.2.3.1장)에 대한 관례와 마찬가지로 이는 기껏해야 경험에 의한 규칙입니다.

일반적으로 "실제" 영향을 기반으로 표준화된 평균 차이를 해석하는 것이 훨씬 더 좋습니다. Cohen의 기준에 따르면 효과 크기는 작을 수 있지만 여전히 매우 중요할 수 있습니다. 예를 들어, 많은 심각한 질병의 경우 아주 작은 통계 효과라도 인구 수준에 큰 영향을 미칠 수 있으며 잠재적으로 수백만 명의 생명을 구할 수 있습니다. 한 연구에서는 우울증 치료의 경우 $SMD_{between}= 0.24$만큼 작은 효과라도 환자의 삶에 임상적으로 중요한 영향을 미칠 수 있음을 보여주었습니다(Pim Cuijpers et al. 2014).

$SMD_{between}의 표준 오차는 다음 공식을 사용하여 계산할 수 있습니다(Borenstein et al. 2011).
 
$$\begin{equation}
SE_{\text{SMD}_{\text{between}}} = \sqrt{\frac{n_1+n_2}{n_1n_2} + \frac{\text{SMD}^2_{\text{between}}}{2(n_1+n_2)}}
\tag{3.18}
\end{equation}$$


여기서 $n_1$ 및 $n_2$는 그룹 1과 그룹 2의 표본 크기이고 $SMD_{between}$은 계산된 그룹 간 표준화 평균 차이입니다.

R에는 $SMD_{between}/Cohen의 $d$를 한 단계로 계산할 수 있는 여러 함수가 있습니다. 여기서는 {esc} 패키지(Lüdecke 2019)의 일부인 esc_mean_sd 함수를 사용합니다. 이전에 이 패키지를 사용한 적이 없으므로 먼저 설치해야 합니다.
 
 
```{r}
# Load esc package
library(esc)

# Define the data we need to calculate SMD/d
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

# Calculate effect size
esc_mean_sd(grp1m = grp1m, grp2m = grp2m, 
            grp1sd = grp1sd, grp2sd = grp2sd, 
            grp1n = grp1n, grp2n = grp2n)
```
출력에는 두 가지 언급할 내용이 있습니다.

* 먼저, 계산된 표준화 평균 차이가 정확히 1이라는 것을 알 수 있습니다. 이는 우리가 정의한 두 평균 간의 차이가 (합동) 표준 편차와 동일하기 때문에 의미가 있습니다.

* 둘째, 효과크기가 음수임을 알 수 있다. 이는 그룹 2의 평균이 그룹 1의 평균보다 크기 때문입니다. 이는 수학적으로는 정확하지만 다른 사람들이 더 쉽게 해석할 수 있도록 계산된 효과 크기의 부호를 변경해야 하는 경우가 있습니다.

이 예의 데이터는 중재를 받은 후(그룹 1) 또는 중재를 받지 않은 후(그룹 2) 사람들이 주당 피우는 평균 담배 수를 측정하는 연구에서 나온 것입니다. 이러한 맥락에서, 개입 그룹에서 평균 흡연 횟수가 더 낮았기 때문에 연구 결과는 긍정적이었습니다. 따라서 효과크기를 -1.0이 아닌 1.0으로 보고하여 다른 사람들이 개입이 긍정적인 효과를 가져왔다는 것을 직관적으로 이해할 수 있도록 하는 것이 합리적입니다.

효과 크기의 부호는 일부 연구에서는 값이 높을수록 더 나은 결과를 의미하는 측정값을 사용하고 다른 연구에서는 값이 낮을수록 더 나은 결과를 나타내는 측정값을 사용할 때 특히 중요합니다. 이 경우 모든 효과 크기가 동일한 방향으로 일관되게 코딩되는 것이 중요합니다(예를 들어 메타 분석의 모든 연구에서 효과 크기가 높을수록 중재 그룹에서 더 나은 결과를 의미하는지 확인해야 합니다).

종종 표준화된 평균 차이에 소표본 수정이 적용되어 Hedges의 $g$라는 효과 크기가 생성됩니다. 이 수정 사항은 3.4.1장에서 다루겠습니다.

표준화된 평균 차이에 대한 메타 분석을 수행하려면 데이터 세트에 최소한 다음 열이 포함되어야 합니다.


* n.e. 개입/실험 그룹의 관찰 수입니다.

* mean.e. 개입/실험 그룹의 평균입니다.

* sd.e. 개입/실험 그룹의 표준 편차입니다.

* n.c. 통제그룹의 관측치 수입니다.

* mean.c. 통제그룹의 평균입니다.
* SD.C. 통제그룹의 표준편차입니다.

### 그룹 내(표준화) 평균 차이
그룹 내 비표준화 또는 표준화 평균 차이는 한 그룹 내의 차이를 조사할 때 계산할 수 있습니다. 이는 일반적으로 동일한 그룹의 사람들이 두 가지 다른 시점(예: 개입 전과 개입 후)에서 측정되는 경우입니다.

그룹 간 평균 차이와 달리 $(S)MD_{within}$은 독립적이지 않은 데이터를 사용하여 계산됩니다. 예를 들어, 측정 지점에서 사람 $i$의 가치는
$t_1$은 $t_2$ 측정 지점에서 동일인의 가치에 영향을 미쳤습니다. 그룹 내 평균 차이는 일반적으로 서로 다른 시점에서 측정된 데이터를 기반으로 하기 때문에 (표준화된) 평균 이득이라고도 합니다.

그룹 내 평균 차이 $MD_{within}$는 $MD_{between}$(3.3.1.1장 참조)과 동일한 방식으로 계산됩니다. 단, 이제 두 개의 다른 시점에서 동일한 그룹의 값을 비교합니다. t_1$ 및 $t_2$.

$$\begin{equation}
\text{MD}_{\text{within}} = \bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}
\tag{3.19}
\end{equation}$$
그룹 내 평균 차이의 표준화된 버전을 계산하려고 하면 상황이 더 복잡해집니다. $SMD_{within}$를 계산하는 방법에 대한 완전한 합의가 없습니다. 블로그 게시물에서 Jake Westfall은 이를 계산하는 데 최소한 5가지의 서로 다른 방법이 있음을 지적합니다.

직관적인 옵션은 두 평가 포인트 $s_{t1}$ 및 $s_{t2}$의 합동 표준 편차를 사용하여 평균 차이 $MD_{within}$를 표준화하는 것입니다. 관측치 수는 일반적으로 그룹 내 설계에서 동일하므로 $s^2_{pooled}$를 얻으려면 두 개의 제곱 표준 편차의 합을 2로 나누어야 함을 의미합니다. 그렇지 않으면 공식(3.16)을 사용하여 $s_{pooled}$를 계산할 수 있습니다. 이는 다음 공식으로 이어집니다.

$$\begin{equation}
\text{SMD}_{\text{within}} = \frac{\bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}}{s_{\text{pooled}}}
\tag{3.20}
\end{equation}$$


 

Becker(1988)가 제안한 훨씬 더 나은 해결책은 $MD_{within}$을 사전 테스트 점수($s_{t1}$)의 표준 편차로 나누는 것입니다. 그 이유는 $s_{t1}$가 개입 효과의 영향을 받을 가능성이 적기 때문입니다.

$$\begin{equation}
\text{SMD}_{\text{within}} = \frac{\bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}}{s_{\text{t}_1}}
\tag{3.21}
\end{equation}$$



 

$MD_{within}$ 및 $SMD_{within}$의 표준 오차는 다음 공식을 사용하여 계산할 수 있습니다(Borenstein et al. 2011, chap. 4; Becker 1988).


$$\begin{equation}
SE_{\text{MD}_{\text{within}}}=\sqrt{\dfrac{s^2_{\text{t}_1}+s^2_{\text{t}_2}-(2r_{\text{t}_1\text{t}_2}s_{\text{t}_1}s_{\text{t}_2})}{n}}
\tag{3.22}
\end{equation}$$


$$\begin{equation}
SE_{\text{SMD}_{\text{within}}} = \sqrt{\frac{2(1-r_{\text{t}_1\text{t}_2})}{n}+\frac{\text{SMD}^2_{\text{within}}}{2n}}
\tag{3.23}
\end{equation} $$

그룹 내(표준화된) 평균 차이의 표준 오차를 계산하기 위해 평가 지점 간의 상관 관계 $r_{t1t2}$를 알아야 한다는 사실은 실제로 문제가 되는 경우가 많습니다. 변수의 사전 사후 상관관계는 출판된 연구에서 거의 보고되지 않으며, 이는 이전 연구를 기반으로 $r_{t1t2}$ 값을 가정하도록 강요합니다.

그러나 상관관계를 정확하게 얻지 못하면 결과에 오류가 발생할 수 있습니다. 일반적으로 메타 분석을 위해 그룹 내 효과 크기를 계산하는 것은 피하는 것이 가장 좋습니다(Pim Cuijpers et al. 2017). 특히 실험군과 대조군 모두의 데이터가 있는 경우 치료 효과를 측정하기 위해 사전 사후 비교보다 $t_2$에서 그룹 간(표준화) 평균 차이를 계산하는 것이 훨씬 좋습니다. 그러나 메타 분석이 대조군을 포함하지 않은 연구에만 초점을 맞추는 경우 그룹 내 평균 차이가 계산될 수 있습니다.

그룹 내 표준화 평균 차이(그룹 내 Cohen의 $d$라고도 함)는 R에서 다음과 같이 계산할 수 있습니다.


```{r}
# Define data needed for effect size calculation
x1 <- 20    # mean at t1
x2 <- 30    # mean at t2
sd1 <- 13   # sd at t1
n <- 80     # sample size
r <- 0.5    # correlation between t1 and t2

# Caclulate the raw mean difference
md_within <- x2 - x1

# Calculate the smd:
# Here, we use the standard deviation at t1
# to standardize the mean difference
smd_within <- md_within/sd1
smd_within
```

```{r}
# Calculate standard error
se_within <- sqrt(((2*(1-r))/n) + 
              (smd_within^2/(2*n)))
se_within
```

그룹 내(표준화된) 평균 차이에 대한 메타 분석은 미리 계산된 효과 크기를 사용하여 R에서만 수행할 수 있습니다. 데이터 세트에는 다음 열이 필요합니다.

* TE: 계산된 그룹 내 효과 크기입니다.

* seTE: 그룹내 효과크기의 표준오차.


## 2.2. 위험 및 승산비

### 위험 비율


이름에서 알 수 있듯이 위험 비율(상대 위험이라고도 함)은 두 가지 위험의 비율입니다. 위험은 본질적으로 비율입니다(3.2.2장 참조). 이는 이분법적 또는 이분법적 결과 데이터를 다룰 때 계산될 수 있습니다.

우리는 "비율" 대신 "위험"이라는 용어를 사용합니다. 이러한 유형의 결과 데이터는 질병 발병이나 사망 위험을 조사하는 의학 연구에서 자주 발견되기 때문입니다. 이러한 발생을 이벤트라고 합니다. 우리가 치료 그룹과 대조군으로 구성된 통제된 임상 시험을 수행하고 있다고 상상해 보십시오. 우리는 연구 기간 동안 몇 명의 환자가 $E$ 사건을 경험했는지에 관심이 있습니다.

그러한 연구에서 얻은 결과는 2×2 테이블로 분류될 수 있습니다(Schwarzer, Carpenter, and Rücker 2015, chap. 3.1).

 
![Fig3](fig2.png)

이 데이터를 바탕으로 치료군과 대조군 모두 연구 기간 동안 사건 $E$를 경험할 위험을 계산할 수 있습니다. 우리는 단순히 한 그룹에서 $E$를 경험하는 사람들의 수를 해당 그룹의 전체 표본 크기로 나눕니다.

따라서 치료 그룹의 위험 $pE_{treat}$은 다음과 같이 계산됩니다.


$$\begin{equation}
{p_{E}}_{\text{treat}} = \frac{a}{a+b} = \frac{a}{n_{\text{treat}}}
\tag{3.24}
\end{equation}$$

통제 그룹 $pE_{control}$의 위험은 다음과 같습니다.

$$\begin{equation}
{p_{E}}_{\text{control}} = \frac{c}{c+d} = \frac{c}{n_{\text{control}}}
\tag{3.25}
\end{equation}$$

그런 다음 위험 비율은 치료/중재 그룹의 위험을 대조군의 위험으로 나눈 값으로 정의됩니다.

$$\begin{equation}
\text{RR} = \frac{{p_{E}}_{\text{treat}}}{{p_{E}}_{\text{control}}}
\tag{3.26}
\end{equation}$$

$pE_{treat}$ 및 $pE_{control}$ 모두 0과 1 사이의 값만 가질 수 있으므로 RR에는 몇 가지 흥미로운 속성이 있습니다. 우선, 위험 비율은 결코 음수가 될 수 없습니다. 둘째, 치료군과 대조군 사이에 차이가 없으면 RR은 1(SMD처럼 0이 아닌) 값을 갖습니다. RR이 1보다 크면 이는 치료 그룹이 사건 $E$의 위험을 증가시킨다는 것을 의미합니다. RR이 1보다 작으면 개입으로 위험이 줄어듭니다.

RR의 특징은 동일한 크기의 효과가 등거리가 아니라는 것입니다. 예를 들어 RR = 0.5는 개입 그룹에서 위험이 절반으로 줄어든다는 것을 의미합니다. 그러나 이 효과의 정반대인 개입으로 인해 위험이 두 배가 되는 것은 RR = 1.5가 아니라 RR = 2로 표현됩니다. 이는 위험 비율이 정규 분포를 따르지 않는다는 것을 의미하며 이는 메타에서 문제가 될 수 있습니다. -복수.

이 문제를 방지하기 위해 위험 비율은 풀링 전에 로그 위험 비율로 변환되는 경우가 많습니다. 이렇게 하면 효과 크기가 어떤 값이든 가정할 수 있고 값이 0(효과 없음을 의미)을 중심으로 집중된다는 무증상 정규성이 보장됩니다. 변환은 RR의 자연 로그를 취하여 수행됩니다.


$$\begin{equation}
\log \text{RR}  = \log_{e}(\text{RR})
\tag{3.27}
\end{equation}$$

로그-위험 비율의 표준 오차는 다음 공식을 사용하여 계산할 수 있습니다.

$$\begin{equation}
SE_{\log \text{RR}} = \sqrt{\frac{1}{a}+\frac{1}{c} - \frac{1}{a+b} - \frac{1}{c+d}}
\tag{3.28}
\end{equation}$$


R에서 (로그-)위험 비율을 다음과 같이 계산할 수 있습니다.

```{r}
# Define data
a <- 46         # events in the treatment group
c <- 77         # events in the control group
n_treat <- 248  # sample size treatment group
n_contr <- 251  # sample size control group

# Calculate the risks
p_treat <- a/n_treat
p_contr <- c/n_contr

# Calculate the risk ratio
rr <- p_treat/p_contr
rr
```

```{r}
# Calculate the log-risk ratio and its standard error
log_rr <- log(rr)
log_rr
```

```{r}
se_log_rr <- sqrt((1/a) + (1/c) - (1/n_treat) - (1/n_contr))
se_log_rr
```

셀이 0이면 위험 비율 계산이 어려워집니다. 실제로 $a$ 또는 $c$(또는 둘 다)가 0일 수도 있습니다. 이는 치료군이나 대조군에 사건이 기록되지 않았음을 의미합니다. RR을 계산하는 데 사용되는 공식을 살펴보면 이것이 왜 문제인지 쉽게 알 수 있습니다. $a$(치료 그룹의 이벤트)가 0이면 $PE_{treat}$도 0이고 RR은 0이 됩니다. $c$가 0인 경우는 더욱 문제가 됩니다. 이는 $pE_{control}$가 0이고 우리 모두가 0으로 나눌 수 없다는 것을 알고 있음을 의미합니다.

이 문제는 연속성 수정을 사용하여 처리되는 경우가 많습니다. 가장 일반적인 연속성 수정 방법은 0인 모든 셀에 0.5의 증분을 추가하는 것입니다(Gart and Zweifel 1967). 대조군과 치료군의 표본 크기가 매우 고르지 않은 경우 치료군 연속성 보정을 사용할 수도 있습니다(Sweeting, Sutton, and Lambert 2004).

그러나 그러한 수정이 편향된 결과로 이어질 수 있다는 증거가 있습니다(Efthimiou 2018). 4.2.3.1.1장에서 발견할 메타 분석 풀링 기술인 (고정 효과) Mantel-Haenszel 방법은 메타 분석의 모든 연구에 존재하지 않는 한 제로 셀을 수정 없이 처리할 수 있습니다. 따라서 후자의 시나리오가 적용되지 않는 한 연속성 수정을 피하는 것이 좋습니다.

제로 셀 문제의 특별한 형태는 더블 제로 연구입니다. $a$와 $c$가 모두 0인 연구입니다. 직관적으로 이러한 연구 결과는 단순히 중재군과 대조군의 위험이 유사하고 RR = 1이라는 것을 의미한다고 생각할 수도 있습니다.

불행히도 그렇게 쉬운 일은 아닙니다. 두 그룹 사이에 실제 효과가 있을 가능성이 매우 높지만 표본 크기가 너무 작아서 이러한 차이를 감지할 수 없습니다. 이는 $E$가 발생할 확률이 매우 낮을 때 특히 그렇습니다.

미친 과학자가 번개에 맞을 위험을 줄여준다고 알려진 풀구리돈(Fulguridone)의 효과를 평가하는 무작위 대조 시험을 실시한다고 상상해 보십시오. 그는 100명을 약물치료군과 대조군에 균등하게 배정하고 3년 동안 관찰했다. 실험 결과는 실망스럽습니다. 치료군이나 대조군 모두에서 번개를 맞은 사람은 아무도 없었기 때문입니다. 그러나 우리는 일반적으로 번개에 맞을 가능성이 얼마나 낮은지 알고 있습니다. 비록 우리가 치료가 효과가 있다는 다소 기괴한 생각을 받아들인다 하더라도 단지 100명만을 관찰하는 것만으로는 그렇게 드문 사건의 차이를 발견하는 데 충분하지 않습니다. 이러한 이유로 이중 제로 연구는 효과를 통합할 때 완전히 폐기되는 경우가 많습니다.

이는 위험 비율과 관련된 마지막 주의 사항으로 이어집니다. 이는 일반적으로 이벤트가 얼마나 흔한지에 대한 정보를 제공하지 않습니다. 예를 들어 메타 분석에서 위험 비율이 0.5로 보고되면 개입으로 위험이 절반으로 감소했다는 것을 알 수 있습니다. 하지만 위험이 40%에서 20%로 감소했는지, 아니면 0.004%에서 0.002%로 감소했는지는 알 수 없습니다. 위험 비율이 실제로 관련이 있는지 여부는 상황에 따라 다릅니다. 0.5의 위험 비율이 0.002%의 위험 감소를 나타내는 경우 이는 인구 수준에 큰 영향을 미치지 않을 수 있지만 관심 사건이 예를 들어 심각하고 쇠약해지는 질병인 경우에는 여전히 중요할 수 있습니다.

*R에서 메타 분석을 수행할 때 일반적으로 연구의 로그 위험 비율을 직접 계산할 필요는 없습니다. 또한 데이터를 가져올 때 셀이 0인 것에 대해 걱정할 필요가 없습니다. 데이터 세트에는 다음 열이 포함되어야 합니다.

* event.e. 치료군 또는 실험군에서의 사건 수.

* n.e. 치료 또는 실험 그룹의 표본 크기.

* event.c. 통제그룹의 이벤트 수입니다.

* n.c. 통제그룹의 표본 크기입니다.

### 승산비
위험 비율과 마찬가지로 승산비는 두 그룹의 이진 결과 데이터가 있을 때 계산될 수도 있습니다. 비율에 관한 앞의 설명에서 이미 확률을 특정 범주에 속하는 사례 수를 해당 범주에 속하지 않는 단위 수로 나눈 값으로 정의했습니다.

표 3.1의 표기법을 사용하면 치료군과 대조군의 확률 공식은 다음과 같습니다.

$$\begin{equation}
\text{Odds}_{\text{treat}} = \frac{a}{b}
\tag{3.29}
\end{equation}$$

$$\begin{equation}
\text{Odds}_{\text{control}} = \frac{c}{d}
\tag{3.30}
\end{equation}$$

확률이 실제로 무엇을 의미하는지 정확하게 해석하는 것은 어려울 수 있습니다. 이는 사건의 확률이 아니라 사건과 비사건의 비율을 설명합니다. 우리가 세 사람을 연구했다고 상상해 보세요. 두 명은 관심 있는 사건을 경험했지만 한 명은 그렇지 않았습니다. 이 데이터를 바탕으로 사건의 확률(또는 위험)은 $p = \frac{2}{3} \about 66$%가 됩니다. 그러나 사건의 확률은 Odds = $\frac{2}{1} = 2$입니다. 즉, 하나의 비사건에 대해 두 개의 사건이 있다는 의미입니다.

승산비(OR)는 처리군의 승산을 대조군의 승산으로 나눈 값으로 정의됩니다.


$$\begin{equation}
\text{OR} = \frac{a/b}{c/d}
\tag{3.31}
\end{equation}$$

위험비와 마찬가지로 승산비는 메타 분석에 바람직하지 않은 통계적 특성을 갖습니다. 따라서 자연 로그를 사용하여 승산비를 로그 승산비로 변환하는 것도 일반적입니다.

$$\begin{equation}
\log \text{OR}  = \log_{e}(\text{OR})
\tag{3.32}
\end{equation}$$


로그 승산비의 표준 오차는 다음 공식을 사용하여 계산할 수 있습니다(표 3.1의 표기법 사용).

$$\begin{equation}
SE_{\log \text{OR}}  = \sqrt{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}}
\tag{3.33}
\end{equation}$$

{esc} 패키지의 esc_2x2 함수는 R에서 (로그) 승산비를 계산하는 쉬운 방법을 제공합니다.

```{r}
library(esc)

# Define data
grp1yes <- 45  # events in the treatment group
grp1no <- 98   # non-events in the treatment group
grp2yes <- 67  # events in the control group
grp2no <- 76   # non-events in the control group

# Calculate OR by setting es.type to "or"
esc_2x2(grp1yes = grp1yes, grp1no = grp1no,
        grp2yes = grp2yes, grp2no = grp2no,
        es.type = "or")
```
```{r}
# Calculate logOR by setting es.type to "logit"
esc_2x2(grp1yes = grp1yes, grp1no = grp1no,
              grp2yes = grp2yes, grp2no = grp2no,
              es.type = "logit")
```
위험 비율, 제로 셀 및 이중 제로 연구(3.3.2.1장 참조)와 관련된 동일한 문제는 승산비를 계산할 때도 관련됩니다. 그러나 승산비는 RR에 비해 한 가지 추가 단점이 있습니다. 많은 사람들이 이해하기 어렵다고 생각하며 OR를 RR로 잘못 해석하는 경우가 많습니다.

따라서 메타 분석에서는 위험 비율만 사용하거나 결과를 보고할 때 승산비를 위험 비율로 변환하는 것이 종종 바람직합니다(Julian Higgins et al. 2019, chap. 6.4.1.2). 변환은 다음 공식을 사용하여 수행할 수 있습니다(Zhang and Yu 1998).

$$\begin{equation}
\text{RR} = \frac{\text{OR}}{\left(1-\dfrac{c}{n_{\text{control}}}\right)+ \left(\dfrac{c}{n_{\text{control}}}\times \text{OR} \right)}
\tag{3.34}
\end{equation}$$

R에서 승산비에 대한 메타 분석을 수행하려면 데이터 세트에 다음 열이 포함되어야 합니다.

* event.e. 치료군 또는 실험군에서의 사건 수.

* n.e. 치료 또는 실험 그룹의 표본 크기.

* event.c. 통제그룹의 이벤트 수입니다.

* n.c. 통제그룹의 표본 크기입니다.

## 2.3. 발생률 비율
이전에 조사한 이진 결과 데이터의 효과 크기인 위험 비율과 승산비는 두 그룹의 이벤트 수를 비교하는 방법입니다. 그러나 이러한 이벤트가 발생한 시간을 직접 인코딩하지는 않습니다. 위험비 또는 승산비를 계산할 때 우리는 두 그룹의 관찰 기간이 비슷하다고 암묵적으로 가정합니다. 또한 위험 및 승산비는 사건이 발생할 때까지 걸린 시간에 대한 정보를 제공하지 않습니다.

어떤 경우에는 시간 프레임이 우리의 연구 질문과 지나치게 관련되지 않기 때문에 이는 괜찮습니다. 또한 이진 데이터가 단면적이며 시간 차원이 전혀 없을 수도 있습니다15. 이러한 경우 위험 또는 승산비는 일반적으로 적절한 효과 크기 척도입니다.

하지만 이제 10년에 걸쳐 두 그룹으로 나누어 개인의 사망률을 조사하는 연구를 상상해 보세요. 10년 동안 발생한 사건(예: 사망)의 수는 두 그룹 모두에서 대략 비슷할 수도 있습니다. 그러나 사망이 발생한 시기를 자세히 살펴보면 첫 해에 한 그룹에서 더 많은 사건이 발생한 반면, 다른 그룹에서는 10년 관찰 기간이 끝날 때까지 다소 더 많은 사건이 발생했음을 알 수 있습니다. 데이터에 대해 계산된 확률 또는 위험 비율은 대략 1이며 이는 그룹 차이가 없음을 나타냅니다. 그러나 이는 중요한 사실을 놓치고 있습니다. 즉, 한 그룹의 참가자는 결국 사망하더라도 어느 정도 더 오래 살아남았다는 것입니다.

시간을 효과 크기 추정에 통합하기 위해 발생률 비율(때때로 간단히 비율 비율이라고 함)을 계산할 수 있습니다. 발생률 비율은 두 가지 발생률로 구성됩니다. 이러한 발생률을 계산하려면 먼저 개인-시간(Person-Time)의 개념을 이해해야 합니다.

개인 시간은 연구 참가자가 사건이 발생할 위험에 처한 총 시간을 나타냅니다. 개인 시간을 계산하기 위해 모든 연구 대상의 위험에 처한 시간(일, 주 또는 년으로 표시)을 합산합니다. 그러나 위험에 처하는 시간은 사람마다 다릅니다.

이를 예시하기 위해 6명의 참가자가 참여하는 연구를 진행한다고 가정해 보겠습니다. 이 연구는 정확히 10년 동안 지속됩니다. 매년 후에 우리는 참가자들을 인터뷰하여 그들이 관심 있는 사건을 경험했는지 조사합니다. 사건이 발생한 것을 관찰할 때마다 영향을 받은 참가자에 대한 연구가 종료되며 연구가 끝날 때까지 해당 참가자를 조사하지 않습니다. 우리 연구 결과는 그림 3.4에 시각화되어 있습니다.


![Fig3_1](fig3.png)

Figure 3.4: Example of time-to-event data.

우리 참가자 중 Victoria와 Lea 두 명만 연구가 끝날 때까지 연구에 남아 있음을 알 수 있습니다. 10년의 관찰기간 내내 그 사건을 경험하지 못했기 때문이다. 따라서 둘 다 10년 동안 위험에 처해 있었습니다.

다른 모든 참가자는 연구 기간 동안 이벤트를 경험했습니다. 예를 들어 레베카가 2학년 때 검사를 받았을 때 우리는 그녀가 작년에 그 사건을 경험했다는 것을 알게 되었습니다. 그러나 우리는 그 사건이 정확히 언제 발생했는지는 알 수 없으며 2년차에 발생했다는 것만 알고 있습니다.

이와 같은 연구 데이터를 구간 검열 데이터라고 하며, 소위 생존 분석을 수행하는 임상시험에서 매우 자주 발견됩니다. 데이터가 검열된다는 것은 Rebecca가 마침내 사건을 경험하기 전에 얼마나 오랫동안 위험에 처해 있었는지 부분적으로만 알 수 있다는 것을 의미합니다. 우리는 그녀가 1년차 이후와 2년차가 끝나기 전에 행사를 가졌다는 것을 알고 있지만 그 이상은 아닙니다. 따라서 다른 정보가 부족하여 사건이 중간 어딘가에서 발생했다고 가정하고 1.5년의 시간을 위험에 빠뜨릴 수 있습니다.

검열된 모든 데이터에 대해 동일한 체계를 적용하면 연구에서 위험에 처한 인년을 계산할 수 있습니다.


$$10 + 1.5+5.5+4.5+8.5+10 = 40$$
따라서 우리 연구에서 위험에 처한 총 인년은 40입니다. 1년이 52주임을 알면 연구의 인-주를 $40×52=2080$로 계산할 수도 있습니다.

이제 $T$로 표시할 실험의 인년을 알았으므로 1년 이내의 발생률도 계산할 수 있습니다. 연구 기간 동안 4명의 참가자가 이벤트를 경험한 것으로 알고 있으므로 이벤트 수는 $E=4$입니다. 그런 다음 다음 공식을 사용하여 발생률 IR을 계산할 수 있습니다.


$$\begin{equation}
\text{IR} = \frac{E}{T}
\tag{3.34}
\end{equation}$$

이 예에서는 발생률이 $4/40=0.1$입니다. 이 발생률은 1000명을 1년 동안 추적하면 100명이 그 기간 동안 사건을 경험한다는 것을 의미합니다.

발생률 비율 IRR을 계산하려면 한 그룹의 발생률을 다른 그룹의 발생률로 나누어야 합니다.

$$\begin{equation}
\text{IRR} = \frac{ E_{\text{treat}}/T_{\text{treat}} }{E_{\text{control}}/T_{\text{control}}}
\tag{3.35}
\end{equation}$$


이 공식에서 $E_{treat}$ 및 $T_{treat}$는 치료 그룹의 사건 수와 개인 시간이고, $E_{control}$ 및 $T_{control}$은 사건 수와 $T_{control}$입니다. 대조군의 개인 시간. 물론, 두 그룹은 여성과 남성, 흡연자와 비흡연자 등 다른 이분법적 관심 변수를 나타낼 수도 있습니다.

IRR은 1을 중심으로 하고 항상 음수가 아닌 등 위험 및 승산비와 많은 속성을 공유합니다. OR 및 RR과 마찬가지로 발생률 비율도 메타 분석을 위해 종종 로그 변환되어 로그 발생률 비율을 생성합니다.

$$\begin{equation}
\log \text{IRR} = \log_{e}(\text{IRR})
\tag{3.36}
\end{equation}$$

이에 대한 표준 오차는 다음과 같이 계산할 수 있습니다(Rothman, Greenland, and Lash 2008, chap. 14).

$$\begin{equation}
SE_{\log \text{IRR}} = \sqrt{\frac{1}{E_{\text{treat}}}+\frac{1}{E_{\text{control}}}}
\tag{3.37}
\end{equation}$$

R에서 (로그)발생률과 표준오차를 다음과 같이 계산할 수 있습니다.


```{r}
# Define Data
e_treat <- 28    # Number of events in the treatment group
e_contr <- 28    # Number of events in the control group
t_treat <- 3025  # Person-time in the treatment group
t_contr <- 2380  # Person-time in the control group

# Calculate IRR
irr <- (e_treat/t_treat)/(e_contr/t_contr)
irr
```

```{r}
# Calculate log-IRR
log_irr <- log(irr)
log_irr

# Calculate standard error
se_log_irr <- sqrt((1/e_treat)+(1/e_contr))
se_log_irr
```
이 예에서는 이벤트 $E_{treat}$ 및 $E_{control}$의 수가 정확히 동일하지만 치료 그룹이 위험에 노출되는 개인 시간이 더 긴 경우를 시뮬레이션했습니다. 이 시차는 IRR을 계산할 때 고려됩니다. 따라서 우리가 얻는 결과는 1이 아니라 $IRR \about 0.79$로 치료군에서 발생률이 더 낮음을 나타냅니다.

발생률 비율은 역학 및 예방 연구에 일반적으로 사용됩니다. 참가자를 장기간 추적할 때와 그 사이에 정기적인 평가가 있을 때 사용할 수 있습니다. 그러나 실제로 메타 분석의 일부로 IRR을 계산할 때 고려해야 할 한 가지 주의 사항이 있습니다. 즉, 포함된 기사에 보고된 발생률 데이터가 충분히 세분화되어 있어야 한다는 것입니다. 때로는 논문에서 전체 연구 기간 동안의 총 사건 수만 보고하고 그 사이의 각 평가 지점에서 기록된 사건 수는 보고하지 않는 경우도 있습니다. 처음부터 중간 평가가 이루어지지 않았을 수도 있습니다.

위의 예(그림 3.4 참조)에서는 참가자의 위험에 처한 시간을 추정하기 위해 마지막 "이벤트 없는" 평가 지점과 이벤트가 기록된 평가 지점 사이의 중간점을 간단히 취했습니다. 이는 사건이 정확히 언제 일어났는지에 대한 최선의 추측일 뿐이라는 점을 명심하는 것이 중요합니다. 중간점을 취하더라도 이 예에서는 추정치가 여전히 약 반년 정도 벗어날 수 있습니다.

평가 지점 사이의 시간이 가능한 한 작을 경우 개인 시간에 대한 추정이 가장 좋습니다. 연구의 평가 간격이 너무 거친 경우 메타 분석의 맥락에 따라 다르지만 항상 민감도 분석을 수행하는 것이 좋습니다(Panageas et al. 2007).

이는 개인 시간의 다양한 추정치를 기반으로 연구의 IRR을 다시 계산하는 것을 의미합니다.

* 간격의 중간점을 사용하여,

* 마지막 "이벤트 없는" 평가 포인트를 사용하고,

* 이벤트가 감지된 평가 지점을 사용합니다.

이 세 가지 메타 분석 결과가 모두 같은 방향을 가리키면 우리는 결과에 더 확신을 가질 수 있습니다. 또한 평가 기간이 연구 간에 너무 많이 다르지 않도록 해야 합니다(예: 한 연구는 매일 사건을 조사하고 다른 연구는 매년만 조사함). 메타 분석에 대한 IRR의 적용 가능성에 대해 의문이 있는 경우 대신(또는 추가로) 위험 또는 승산비를 계산할 가능성이 항상 있습니다. 그러나 이렇게 할 때는 각 연구에서 평가 포인트가 유사한지 확인해야 합니다(예: 1년 후).

R의 발생률 비율을 기반으로 메타 분석을 계산하려면 데이터 세트에 다음 열을 준비해야 합니다.

* event.e: 치료군 또는 실험군의 총 사건 수.

* time.e: 치료군 또는 실험군에서의 개인-시간. 인-시간은 모든 연구에서 동일한 단위(인-일, 인-주 또는 인-년)로 표현되어야 합니다.

* event.c: 대조군의 총 이벤트 수입니다.

* time.c: 대조군의 개인-시간입니다. 인-시간은 모든 연구에서 동일한 단위(인-일, 인-주 또는 인-년)로 표현되어야 합니다.




## 2.4. 효과 크기 보정
3.1장에서 우리는 연구 $k$에 대해 계산한 효과 크기 $\hat{\theta_k}$가 연구의 실제 효과 크기 $\theta_k$의 추정치이며 $\hat{\theta_k}$를 다루었습니다. 샘플링 오류 $\epsilon_k$로 인해 $\theta_k$에서 벗어납니다. 불행하게도 많은 경우 이는 지나치게 단순화된 것입니다. 이전에 논의한 방정식에서 추정된 효과 크기와 실제 효과를 구분하는 유일한 것은 샘플링 오류입니다. 공식에 따르면, 샘플링 오류가 감소함에 따라 효과 크기 추정치는 "자연스럽게" 모집단의 실제 효과 크기와 수렴됩니다.

그러나 효과 크기 추정이 체계적인 오류나 편향으로 인해 추가 부담을 받는 경우에는 그렇지 않습니다. 그러한 편견에는 다양한 이유가 있을 수 있습니다. 일부는 효과 크기 지표 자체의 수학적 특성으로 인해 발생하는 반면, 다른 편향은 연구가 수행되는 방식으로 인해 발생합니다.

우리는 편향 위험을 평가하여 연구가 수행된 방식에서 발생하는 편향을 다룰 수 있습니다(편향 평가 도구의 위험에 대한 소개는 1.4.5장을 참조하고 편향 위험을 시각화하는 방법은 15장 참조). 이 판단은 편향 위험이 통합 효과의 차이와 연관되어 있는지 여부를 결정하는 데에도 사용될 수 있습니다(예: 하위군 분석(7장)).

효과 크기 측정항목의 통계적 속성으로 인해 발생하는 편향을 처리하기 위해 메타 분석을 시작하기 전에 특정 효과 크기 수정 방법을 사용하여 데이터를 조정할 수 있습니다.

이 장에서는 일반적으로 사용되는 세 가지 효과 크기 보정 절차와 이를 R에서 구현하는 방법을 다룹니다.

### 작은 표본 편향
3.3.1장에서 우리는 두 그룹의 연속적인 결과 데이터가 있을 때 계산할 수 있는 효과 크기인 표준화된 평균 차이(SMD)를 다루었습니다. 그러나 표준화된 평균 차이는 연구의 표본 크기가 작을 때, 특히 $n \leq 20$일 때 상향 편향을 갖는 것으로 밝혀졌습니다(L. V. Hedges 1981). 이러한 작은 표본 편향은 연구의 전체 표본 크기가 작을 때 SMD가 체계적으로 실제 효과 크기를 과대평가한다는 것을 의미합니다. 불행하게도 실제로는 이런 경우가 많습니다.

따라서 Hedges의 $g$라는 효과 크기를 생성하는 소표본 편향에 대해 포함된 모든 연구의 표준화된 평균 차이를 수정하는 것이 합리적입니다. Hedges의 $g$는 이 수정을 고안한 Larry Hedges의 이름을 따서 명명되었습니다. 수정되지 않은 SMD/Cohen의 $d$를 Hedges의 $g$로 변환하는 공식은 다음과 같습니다.


$$\begin{equation}
g = \text{SMD} \times (1-\frac{3}{4n-9})
\tag{3.38}
\end{equation}$$

이 공식에서 $n$은 연구의 전체 표본 크기를 나타냅니다. {esc} 패키지의 hedges_g 함수를 사용하여 표준화되지 않은 SMD/Cohen의 $d$를 Hedges의 $g$로 쉽게 변환할 수 있습니다.'


```{r}
# Load esc package
library(esc)

# Define uncorrected SMD and sample size n
SMD <- 0.5
n <- 30

# Convert to Hedges g
g <- hedges_g(SMD, n)
g
```
출력에서 볼 수 있듯이 Hedges의 $g$는 수정되지 않은 SMD보다 작습니다. Hedges의 $g$는 수정되지 않은 SMD보다 클 수 없으며, 두 지표 간의 차이는 표본 크기가 작을수록 더 커집니다(그림 3.5 참조).

![Fig4](fig4.png)

그림 3.5: 다양한 샘플 크기에 대해 0.2의 수정된 SMD와 수정되지 않은 SMD.

연구 보고서에서 SMD와 Hedges의 $g$라는 용어가 때때로 같은 의미로 사용된다는 점에 유의하는 것이 중요합니다. 따라서 연구에서 결과를 SMD로 보고하는 경우 저자가 실제로 수정되지 않은 표준화된 평균 차이를 참조했는지, 아니면 소표본 편향 수정이 적용되었는지(Hedges의 $g$가 사용되었음을 의미) 확인하는 것이 중요합니다.


### 신뢰성 없음
측정 오류로 인해 효과 크기 추정치가 편향될 수도 있습니다. 대부분의 설문지나 테스트는 관심 있는 결과를 완벽하게 측정하지 않습니다. 계측기에서 측정 오류가 발생할 확률이 낮을수록 신뢰성이 높아집니다. 일부 변수 $x$를 측정하는 장비의 신뢰도는 0과 1 사이의 값을 가질 수 있는 신뢰도 계수 $r_{xx}$를 통해 표현될 수 있습니다. 신뢰도는 종종 테스트-재테스트-신뢰도로 정의되며 다음과 같이 계산할 수 있습니다. 동일한 사람을 유사한 상황에서 짧은 시간 내에 2회 이상 측정한 후 그 값 간의 상관관계를 계산하는 방식입니다16.

두 연속 변수의 관계를 조사할 때 이러한 변수를 평가하는 데 사용되는 도구 중 하나 또는 둘 모두에 대한 신뢰성이 부족하면 감쇠라는 현상이 발생할 수 있습니다. 이 문제는 유명한 심리학자 Charles Spearman(1904)에 의해 이미 1904년에 설명되었습니다. 예를 들어 상관 관계를 계산할 때 하나 또는 두 변수 모두 오류가 있는 것으로 측정되면 실제 상관 관계를 과소평가하게 됩니다. 상관 관계가 희석됩니다. 하지만 좋은 소식이 있습니다. 측정의 (비)신뢰도에 대한 추정치가 있는 경우 실제 효과 크기에 대한 더 나은 추정치를 얻기 위해 이 감쇠를 수정하는 것이 가능합니다.

메타 분석 분야의 두 중요한 기여자인 John Hunter와 Frank Schmidt는 메타 분석의 일부로 감쇠 보정을 수행할 수 있는 방법을 개발하고 장려했습니다(Hunter and Schmidt 2004, 3장 및 7장). . 이 수정은 때때로 "Hunter 및 Schmidt 기술" 또는 "Hunter 및 Schmidt 방법"(Hough 및 Hall 1994)이라고 함께 불리는 여러 다른 절차 중 하나입니다.

감쇠에 대한 Hunter와 Schmidt의 수정은 (제품-모멘트) 상관 관계 및 표준화된 평균 차이에 적용될 수 있습니다. 먼저, 메타 분석의 일부로 연구의 제품-순간 상관관계 $r_{xy}$를 계산할 때 변수 $x$ 측정의 비신뢰성을 수정하고 싶다고 가정해 보겠습니다. $r_{xx}$로 표시되는 $x$ 측정의 신뢰도를 알면 상관 관계의 수정된 버전인 $r_{xy_{c}}$를 계산할 수 있습니다.

$$\begin{equation}
{r_{xy}}_{c} = \frac{r_{xy}}{\sqrt{r_{xx}}}
\tag{3.39}
\end{equation}$$

결과 $x$가 두 그룹에서 관찰되었고 우리의 목표가 해당 그룹 간의 표준화된 평균 차이를 계산하는 것인 경우 $SMD_c$를 얻기 위해 유사한 방식으로 수정을 수행할 수 있습니다.

$$\begin{equation}
\text{SMD}_c = \frac{\text{SMD}}{\sqrt{r_{xx}}}
\tag{3.40}
\end{equation}$$

두 개의 연속 변수 $x$와 $y$를 사용하여 제품-순간 상관 관계를 계산할 때 $y$의 신뢰도 계수도 알고 있다면 $x$와 $y$의 비신뢰성($r_{yy}$)을 수정하는 것도 가능합니다. 

$$\begin{equation}
{r_{xy}}_{c} = \frac{r_{xy}}{\sqrt{r_{xx}}\sqrt{r_{yy}}}
\tag{3.41}
\end{equation}$$

마지막으로 표준오차도 수정해야 한다. 표준오차는 효과크기 자체와 동일한 방식으로 수정됩니다. 하나의 변수 $x$를 수정하려면 다음 공식을 사용할 수 있습니다.

$$\begin{equation}
SE_c = \frac{SE}{\sqrt{r_{xx}}}
\tag{3.42}
\end{equation}$$

$x$와 $y$ 모두에 대해 수정(제품-순간 상관관계)을 원할 경우 이 공식을 사용할 수 있습니다.

$$\begin{equation}
SE_c = \frac{SE}{\sqrt{r_{xx}}\sqrt{r_{yy}}}
\tag{3.43}
\end{equation}$$

상관 관계 또는 SMD가 수정된 후에는 $r_{xy_c}$를 Fisher의 $z$(3.2.3장)로 변환하거나 $SMD_c$를 Hedges의 $g$(3.2.3장)로 변환하는 등 다른 일반적인 변환을 적용할 수 있습니다. 3.4.1).

R을 사용하는 예제에서 수정 절차를 시도해 보겠습니다.

```{r}
# Define uncorrected correlation and SMD with their standard error
r_xy <- 0.34
se_r_xy <- 0.09
smd <- 0.65
se_smd <- 0.18

# Define reliabilities of x and y
r_xx <- 0.8
r_yy <- 0.7

# Correct SMD for unreliability in x
smd_c <- smd/sqrt(r_xx)
smd_c
```
```{r}
se_c <- se_smd/sqrt(r_xx)
se_c
```
```{r}
# Correct correlation for unreliability in x and y
r_xy_c <- r_xy/(sqrt(r_xx)*sqrt(r_yy))
r_xy_c
```
```{r}
se_c <- se_r_xy/(sqrt(r_xx)*sqrt(r_yy))
se_c
```

이 예의 결과를 자세히 살펴보십시오. 수정으로 인해 상관관계와 SMD가 수정되지 않은 초기 값보다 크다는 것을 알 수 있습니다. 그러나 표준 오류도 증가하는 것을 볼 수 있습니다. 이는 의도된 결과입니다. 우리는 데이터에 대해 가정하는 측정 오류도 포함하도록 표준 오류를 수정합니다.

조직 심리학과 같은 일부 분야에서는 감쇠 보정을 적용하는 것이 일반적입니다. 그러나 생의학 분야를 포함한 다른 분야에서는 이 절차가 거의 사용되지 않습니다. 메타 분석에서는 각 연구에서 신뢰도 계수 $r_{xy}$(및 $r_{yy}$)가 보고된 경우에만 비신뢰성에 대한 수정을 수행할 수 있습니다.

매우 자주, 이것은 사실이 아닙니다. 이 시나리오에서는 이전 연구를 기반으로 기기의 신뢰성에 대한 값을 가정할 수 있습니다. 그러나 보정이 효과크기 값에 큰 영향을 미치기 때문에 $r_{xy}$를 부적절하게 추정하면 결과가 상당히 왜곡될 수 있습니다. 또한 메타 분석에서 일부 효과 크기만 수정하고 다른 효과 크기는 수정하지 않은 채로 두는 것도 불가능합니다. 이러한 이유로 인해 신뢰성 보정의 적용 가능성은 불행하게도 실제로 종종 제한됩니다.

### 범위 제한
Hunter와 Schmidt(2004, 3장 및 7장)가 제안한 또 다른 효과 크기 조정은 범위 제한 문제를 다루고 있습니다. 범위 제한은 일부 변수 $x$의 변동이 실제 관심 모집단보다 연구에서 더 작을 때 발생하는 현상입니다. 이는 전체 인구를 대표할 수 없는 매우 선별적인 개인 표본을 연구에서 모집할 때 자주 발생합니다.

예를 들어, 연구에서 참가자의 연령과 인지 기능 간의 상관 관계를 보고하는 경우를 생각해 보십시오. 직관적으로 우리는 실제로 이러한 변수들 사이에 연관성이 있다고 가정할 수 있습니다. 그러나 연구에 65~69세 참가자만 포함된 경우 두 변수 간에 (높은) 상관관계가 발견될 가능성은 거의 없습니다. 이는 연구 표본의 연령이 범위에 매우 제한되어 있기 때문입니다. 연령에는 실제 변화가 없습니다. 이는 이 변수가 인지 능력을 잘 예측할 수 없음을 의미합니다.

측정 도구의 신뢰성이 떨어지는 것과 마찬가지로(이전 장 참조) 이는 연구를 위해 계산하는 효과의 인위적인 감쇠로 이어집니다. 실제로 중요한 연관성이 있더라도 이를 감지할 수 없습니다.

SMD 또는 상관 관계 $r_{xy}$의 범위 제한을 수정하는 것이 가능합니다. 그러나 이를 위해서는 관심 모집단의 무제한 표준 편차 $s_{unrestricted}$를 알거나 추정해야 합니다. 관심 모집단은 메타 분석의 연구 질문에 따라 결정됩니다.

예를 들어, 노년기의 연령과 인지 기능 사이의 관계를 조사하려는 경우 65세 이상의 개인을 대표하는 대규모 표본에서 표준 편차 추정치를 검색할 수 있습니다. "라는 연구 결과가 정의되어 있습니다. 물론 이는 여전히 범위 제한이지만 메타 분석에서 다루고 있는 연구 모집단을 반영하기 때문에 연령을 중요한 범위로 제한합니다.

범위 제한을 수정하려면 제한되지 않은 모집단 표준 편차 $s_{unrestricted}$와 연구에서 제한된 변수의 표준 편차 $s_{restricted}$ 사이의 비율인 $U$를 계산해야 합니다.


$$\begin{equation}
U =  \frac{s_{\text{unrestricted}}}{s_{\text{restricted}}}
\tag{3.44}
\end{equation}$$

$s_{unrestricted}$의 값은 예를 들어 관심 변수를 평가한 이전의 대표적인 연구에서 얻을 수 있습니다. 그런 다음 $U$를 사용하여 다음 공식을 사용하여 상관관계 $r_{xy}$ 값을 수정할 수 있습니다.

$$\begin{equation}
{r_{xy}}_c = \frac{U\times r_{xy}}{\sqrt{(U^2-1)r_{xy}^2+1}} 
\tag{3.45}
\end{equation}$$
 
이를 통해 수정된 상관관계 $r_{xy_c}$를 얻을 수 있습니다. 동일한 공식을 사용하여 수정된 SMD 버전을 계산할 수도 있습니다.

$$\begin{equation}
\text{SMD}_c = \frac{U\times \text{SMD}}{\sqrt{(U^2-1)\text{SMD}^2+1}}
\tag{3.46}
\end{equation}$$

$r_{xy}$ 및 SMD의 표준 오류도 각각 다음 공식을 사용하여 수정해야 합니다.


$$\begin{equation}
SE_{{r_{xy}}_c} = \frac{{r_{xy}}_c}{r_{xy}}SE_{r_{xy}}
\tag{3.47}
\end{equation}$$

$$\begin{equation}
SE_{{\text{SMD}}_c} = \frac{{\text{SMD}}_c}{\text{SMD}}SE_{\text{SMD}}
\tag{3.48}
\end{equation}$$

상관 관계 또는 SMD가 수정된 후 $r_{xy_c}$를 Fisher의 $z$(3.2.3.1장)로 변환하거나 $SMD_c$를 Hedges의 $g$로 변환하는 등 다른 일반적인 변환을 적용할 수 있습니다. 이제 R을 사용하여 수정을 시도해 보겠습니다.
```{r}
# Define correlation to correct
r_xy <- 0.34
se_r_xy <- 0.09

# Define restricted and unrestricted SD
sd_restricted <- 11
sd_unrestricted <- 18

# Calculate U
U <- sd_unrestricted/sd_restricted

# Correct the correlation
r_xy_c <- (U*r_xy)/sqrt((U^2-1)*r_xy^2+1)
r_xy_c
```
```{r}
# Correct the standard error
se_r_xy_c <- (r_xy_c/r_xy)*se_r_xy
se_r_xy_c
```


다른 Hunter 및 Schmidt 조정과 마찬가지로 범위 제한 수정은 다른 연구 분야보다 일부 연구 분야에서 더 일반적으로 발견됩니다. 범위 제한에 대한 수정을 적용하기로 결정한 경우 메타 분석에서 모든 효과 크기에 대해 수정을 수행하는 것이 중요합니다. 모든 메타 분석에서 범위 제한을 수정하는 것은 기술적으로 가능하지만 종종 이는 필요하지 않습니다.

실제로 각 연구가 우리의 메타 분석 범위를 완벽하게 나타내는 경우는 거의 없습니다. 사실 메타분석의 목적은 개별 연구 결과를 넘어서는 것이다. 따라서 범위 제한 수정은 여러 연구의 범위가 크게 제한되는 경우에만 필요할 수 있습니다.

## 2.5. 일반적인 문제
이번 장에서는 효과크기를 계산할 때 실제로 자주 직면하게 되는 문제에 대해 조금 더 시간을 투자하고자 합니다. 먼저, 효과 크기 데이터가 다양한 형식으로 보고될 때 무엇을 할 수 있는지 논의하겠습니다. 그런 다음, 이후 단계에서 메타 분석 풀링에 영향을 미치는 분석 단위 문제를 검토합니다.

### 다양한 효과 크기 데이터 형식
지난 장에서 효과 크기 지표를 설명했을 때 데이터 세트의 열로 필요한 변수 유형도 언급했습니다. R 함수가 효과 크기를 계산하고 메타 분석을 수행할 수 있도록 이러한 변수가 필요합니다. 예를 들어 그룹 간 표준화 평균 차이에 대한 메타 분석을 계산하려면 두 그룹의 평균, 표준 편차 및 표본 크기를 준비해야 합니다.

모든 연구에서 이 정보를 추출할 수 있다면 모든 것이 괜찮습니다. 그러나 실제로 모든 연구가 적절한 형식으로 결과를 보고하는 것은 아니라는 사실을 곧 알게 될 것입니다. 예를 들어 일부 연구에서는 두 그룹의 원시 데이터를 보고하지 않고 계산된 표준화 평균 차이와 신뢰 구간만 보고할 수 있습니다. 다른 사람들은 두 그룹 간의 차이를 조사하는 t-검정이나 분산 분석(ANOVA)의 결과만 보고할 수도 있습니다.

이 경우 메타 분석에 원시 효과 크기 데이터를 사용하는 것이 불가능해지는 경우가 많습니다. 대신, 각 연구를 통합하기 전에 각 연구의 효과 크기를 미리 계산해야 합니다. 3.1장에서 우리는 메타분석을 하기 위해 필요한 최소한의 정보가 연구의 효과크기와 표준오차라는 것을 이미 알아냈습니다. 그러므로 결과를 효과크기와 표준오차의 추정치로 변환할 수 있다면 연구를 포함시킬 수 있다. 17장의 "유용한 도구" 섹션에서는 보고된 다른 유형의 데이터에서 효과 크기를 도출하는 데 도움이 될 수 있는 여러 가지 효과 크기 변환기를 제시합니다.

그러나 이러한 도구를 사용해도 효과 크기를 계산할 수 없는 연구가 여전히 있을 수 있습니다. 1.4.4장에서 언급했듯이, 그러한 상황에서 남은 가능성 중 하나는 각 출판물의 저자에게 여러 번 연락하여 효과 크기를 계산하는 데 필요한 데이터를 제공할 수 있는지 문의하는 것입니다. 이것도 실패하면 연구를 제외해야합니다.

4.2.1장에서는 R의 Metagen이라는 특수 함수에 대해 알아봅니다. 이 기능을 사용하면 미리 계산해야 했던 효과 크기 데이터의 메타 분석을 수행할 수 있습니다. 이 함수를 사용하려면 데이터 세트에서 다음 열을 준비해야 합니다.

* TE테. 각 연구의 계산된 효과 크기.

* SeTE. 각 효과크기의 표준오차입니다.

### 분석 단위 문제

한 연구가 우리의 메타 분석에 두 가지 이상의 효과 크기에 기여하는 것은 드문 일이 아닙니다. 특히 (1) 연구에 두 개 이상의 그룹이 포함되었거나 (2) 연구가 둘 이상의 도구를 사용하여 결과를 측정했을 수 있습니다. 두 경우 모두 문제가 발생합니다. 연구가 메타 분석에서 두 가지 이상의 효과 크기에 기여하는 경우, 우리는 메타 분석의 각 효과 크기가 독립적이라는 핵심 가정 중 하나를 위반하는 것입니다(Julian Higgins et al. 2019, chap. 6.2 및 23; Borenstein et al 2011, 25장. 이 가정이 충족되지 않으면 분석 단위 문제를 다루는 것입니다.

연구에 두 개 이상의 그룹이 있는 첫 번째 사례부터 시작하겠습니다. 예를 들어 치료 A를 조사하는 한 그룹, 치료 B가 투여되는 다른 그룹, 대조군 C를 예로 들 수 있습니다. 이 연구에서는 두 가지 효과 크기를 계산할 수 있습니다. 결과 데이터에 따라 위험, 확률, 발생률 비율 또는 표준화된 평균 차이가 될 수 있습니다. 치료 A를 대조군과 비교하는 효과 크기 $\hat\theta_{\text{A-C}}$와 비교 치료 B의 효과를 나타내는 또 다른 효과 크기 $\hat\theta_{\text{B-C}}$가 있습니다. 제어하다. $\hat\theta_{\text{A-C}}$ 및 $\hat\theta_{\text{B-C}}$가 동일한 메타 분석에 포함된 경우 이러한 효과 크기는 독립적이지 않습니다. 두 번 포함됩니다. 이 문제는 이중 계산이라고도 합니다.

C의 이중 계산으로 인해 두 효과 크기는 상관 관계가 있습니다. 표본 크기가 모든 그룹에서 동일하다면 이 상관 관계는 $r= 0.5$라는 것을 알 수 있습니다(Borenstein et al. 2011, chap. 25). 이는 A와 B가 독립적인 그룹이므로 상관 관계가 없기 때문입니다. 그러나 두 효과 크기의 대조군은 동일하므로 완벽한 상관 관계는 1입니다. 중간점은 0.5이다. 그룹을 이중 계산하면 영향을 받는 효과 크기의 정밀도(즉, 표준 오차)가 과대평가됩니다. 이는 메타 분석에서 이러한 효과에 부여하는 가중치를 부풀리고 궁극적으로 결과를 왜곡합니다. 이 문제를 처리하는 방법에는 세 가지가 있습니다.

* 공유 그룹의 샘플 크기를 분할합니다. 이는 효과 크기를 계산할 때 그룹 C의 표본 크기(예: $n= 200$)를 A와의 비교와 C와의 비교에 균등하게 분할한다는 의미입니다. 이진 결과 데이터를 다루는 경우 이벤트 수도 균등하게 분할됩니다. 이 예에서는 이전처럼 두 가지 효과 크기를 계산하지만 이제 두 계산 모두에서 C가 100명의 개인으로만 구성되었다고 가정합니다. 이 접근법은 이중 계산으로 인해 효과 크기의 정밀도가 인위적으로 부풀려지는 문제를 해결합니다. 그러나 효과 크기는 상관 관계를 유지하기 때문에 여전히 차선책입니다(Julian Higgins et al. 2019, 23.3.4).

* 그룹을 제거합니다. 무차별 접근 방식은 단순히 하나의 비교를 제거하는 것입니다. $\hat\theta_{\text{B-C}}$, 전적으로 메타 분석에서 나온 것입니다. 이는 분석 단위 문제를 해결하지만 새로운 문제를 야기합니다. 하나의 효과 크기를 단순히 버리면 잠재적으로 관련 있는 정보를 잃게 됩니다.

* 그룹을 결합합니다. 이 접근 방식에는 두 그룹의 결과를 결합하여 하나의 비교만 남게 됩니다. 이 예에서 이는 A와 B의 데이터를 결합한 다음 풀링된 결과를 C와 비교하는 것을 의미합니다. 이는 참가자 수와 이벤트 수만 합산하면 되는 이진 결과 데이터의 경우 상대적으로 쉽습니다. 두 그룹 모두. 연속적인 결과 데이터(예: 평균 및 표준 편차)가 있는 경우 상황은 좀 더 복잡해집니다. 17.9장의 "유용한 도구" 섹션에서 이러한 데이터를 결합할 수 있는 R 함수를 찾을 수 있습니다. 그룹을 결합함으로써 이중 계산 및 상관 효과 크기를 모두 방지합니다. 이것이 Cochrane에서도 이 접근 방식을 권장하는 이유입니다(Julian Higgins et al. 2019, chap. 23.3.4). 그럼에도 불구하고 이 방법에는 단점도 있습니다. 두 그룹이 너무 다르기 때문에 실제로 비교할 수 없는 것을 하나로 묶을 수도 있습니다. 그룹 A와 B의 치료법이 완전히 달랐다고 상상해 보세요. A는 최첨단 개입이고 B는 제한된 증거 기반을 갖춘 구식 접근 방식입니다. 이 두 가지 치료법을 결합했지만 효과가 없는 경우 이것이 두 가지 유형의 개입 모두에 해당되거나 B의 비효율성이 단순히 A의 효과를 희석한 경우 이를 풀기가 거의 불가능합니다. 따라서 접근 방식 (1)과 (2)는 다음과 같습니다. 두 그룹이 너무 다를 때 사용됩니다.

분석 단위 문제는 연구가 여러 도구를 사용하여 결과를 측정할 때도 발생합니다. 이는 일반적으로 관심 변수를 측정하는 방법을 결정하는 명확한 "최적 기준"이 없는 경우에 해당됩니다. 이러한 각 측정값에 대한 효과 크기를 계산하고 이를 메타 분석에 포함하면 이중 계산이 발생합니다. 또한 효과를 측정하는 데 동일한 표본이 사용되었으므로 효과 크기는 상관 관계가 있습니다. 이 상황을 처리하는 데는 세 가지 접근 방식이 있습니다.

* 첫째, 연구당 하나의 악기를 간단히 선택할 수 있습니다. 이러한 선택은 체계적이고 재현 가능한 방식으로 수행되는 것이 중요합니다. 기껏해야 분석 계획(1.4.2장)에서는 이미 메타 분석을 위한 도구 계층 구조를 정의해야 합니다. 이 계층 구조는 특정 도구의 신뢰성에 대한 이전 증거를 기반으로 하거나 연구 질문의 내용을 가장 잘 반영하는 측정 유형을 기반으로 할 수 있습니다. 그런 다음 계층 구조는 둘 이상의 도구를 사용할 수 있는 경우 어떤 도구를 선택하는지 명확하게 결정합니다.

* 또는 계산된 효과 크기를 사용하고 이를 집계하여 각 연구가 하나의 (집합된) 효과 크기만 제공하도록 할 수도 있습니다. 이는 일종의 "무차별 대입" 접근 방식입니다. 연구 내에서 효과 크기의 상관 관계가 얼마나 강한지 지정해야 하지만 이 값은 일반적으로 알려져 있지 않습니다. 17.10장에서는 미리 계산된 효과 크기를 각 연구에 대한 하나의 결합 추정치로 집계할 수 있는 함수를 제시합니다.

* 세 번째 접근 방식은 사용 가능한 모든 도구의 데이터를 포함하고 메타 분석 연구가 두 가지 이상의 효과 크기에 기여한다는 사실을 설명할 수 있는 메타 분석 모델을 사용하는 것입니다. 이는 10장에서 검토할 "3단계" 메타 분석 모델을 통해 달성할 수 있습니다.


## 2.6. 요약
효과 크기는 메타 분석의 구성 요소입니다. 메타 분석을 수행하려면 최소한 효과 크기와 표준 오차에 대한 추정이 필요합니다.

효과 크기의 표준 오차는 연구의 효과 추정치가 얼마나 정확한지를 나타냅니다. 메타 분석은 실제 효과를 더 잘 추정할 수 있기 때문에 정확도가 더 높은 효과 크기에 더 높은 가중치를 부여합니다.

메타 분석에 사용할 수 있는 효과 크기는 다양합니다. 일반적인 측정값으로는 "일변수" 관계 측정값(예: 평균 및 비율), 상관관계, (표준화된) 평균 차이, 위험도, 확률 및 발생률 비율이 있습니다.

효과 크기는 측정 오류 및 범위 제한 등으로 인해 편향될 수도 있습니다. 표준화된 평균 차이의 작은 표본 편향, 비신뢰성으로 인한 감쇠, 범위 제한 문제 등 일부 편향을 수정하는 공식이 있습니다.

다른 일반적인 문제는 연구가 효과 크기를 계산하는 데 필요한 데이터를 다양한 형식으로 보고한다는 점과, 연구가 두 가지 이상의 효과 크기에 기여할 때 발생하는 분석 단위 문제입니다.



# 3. 풀링 효과 크기

![Fig5](pooling_es.jpg)

구불구불한 길은 이미 우리 뒤에 있습니다. 다행스럽게도 우리는 이제 모든 메타 분석의 핵심 부분인 효과 크기 통합에 도달했습니다. 우리는 여러분이 이 장부터 바로 시작하고 싶은 유혹을 물리칠 수 있기를 바랍니다. 우리는 이미 이 책에서 연구 질문의 정의, 연구 데이터 검색, 선택, 추출 지침, 효과 크기 준비 방법 등 다양한 주제를 논의했습니다.

철저한 준비는 좋은 메타 분석의 핵심 요소이며 앞으로 진행될 단계에서 큰 도움이 될 것입니다. 이전 장을 진행하는 데 들인 시간이 잘 투자되었음을 확신할 수 있습니다.

R에는 효과 크기를 풀링할 수 있는 많은 패키지가 있습니다. 여기서는 2.2장에서 이미 설치한 {meta} 패키지의 기능에 중점을 둘 것입니다. 이 패키지는 매우 사용자 친화적이며 단 몇 줄의 코드를 사용하여 거의 모든 중요한 메타 분석 결과를 제공합니다. 이전 장에서 우리는 관심 결과에 따라 효과 크기가 서로 다른 "방향"으로 나타난다는 점을 다루었습니다. {meta} 패키지에는 이러한 효과 크기 지표 각각에 대한 특수 메타 분석 기능이 포함되어 있습니다. 모든 기능도 거의 동일한 구조를 따릅니다.

따라서 {meta}의 작동 방식에 대한 기본 이해가 있으면 우리가 초점을 맞추고 있는 효과 크기에 관계없이 코딩 메타 분석이 간단해집니다. 이 장에서는 {meta} 패키지의 일반적인 구조를 다룰 것입니다. 물론 실습 예제를 사용하여 패키지의 메타 분석 기능을 더 자세히 살펴보겠습니다.

{meta} 패키지를 사용하면 효과 크기를 합치는 방식에 대한 많은 세부 사항을 조정할 수 있습니다. 이전에 언급했듯이 메타 분석에는 많은 "연구자 자유도"가 있습니다. 우리가 적용할 수 있는 통계 기법과 접근법에 관한 선택은 무수히 많습니다. 한 방법이 다른 방법보다 나은지는 상황에 따라 달라지는 경우가 많습니다.

따라서 R에서 분석을 시작하기 전에 메타 분석의 통계적 가정과 그 뒤에 있는 수학에 대한 기본적인 이해를 얻어야 합니다. 중요한 것은 메타 분석의 이면에 있는 "아이디어"에 대해서도 논의할 것입니다. 통계에서 이 "아이디어"는 모델로 해석되며, 메타 분석 모델이 어떤 모습인지 살펴보겠습니다.

앞으로 살펴보겠지만 메타 분석의 특성상 우리는 근본적인 결정을 즉시 내려야 합니다. 즉, 고정 효과 모델 또는 무작위 효과 모델을 가정해야 합니다. 다른 분석 사양과 함께 이 두 모델 중 어떤 모델이 어떤 상황에 더 적합한지 정보에 입각한 결정을 내리려면 메타 분석 풀링 뒤에 있는 개념에 대한 지식이 필요합니다.

## 3.1. 고정 효과 및 확률효과 모델
메타분석 모델을 지정하기 전에 먼저 통계 모델이 실제로 무엇인지 명확히 해야 합니다. 통계는 "모델"로 가득 차 있으며 이전에 이 맥락에서 이 용어를 들어봤을 것입니다. '선형모델', '일반화선형모델', '혼합모델', '가우스 덧셈모델', '구조방정식모델' 등이 있다.

통계에서 모델의 편재성은 이 개념이 얼마나 중요한지를 나타냅니다. 어떤 방식으로든 모델은 통계 도구 상자의 거의 모든 부분의 기초를 구축합니다. t-검정, 분산 분석, 회귀 분석에는 모델이 있습니다. 모든 가설 검정에는 해당 통계 모델이 있습니다.

통계 모델을 정의할 때 이미 제공된 정보부터 시작합니다. 이것은 말 그대로 우리의 데이터입니다17. 메타 분석에서 데이터는 포함된 연구에서 관찰된 효과 크기입니다. 우리 모델은 관찰된 데이터가 생성되는 프로세스를 설명하는 데 사용됩니다.

데이터는 블랙박스의 산물로 간주되며, 우리 모델은 블랙박스 내부에서 무슨 일이 일어나고 있는지 밝히는 것을 목표로 합니다.


![Fig6](fig5.png)
일반적으로 통계 모델은 특별한 유형의 이론과 같습니다. 모델은 관찰된 데이터를 생성한 메커니즘을 설명하려고 노력하며, 특히 이러한 메커니즘 자체를 직접 관찰할 수 없는 경우 더욱 그렇습니다. 이는 수학 공식을 사용하여 우리 주변 세계의 과정을 이상적인 방식으로 설명하는 생명의 모방입니다.

모델의 이러한 설명적 특성은 현대 통계에 깊이 뿌리박혀 있으며 메타 분석도 예외는 아닙니다. 설명을 위한 수단으로 모델을 개념화하는 것은 Breiman(2001)이 유명하게 추정한 것처럼 모든 통계학자의 98%가 고수하는 통계적 '문화'의 특징입니다.

통계 모델을 지정함으로써 우리는 데이터 뒤에 있는 "현실"의 대략적인 표현을 찾으려고 노력합니다. 우리는 관찰된 결과를 기반으로 모든 연구의 기초가 되는 실제 효과 크기를 찾는 방법을 설명하는 수학 공식을 원합니다. 1.1장에서 배운 것처럼, 메타 분석의 궁극적인 목표 중 하나는 관찰된 효과 크기가 연구마다 다르지만 연구 전체를 특징짓는 하나의 수치 값을 찾는 것입니다. 따라서 메타 분석 모델은 전체 효과가 하나뿐임에도 불구하고 관찰된 연구 결과가 왜 그리고 얼마나 다른지 설명해야 합니다.

이 질문에 정확히 대답하려는 두 가지 모델, 즉 고정 효과 모델과 무작위 효과 모델이 있습니다. 둘 다 서로 다른 가정을 기반으로 하지만 곧 살펴보겠지만 둘 사이에는 여전히 강력한 연관성이 있습니다.


### 고정 효과 모델
고정 효과 모델은 모든 효과 크기가 단일하고 동질적인 모집단에서 비롯된다고 가정합니다. 모든 연구가 동일한 실제 효과 크기를 공유한다고 명시되어 있습니다. 이 실제 효과는 $\theta$로 표시되는 메타 분석에서 계산하려는 전체 효과 크기입니다.

고정 효과 모델에 따르면 연구 $k$의 관찰된 효과 크기 $\hat{\theta_k}$가 $\theta$에서 벗어나는 유일한 이유는 샘플링 오류 $\epsilon_k$ 때문입니다. 고정 효과 모델은 연구의 다양한 효과 크기, 즉 "블랙 박스"의 내용을 생성하는 프로세스가 간단하다는 것을 알려줍니다. 모든 연구는 동일한 실제 효과 크기의 추정자입니다. 그러나 모든 연구는 무한히 큰 연구 모집단에서 어느 정도 더 크거나 작은 샘플만 추출할 수 있기 때문에 결과에는 샘플링 오류가 발생합니다. 이 샘플링 오류로 인해 관찰된 효과가 전체 실제 효과에서 벗어나게 됩니다.

우리는 이 관계를 다음과 같이 설명할 수 있습니다(Borenstein et al. 2011, chap. 11).

$$\begin{equation}
\hat\theta_k = \theta + \epsilon_k 
\tag{4.1}
\end{equation}$$
 

예민한 독자들에게는 이 공식이 3.1장의 공식과 이상하게 유사해 보일 수도 있습니다. 당신은 착각하지 않습니다. 이전 공식에서 우리는 일부 연구 $k$의 관찰된 효과 크기 $\hat{\theta_k}$가 연구의 샘플링 오류 $\epsilon_k$에 의해 부담되는 해당 연구의 실제 효과 크기 $\theta_k$의 추정치라고 정의했습니다. .

이전 공식과 고정 효과 모델 사이에는 아주 작지만 통찰력 있는 차이가 있습니다. 고정 효과 모델의 공식에서 실제 효과 크기는 $\theta_k$가 아니라 $\theta$로 기호화됩니다. 아래첨자 $k$는 삭제됩니다.

이전에는 하나의 개별 연구 $k$의 실제 효과 크기에 대해서만 설명했습니다. 고정 효과 모델은 한 단계 더 나아갑니다. 연구 $k$의 실제 효과 크기를 찾으면 이 효과 크기는 특히 $k$에 대해서뿐만 아니라 메타 분석의 모든 연구에 대해서도 적용된다는 것을 알려줍니다. 연구의 실제 효과 크기 $\theta_k$와 전체 통합 효과 크기 $\theta$는 동일합니다.

고정 효과 모델의 공식은 관측된 효과 크기 $\theta_k$가 실제 전체 효과에서 벗어나는 이유는 단 하나, 즉 샘플링 오류 때문임을 알려줍니다.
$\epsilon_k$. 3.1장에서 우리는 표본 추출 오류와 연구의 표본 크기 사이에 연관성이 있다는 것을 이미 논의했습니다. 모든 조건이 동일할 때 표본 크기가 커질수록 표본 추출 오류는 작아집니다. 또한 표본오차는 표준오차로 수치적으로 표현될 수 있으며, 표준오차 역시 표본 크기가 커질수록 작아진다는 사실도 배웠습니다.

우리 연구의 실제 전체 효과 크기를 알지 못하더라도 이 관계를 활용하여 실제 전체 효과에 대한 최상의 추정치인 $\hat\theta_k$에 도달할 수 있습니다. 우리는 표준 오류가 작을수록 샘플링 오류도 작아진다는 것을 알고 있습니다. 따라서 표준 오차가 작은 연구는 표준 오차가 큰 연구보다 실제 전체 효과를 더 잘 추정할 수 있어야 합니다.

시뮬레이션을 통해 이를 설명할 수 있습니다. 이전에 이미 사용한 rnorm 함수를 사용하여 실제 전체 효과가 $\theta=0$인 연구 선택을 시뮬레이션했습니다. 우리는 여러 개의 샘플을 채취했지만 "관찰된" 효과 간에 표준 오차가 다르도록 샘플 크기를 변경했습니다. 시뮬레이션 결과는 그림 4.1에서 확인할 수 있습니다.


![Fig7](fig6.png)

그림 4.1: 효과 크기와 표준 오차 사이의 관계.

시뮬레이션 결과는 흥미로운 패턴을 보여줍니다. 작은 샘플링 오류가 있는 효과 크기가 실제 효과 크기 $\theta = 0$ 주위에 빽빽하게 들어차 있음을 알 수 있습니다. y축18의 표준오차가 증가할수록 효과크기의 분산은 점점 커지고, 관찰된 효과는 실제 효과에서 점점 더 벗어나게 됩니다.

이 동작은 고정 효과 모델의 공식으로 예측할 수 있습니다. 우리는 표준 오차가 작은 연구의 경우 표본 오차가 더 작으므로 전체 효과 크기에 대한 추정치가 진실에 더 가깝다는 것을 알고 있습니다.

우리는 관찰된 모든 효과 크기가 실제 효과의 추정치이지만 일부는 다른 것보다 낫다는 것을 확인했습니다. 따라서 메타 분석에서 효과를 통합할 때 정밀도가 더 높은(즉, 표준 오차가 더 작은) 효과 크기에 더 큰 가중치를 부여해야 합니다. 고정 효과 모델에서 통합 효과 크기를 계산하려면 모든 연구의 가중 평균을 사용하면 됩니다.

각 연구 $k$에 대한 가중치 $W_k$를 계산하기 위해 표준 오차를 사용할 수 있으며 이를 제곱하여 각 효과 크기의 분산 $s^2_k$을 얻습니다. 분산이 낮을수록 정밀도가 높음을 나타내므로 분산의 역수를 사용하여 각 연구의 가중치를 결정합니다.

$$\begin{equation}
w_k = \frac{1}{s^2_k}
\tag{4.2}
\end{equation}$$

가중치를 알면 실제 합동 효과 $\hat\theta$에 대한 추정치인 가중 평균을 계산할 수 있습니다. 각 연구의 효과 크기 $\hat\theta_k$에 해당 가중치 $w_k$를 곱하고 메타 분석에서 모든 연구의 결과 $K$를 합산한 다음 모든 개별 가중치의 합으로 나누면 됩니다.

$$\begin{equation}
\hat\theta = \frac{\sum^{K}_{k=1} \hat\theta_kw_k}{\sum^{K}_{k=1} w_k}
\tag{4.3}
\end{equation}$$

이 방법은 메타 분석에서 평균 효과를 계산하는 가장 일반적인 접근 방식입니다. 우리는 분산의 역수를 사용하기 때문에 역분산 가중치 또는 단순히 역분산 메타 분석이라고도 합니다.

이진 효과 크기 데이터의 경우 Mantel-Haenszel, Peto 또는 Bakbergenly(2020)의 표본 크기 가중치 방법을 포함하여 가중 평균을 계산하는 대체 방법이 있습니다. 이러한 방법은 4.2.3.1장에서 논의할 것입니다.

{meta} 패키지를 사용하면 고정 효과 메타 분석을 매우 쉽게 수행할 수 있습니다. 그러나 그 전에 R에서 "수동으로" 역분산 풀링을 시도해 보겠습니다. 이 예에서는 이미 2.4장에서 가져온 SuicidePrevention 데이터 세트를 사용합니다.

SuicidePrevention 데이터 세트에는 원시 효과 크기 데이터가 포함되어 있습니다. 즉, 효과 크기를 먼저 계산해야 합니다. 이 예에서는 소표본 조정 표준화 평균 차이(Hedges의 $g$)를 계산합니다. 이를 위해 {esc} 패키지(3.3.1.2장)의 esc_mean_sd 함수를 사용합니다.

이 함수에는 추가 인수 es.type이 있으며 이를 통해 소표본 수정이 수행되어야 함을 지정할 수 있습니다(es.type = "g" 설정, 3.4.1장).

```{r}
# Load dmetar, esc and tidyverse (for pipe)
# devtools::install_github("MathiasHarrer/dmetar")
library(dmetar)
library(esc)
library(tidyverse)

# Load data set from dmetar
data(SuicidePrevention)

# Calculate Hedges' g and the Standard Error
# - We save the study names in "study".
# - After that, we use the pipe operator to directly transform
#   the results to a data frame.
SP_calc <- esc_mean_sd(grp1m = SuicidePrevention$mean.e,
                       grp1sd = SuicidePrevention$sd.e,
                       grp1n = SuicidePrevention$n.e,
                       grp2m = SuicidePrevention$mean.c,
                       grp2sd = SuicidePrevention$sd.c,
                       grp2n = SuicidePrevention$n.c,
                       study = SuicidePrevention$author,
                       es.type = "g") %>% 
                     as.data.frame()

# Let us catch a glimpse of the data
# The data set contains Hedges' g ("es") and standard error ("se")
glimpse(SP_calc)
```
es: 효과 크기,
se: 표준 오류,
var: 효과 크기의 분산
ci.lo, ci.hi: 신뢰 하한 및 상한
w: 가중치 계수
total.n: 전체 샘플 크기 totaln입니다.


```{r}
# We now calculate the inverse variance-weights for each study
SP_calc$w <- 1/SP_calc$se^2

# Then, we use the weights to calculate the pooled effect
pooled_effect <- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)
pooled_effect
```
### 확률효과 모형
앞서 살펴보았듯이 고정 효과 모델은 메타 분석 데이터의 기원과 효과를 통합하는 방법을 개념화하는 한 가지 방법입니다. 그러나 중요한 질문은 이 접근 방식이 현실을 적절하게 반영하는가입니다.

고정 효과 모델은 우리의 모든 연구가 동질적인 모집단의 일부이며 관찰된 효과의 차이에 대한 유일한 원인은 연구의 샘플링 오류라고 가정합니다. 샘플링 오류 없이 각 연구의 효과 크기를 계산한다면 모든 실제 효과 크기는 완전히 동일할 것입니다.

이 개념을 빠른 현실 점검에 적용하면 고정 효과 모델의 가정이 많은 실제 응용 프로그램에서 너무 단순할 수 있음을 알 수 있습니다. 메타 분석의 연구가 항상 완전히 동질적이라는 것은 비현실적입니다. 비록 미묘한 방식일지라도 연구 결과는 매우 자주 다를 것입니다. 관심 결과는 다양한 방식으로 측정되었을 수 있습니다. 아마도 치료 유형이 정확히 동일하지 않았거나 치료 강도와 기간이 동일하지 않았을 수도 있습니다. 연구의 대상 모집단은 정확히 동일하지 않았을 수도 있고, 사용된 대조군에 차이가 있었을 수도 있습니다.

메타 분석의 연구는 이러한 측면 중 하나뿐만 아니라 동시에 여러 측면에 따라 달라질 가능성이 높습니다. 이것이 사실이라면, 우리는 실제 효과에서 연구 간 이질성이 상당할 것으로 예상할 수 있습니다.

이 모든 것이 고정 효과 모델의 타당성에 의문을 제기합니다. 예를 들어 일부 연구에서 다양한 유형의 치료법을 사용한 경우 한 가지 형식이 다른 형식보다 더 효과적인 것은 완전히 정상적인 것처럼 보입니다. 이러한 차이가 연구의 샘플링 오류로 인해 발생하는 잡음일 뿐이라고 가정하는 것은 무리입니다.

정반대로, 연구의 실제 효과 크기에 실제 차이가 존재하는 이유는 셀 수 없이 많습니다. 무작위 효과 모델은 이러한 문제를 해결합니다. 이는 데이터 이면의 현실을 훨씬 더 잘 반영하는 모델을 제공합니다.

무작위 효과 모델에서 우리는 효과 크기가 단일 동질 모집단에서 추출했을 때보다 더 많은 분산을 보인다는 사실을 설명하려고 합니다(L. V. Hedges and Vevea 1998). 따라서 우리는 개별 연구의 효과가 샘플링 오류만으로 인해 벗어날 뿐만 아니라 다른 분산 원인이 있다고 가정합니다.

이 추가적인 분산 구성요소는 연구가 단일 모집단에서 유래하지 않는다는 사실에 의해 도입됩니다. 대신, 각 연구는 인구의 "우주"에서 독립적인 추첨으로 간주됩니다.

* 랜덤효과모형은 하나의 실제 효과크기뿐만 아니라 실제 효과크기의 분포도 존재한다고 가정합니다. 따라서 무작위 효과 모델의 목표는 모든 연구의 하나의 실제 효과 크기를 추정하는 것이 아니라 실제 효과 분포의 평균을 추정하는 것입니다.

랜덤 효과 모델이 어떻게 공식으로 표현되는지 살펴보겠습니다. 고정 효과 모델과 유사하게 무작위 효과 모델은 관찰된 효과 크기 $\hat\theta_k$가 샘플링 오류 $\epsilon_k$로 인해 부담되는 연구의 실제 효과 크기 $\theta_k$의 추정자라고 가정하여 시작합니다.

$$\begin{equation}
\hat\theta_k = \theta_k + \epsilon_k 
\tag{4.4}
\end{equation}$$

$\theta$ 대신 $\theta_k$를 사용한다는 사실은 이미 중요한 차이점을 지적합니다. 무작위 효과 모델은 $\theta_k$가 하나의 단일 연구 $k$의 실제 효과 크기라고 가정합니다. $\zeta_k$로 표시되는 두 번째 오류 소스가 있음을 규정합니다. 이 두 번째 오류 원인은 $k$ 연구의 실제 효과 크기 $\theta_k$조차도 평균 $\mu$를 갖는 실제 효과 크기의 중요한 분포의 일부일 뿐이라는 사실로 인해 발생합니다.

$$\begin{equation}
\theta_k  = \mu + \zeta_k
\tag{4.5}
\end{equation}$$

무작위 효과 모델은 블랙박스 내부에서 발생하는 두 가지 프로세스의 계층 구조가 있음을 알려줍니다(S. G. Thompson, Turner 및 Warn 2001). 연구에서 관찰된 효과 크기는 샘플링 오류로 인해 실제 값에서 벗어납니다. 그러나 실제 효과 크기조차도 실제 효과의 세계에서 가져온 것일 뿐이며, 그 평균 $\mu$는 메타 분석의 통합 효과로 추정하고자 합니다.

두 번째 공식을 첫 번째 공식에 연결하면(즉, $\theta_k$를 두 번째 공식의 정의로 대체) 무작위 효과 모델을 한 줄로 표현할 수 있습니다(Borenstein et al. 2011, chap. 12).

$$\begin{equation}
\hat\theta_k = \mu + \zeta_k + \epsilon_k
\tag{4.6}
\end{equation}$$

이 공식을 사용하면 관찰된 효과 크기가 $\zeta_k$ 및 $\epsilon_k$라는 두 가지 오차항으로 인해 통합 효과 $\mu$에서 벗어난다는 것이 분명해집니다. 이 관계는 그림 4.2에 시각화되어 있습니다.

무작위 효과 모델의 중요한 가정은 $\zeta_k$의 크기가 $k$와 독립적이라는 것입니다. 다르게 말하면, 우리는 선험적으로 다음을 나타내는 것이 아무것도 없다고 가정합니다.
한 연구의 $\zeta_k$는 다른 연구보다 높습니다. 우리는 $\zeta_k$의 크기가 우연의 산물이고 우연일 뿐이라고 가정합니다.

이는 무작위 효과 모델의 교환 가능성 가정으로 알려져 있습니다(Julian Higgins, Thompson, and Spiegelhalter 2009; Lunn et al. 2012, chap. 10.1). 데이터를 보기 전에 $\zeta_k$가 일부 연구 $k$에서 얼마나 큰지 알 수 있는 것이 아무것도 없는 한 모든 실제 효과 크기는 교환 가능한 것으로 가정됩니다.

![Fig42](fig7.png)

그림 4.2: 무작위 효과 모델의 매개변수 그림.

## 3.2.R의 효과 크기 풀링

배운 내용을 실제로 적용해 볼 시간입니다. 이 장의 나머지 부분에서는 R에서 직접 다양한 효과 크기의 메타 분석을 실행할 수 있는 방법을 살펴보겠습니다. 이를 수행하는 데 사용할 {meta} 패키지는 특별한 구조를 가지고 있습니다. 여기에는 각각 한 가지 유형의 효과 크기 데이터에 초점을 맞춘 여러 메타 분석 기능이 포함되어 있습니다. 이러한 모든 기능에서 동일한 방식으로 지정할 수 있는 매개변수 세트가 있습니다. 예를 들어 고정 또는 무작위 효과 모델을 적용하려는 경우 또는 $\tau^2$ 추정기를 사용해야 하는 경우입니다. 그 외에도 특정 유형의 데이터에만 관련된 메타 분석의 세부 사항을 조정할 수 있는 기능별 인수가 있습니다.

그림 4.3은 {meta} 구조의 개요를 제공합니다. 어떤 함수를 사용할지 결정하려면 먼저 어떤 종류의 효과 크기 데이터를 합성할지 명확히 해야 합니다. 가장 근본적인 차이점은 원시 효과 크기 데이터와 사전 계산된 효과 크기 데이터 간의 차이입니다. 데이터 프레임에 원하는 효과 크기를 계산하는 데 필요한 모든 정보가 있지만 아직 실제 효과 크기를 계산하지 않은 경우 "원시" 데이터를 말합니다. 이전에 사용한 SuicidePrevention 데이터 세트에는 표준화된 평균 차이를 계산하는 데 필요한 두 그룹의 평균, 표준 편차 및 표본 크기와 같은 원시 데이터가 포함되어 있습니다.

반면에, 각 연구의 최종 효과 크기와 표준 오차가 이미 포함되어 있는 경우 효과 크기 데이터를 "사전 계산된" 데이터라고 부릅니다. 효과 척도의 수정된 버전(예: Hedges의 $g$, 3.4.1장)을 사용하려면 풀링을 시작하기 전에 미리 계산된 효과 크기 데이터에 이 수정이 이미 적용되어 있어야 합니다.


![Fig43](fig8.png)

가능하다면 메타 분석에는 원시 데이터를 사용하는 것이 좋습니다. 이렇게 하면 다른 사람들이 효과 크기 계산 방법을 더 쉽게 이해하고 결과를 재현할 수 있습니다. 그러나 연구 결과가 다른 방식으로 보고되는 경우가 많기 때문에 원시 데이터를 사용하는 것이 실제로 불가능한 경우가 많습니다(3.5.1장).

이로 인해 모든 연구에서 동일한 형식을 갖도록 각 연구에 대해 원하는 효과 크기를 즉시 미리 계산하는 것 외에 다른 선택의 여지가 없습니다. 이 책의 "유용한 도구" 부분의 17장에서는 보고된 효과 크기를 원하는 측정항목으로 변환하는 데 도움이 되는 몇 가지 공식을 제시합니다.

미리 계산된 효과 크기에 대해 선택되는 함수는 메타겐입니다. 그 이름은 일반적인 역분산 메타 분석을 의미합니다. 이진 데이터(예: 비율, 위험 비율, 승산비)와 함께 Metagen을 사용하는 경우 3.3.2장에서 다룬 것처럼 함수를 사용하기 전에 효과 크기를 로그 변환하는 것이 중요합니다.

원시 효과 크기 데이터에 의지할 수 있는 경우 {meta}는 각 효과 크기 유형에 대한 특수 기능을 제공합니다. 평균, (표준화된) 평균 차이 및 상관 관계에 대해 각각 Metamean, Metacont 및 Metacor 함수를 사용할 수 있습니다. Metarate, Metaprop 및 Metainc 함수를 사용하여 (발생률) 비율, 비율 및 발생률 비율을 통합할 수 있습니다. 위험비나 승산비를 다룰 때 메타빈 기능을 사용할 수 있습니다.

{meta}의 모든 메타 분석 함수는 동일한 구조를 따릅니다. 우리는 분석의 세부 사항을 제어하는 ​​추가 인수뿐만 아니라 (원시 또는 사전 계산된) 효과 크기 데이터를 함수에 제공해야 합니다. 각 함수에 지정할 수 있는 6개의 핵심 인수가 있습니다.


* studlab. 이 인수는 각 효과 크기를 연구 레이블과 연관시킵니다. 데이터 세트에 연구의 이름이나 저자가 저장되어 있는 경우 해당 열의 이름을 지정하기만 하면 됩니다(예: Studlab = 저자).

* sm. 이 인수는 메타 분석에 사용하려는 효과 크기 측정항목인 요약 측정값을 제어합니다. 이 옵션은 원시 효과 크기 데이터를 사용하는 함수에 특히 중요합니다. {meta} 패키지는 "SMD" 또는 "OR"과 같은 다양한 효과 크기 형식에 대한 코드를 사용합니다. 사용 가능한 요약 측정값은 각 기능마다 동일하지 않으며 다음 섹션에서는 각 경우에 가장 일반적인 옵션에 대해 설명합니다.

* fixed. 고정 효과 모델 메타 분석을 계산해야 하는지 나타내는 논리(TRUE 또는 FALSE)를 이 인수에 제공해야 합니다20.
무작위의. 비슷한 방식으로 이 인수는 무작위 효과 모델을 사용해야 하는지 여부를 제어합니다. Comb.fixed와 Comb.random이 모두 TRUE로 설정되면 두 모델이 모두 계산되어 표시됩니다21.

* method.tau. 이 인수는 $\tau^2$ 추정기를 정의합니다. 모든 함수는 이전 장에서 이미 제시한 다양한 추정기의 코드를 사용합니다(예: DerSimonian-Laird 방법: method.tau = "DL").

* hakn. 이것은 또 다른 논리적 주장이며 무작위 효과 모델을 사용할 때 Knapp-Hartung 조정을 적용해야 하는지 여부를 제어합니다.

* data. 이 인수에서는 메타 분석 데이터 세트의 이름과 함께 {meta}를 제공합니다.

* title(필수는 아님) 이 인수는 분석 이름이 포함된 문자열을 사용합니다. 이 주장에 대한 의견을 제공하는 것이 필수적인 것은 아니지만 나중에 분석을 식별하는 데 도움이 될 수 있습니다.

또한 나중 장에서 알게 될 몇 가지 추가 주장도 있습니다. 이 가이드에서는 {meta} 함수의 모든 인수를 논의할 수는 없습니다. 100개가 넘습니다.

고맙게도 이러한 인수의 대부분은 거의 필요하지 않거나 합리적인 기본값을 가지고 있습니다. 의심스러운 경우 R 콘솔에서 항상 함수 이름 앞에 물음표(예: ?metagen)를 붙여 실행할 수 있습니다. 그러면 함수 문서가 열립니다.


### 사전 계산된 효과 크기 데이터
Metagen을 사용하여 메타 분석 기능 둘러보기를 시작하겠습니다. 우리가 배운 대로 이 함수는 미리 계산된 효과 크기 데이터에 사용될 수 있습니다. 첫 번째 예에서는 이 기능을 사용하여 ThirdWave 데이터 세트의 메타 분석을 수행합니다.

이 데이터 세트에는 대학생의 인지된 스트레스에 대한 소위 "제3의 물결" 심리 치료의 효과를 조사한 연구가 포함되어 있습니다. 각 연구에 대해 사후 테스트에서 치료군과 대조군 간의 표준화된 평균 차이를 계산하고 작은 표본 보정을 적용했습니다. 따라서 이 메타 분석에 사용된 효과 크기 측정값은 Hedges의 $g$입니다. 데이터를 살펴 보겠습니다.

```{r}
library(tidyverse) # needed for 'glimpse'
library(dmetar)
library(meta)

data(ThirdWave)
glimpse(ThirdWave)
```

데이터 세트에는 8개의 열이 있으며 그 중 가장 중요한 것은 Author, TE 및 seTE입니다. TE 열에는 각 연구의 $g$ 값이 포함되어 있으며, seTE는 $g$의 표준 오차입니다. 다른 열은 각 연구가 속하는 하위 그룹 범주를 설명하는 변수를 나타냅니다. 이 변수는 현재로서는 관련이 없습니다.

이제 우리가 수행하려는 메타 분석 유형에 대해 생각해 볼 수 있습니다. 하위 그룹 열을 살펴보면 적어도 편견 위험, 통제 그룹, 개입 기간, 개입 유형 및 전달 방식과 관련하여 연구가 다양하다는 것을 알 수 있습니다.

이는 연구 간 이질성이 어느 정도 예상될 수 있으며 모든 연구가 고정된 실제 효과를 갖는다고 가정하는 것이 의미가 없다는 점을 매우 분명하게 만듭니다. 따라서 우리는 풀링을 위해 무작위 효과 모델을 사용할 수 있습니다. 연속 결과 데이터의 강력한 성능을 고려하여 이 예에서는 제한된 최대 우도("REML") 추정기를 선택합니다. 또한 Knapp-Hartung 조정을 사용하여 위양성 결과의 위험을 줄일 것입니다.

이제 이러한 근본적인 질문이 해결되었으므로 Metagen 호출에 대한 사양이 매우 간단해졌습니다. 함수를 사용할 때 항상 지정해야 하는 두 가지 함수별 인수가 있습니다.

* 테. 계산된 효과 크기가 포함된 데이터 세트의 열 이름입니다.

* 세트. 효과크기의 표준오차가 저장되는 컬럼의 이름이다.


나머지는 지난 장에서 이미 다룬 일반 {meta} 인수입니다. 분석에서는 표준화된 평균 차이를 다루므로 sm = "SMD"도 지정합니다. 그러나 이 예에서는 각 연구에 대해 효과 크기가 이미 계산되어 있으므로 이는 결과에 실제 영향을 미치지 않습니다. 출력에서 효과 크기를 SMD로 표시하도록 함수에 지시할 뿐입니다.

이는 Metagen에 대한 첫 번째 호출을 설정하는 데 필요한 모든 정보를 제공합니다. 함수의 결과를 m.gen이라는 객체에 저장하겠습니다.

```{r}
m.gen <- metagen(TE = TE,
                 seTE = seTE,
                 studlab = Author,
                 data = ThirdWave,
                 sm = "SMD",
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Third Wave Psychotherapies")
```

이제 m.gen 개체에는 모든 메타 분석 결과가 포함됩니다. 개요를 얻는 쉬운 방법은 요약 기능을 사용하는 것입니다.

```{r}
summary(m.gen)
```

이제 R을 사용한 첫 번째 메타 분석 결과가 나옵니다. 풀어야 할 내용이 많기 때문에 출력을 단계별로 살펴보겠습니다.

* 출력의 첫 번째 부분에는 효과 크기 및 신뢰 구간과 함께 개별 연구가 포함됩니다. 효과가 미리 계산되었으므로 여기서는 새로운 내용을 확인할 수 없습니다. %W(무작위) 열에는 무작위 효과 모델이 각 연구에 부여한 가중치(백분율)가 포함됩니다. 메타 분석에서 7.9%로 가장 큰 비중을 차지하는 것은 de Vibe의 연구입니다. Ratanasiripong의 연구에는 가장 작은 가중치가 부여되었습니다. 이 연구의 신뢰구간을 살펴보면 왜 그런 것인지 알 수 있습니다. 통합 효과 주변의 CI는 매우 넓습니다. 이는 표준 오차가 매우 높고 따라서 연구의 효과 크기 추정치가 그다지 정확하지 않음을 의미합니다.

* 또한 결과는 메타 분석의 총 연구 수를 알려줍니다. $K= 18$ 연구가 결합된 것을 볼 수 있습니다.

* 다음 섹션에서는 핵심 결과인 통합 효과 크기를 제공합니다. 추정치는 $g \about 0.58$이고 95% 신뢰 구간의 범위는 $g \about 0.38$에서 $0.78$까지입니다. 또한 효과 크기가 유의한지 확인하는 테스트 결과도 제시됩니다. ($p < 0.001$)이 그렇습니다. 중요한 것은 $t$로 표시되는 관련 테스트 통계도 볼 수 있다는 것입니다. 이는 우리가 Knapp-Hartung 조정을 적용했기 때문입니다.
$t$-분포.

* 아래에는 연구 간 이질성에 관한 결과가 나와 있습니다. 여기에 표시된 결과 중 일부에 대해서는 이후 장에서 자세히 알아볼 것이므로 $\tau^2$에만 집중하겠습니다. tau^2 옆에는 실제 효과의 분산 추정치가 $\tau^2 = 0.08$로 표시됩니다. tau^2의 신뢰 구간에는 0(0.03–0.35)이 포함되지 않으며, 이는 $\tau^2$가 0보다 훨씬 크다는 것을 의미합니다. 이 모든 것은 연구 간 이질성이 데이터에 존재하며 무작위 효과 모델이 좋은 선택임을 나타냅니다.

* 마지막 섹션에서는 메타분석에 대한 세부정보를 제공합니다. 역분산 방법을 사용하여 효과를 통합하고, 제한된 최대 우도 추정기를 사용하고, Knapp-Hartung 조정을 적용한 것을 확인합니다.

m.gen에 저장된 정보에 직접 접근할 수도 있습니다. {meta}에서 생성된 메타 분석 결과에는 기본적으로 많은 개체가 저장되며 문서의 "값" 섹션을 살펴보면 그 의미가 무엇인지 알 수 있습니다. $ 연산자를 사용하여 분석의 특정 결과를 인쇄할 수 있습니다. 예를 들어, 통합 효과는 TE.random으로 저장됩니다.

```{r}
m.gen$TE.random
```
fixed = FALSE를 지정하는 경우에도 {meta}의 함수는 항상 내부적으로 고정 효과 모델에 대한 결과를 계산합니다. 따라서 고정 효과 모델을 가정하여 통합 효과에 접근할 수도 있습니다.
```{r}
m.gen$TE.fixed
```
우리는 이 추정치가 확률효과 모형 결과와 상당히 다르다는 것을 알 수 있습니다.

분석의 일부 세부 사항을 조정하려는 경우 update.meta 기능이 도움이 될 수 있습니다. 이 함수에는 입력으로 {meta} 개체와 변경하려는 인수가 필요합니다. 제한된 최대 우도 추정기 대신 Paule-Mandel을 사용하면 결과가 크게 다른지 확인하고 싶다고 가정해 보겠습니다. 다음 코드를 사용하여 그렇게 할 수 있습니다.

```{r}
library(meta)
m.gen_update <- update(m.gen, 
                            method.tau = "PM")

# Get pooled effect
m.gen_update$TE.random
```
```{r}
# Get tau^2 estimate
m.gen_update$tau2
```
합동 효과는 크게 다르지 않지만 Paule-Mandel 추정기는 약간 더 큰 $\tau^2$ 근사치를 제공합니다.

마지막으로 나중에 결과를 저장해 두는 것이 항상 도움이 됩니다. {meta}에 의해 생성된 객체는 저장 기능을 사용하여 .rda(R 데이터) 파일로 쉽게 저장할 수 있습니다.

```{r}
# save(m.gen, file = "path/to/my/meta-analysis.rda") # example path
```

###(표준화) 평균 차이
두 그룹의 평균 및 표준 편차 형태의 원시 효과 크기 데이터는 메타콘트를 사용하여 통합될 수 있습니다. 이 함수는 표준화된 그룹과 표준화되지 않은 그룹 간 평균 차이 모두에 사용할 수 있습니다. 이는 sm = "SMD" 또는 sm = "MD"를 지정하여 얻을 수 있습니다. 그렇지 않으면 제공해야 하는 7개의 함수별 인수가 있습니다.

* n.e. 치료/실험 그룹의 관찰 횟수입니다.

* mean.e. 치료/실험 그룹의 평균입니다.

* sd.e. 치료/실험군의 표준편차입니다.

* n.c.. 통제그룹의 관측치 수입니다.

* mean.c. 대조군의 평균입니다.

* SD.C. 통제그룹의 표준편차입니다.

* 메소드.smd. 이는 sm = "SMD"인 경우에만 관련됩니다. Metacont 기능을 사용하면 세 가지 다른 유형의 표준화된 평균 차이를 계산할 수 있습니다. method.smd = "Cohen"으로 설정하면 수정되지 않은 표준화 평균 차이(Cohen의
$d$)가 효과 크기 측정항목으로 사용됩니다. 다른 두 가지 옵션은 Hedges'$g$를 계산하는 "Hedges"(기본값 및 권장)와 Glass'$\Delta$(delta)를 계산하는 "Glass"입니다. Glass의 $\Delta$는 합동 표준 편차 대신 통제 그룹 표준 편차를 사용하여 평균 차이를 표준화합니다. 이 효과 크기는 치료 그룹이 두 개 이상인 경우 1차 연구에서 때때로 사용되지만 일반적으로 메타 분석에서 선호되는 측정 항목은 아닙니다.

예시 분석을 위해 SuicidePrevention 데이터 세트를 재활용합니다. 우리 표본의 모든 연구가 완전히 동일한 것은 아니므로 무작위 효과 모델을 사용하는 것이 좋습니다. 또한 $\tau^2$에 대한 제한된 최대 우도 추정량뿐만 아니라 Knapp-Hartung 조정도 다시 사용할 것입니다. 우리는 Metacont에게 소표본 편향을 수정하도록 지시하여 Hedges의 $g$를 효과 크기 지표로 생성합니다. 결과는 m.cont라는 개체에 저장됩니다.

전반적으로 우리 코드는 다음과 같습니다.

```{r}
# Make sure meta and dmetar are already loaded
library(meta)
library(dmetar)
library(meta)

# Load dataset from dmetar (or download and open manually)
data(SuicidePrevention)

# Use metcont to pool results.
m.cont <- metacont(n.e = n.e,
                   mean.e = mean.e,
                   sd.e = sd.e,
                   n.c = n.c,
                   mean.c = mean.c,
                   sd.c = sd.c,
                   studlab = author,
                   data = SuicidePrevention,
                   sm = "SMD",
                   method.smd = "Hedges",
                   fixed = FALSE,
                   random = TRUE,
                   method.tau = "REML",
                   hakn = TRUE,
                   title = "Suicide Prevention")
```

결과가 무엇인지 살펴보겠습니다.

```{r}
summary(m.cont)
```


출력을 보고 4.2.1장에서 받은 출력과 비교하면 이미 {meta}의 가장 큰 자산 중 하나를 볼 수 있습니다. Metagen과 Metacont는 서로 다른 데이터 유형을 요구하는 서로 다른 기능이지만 출력 구조는 거의 동일해 보입니다. 이렇게 하면 결과를 해석하기가 매우 쉽습니다. 무작위 효과 모델에 따른 통합 효과는 $g= -0.23$이며 95% 신뢰 구간 범위는 -0.09에서 -0.37입니다. 효과는 상당합니다($p= 0.006$).

효과 크기에 음의 부호가 있음을 알 수 있습니다. 우리의 메타 분석의 맥락에서 이는 유리한 결과를 나타냅니다. 왜냐하면 이는 대조군에 비해 치료군에서 자살 생각이 더 낮았음을 의미하기 때문입니다. 이를 다른 사람들에게 더 명확하게 하기 위해 효과 크기의 부호를 일관되게 반전시켜(예: $g= 0.23$ 대신 쓰기) 긍정적인 효과 크기가 항상 "긍정적인" 결과를 나타내도록 할 수도 있습니다.

제한된 최대 우도 방법은 $\tau^2 = 0.004$의 연구 간 이질성 분산을 추정했습니다. tau^2를 보면 신뢰 구간에 0이 포함되어 있음을 알 수 있습니다. 이는 실제 효과 크기의 분산이 0보다 크게 크지 않음을 의미합니다.

세부 정보 섹션에서는 요청한 대로 Hedges의 $g$가 효과 크기 측정항목으로 사용되었음을 알 수 있습니다.

### R에서 이진 효과 크기 풀링
Metabin에는 8개의 중요한 함수별 인수가 있습니다.

* event.e. 치료/실험 그룹의 사건 수.

* n.e. 치료/실험 그룹의 관찰 횟수입니다.

* event.c. 통제그룹의 이벤트 수입니다.

* n.c. 통제그룹의 관측치 수입니다.

* method. 사용할 풀링 방법입니다. 이는 "역"(일반 역분산 풀링), "MH"(Mantel-Haenszel, 기본값 및 권장), "Peto"(Peto 방법) 또는 "SSW"(Bakbergenly-샘플 크기 방법, sm인 경우에만)일 수 있습니다. = "또는").

* sm. 계산할 요약 측정값(즉, 효과 크기 측정항목)입니다. 위험 비율에는 "RR"을 사용하고 승산비에는 "OR"을 사용할 수 있습니다.

* incr 증분 제로 셀의 연속성 수정을 위해 추가되는 증분입니다. incr = 0.5로 지정하면 0.5씩 증가합니다. incr = "TACC"로 설정하면 치료 팔 연속성 수정 방법이 사용됩니다(3.3.2.1장 참조). 앞서 언급했듯이 일반적으로 이 인수를 생략하고 연속성 수정을 적용하지 않는 것이 좋습니다.

*  MH.exact. method = "MH"인 경우 이 인수를 TRUE로 설정할 수 있으며 이는 Mantel-Haenszel 방법에 연속성 수정이 사용되는 것을 원하지 않음을 나타냅니다.

실습 예제에서는 DepressionMortality 데이터 세트를 사용합니다. 이 데이터 세트는 우울증이 모든 원인으로 인한 사망률에 미치는 영향을 조사한 Cuijpers 및 Smit(2002)의 메타 분석을 기반으로 합니다. 데이터 세트에는 우울증이 있는 개인과 없는 개인의 수, 두 그룹 모두 몇 년 후에 사망한 개인의 수가 포함되어 있습니다.

먼저 데이터 세트를 살펴보겠습니다.

```{r}
library(dmetar)
library(tidyverse)
library(meta)

data(DepressionMortality)
glimpse(DepressionMortality)
```
이 예에서는 Cuijpers와 Smit가 수행한 것처럼 위험 비율을 효과 크기 측정 기준으로 계산합니다. 우리는 랜덤 효과 풀링 모델을 사용할 것이며, 이진 결과 데이터를 다루기 때문에 $\tau^2$에 대해 Paule-Mandel 추정기를 사용할 것입니다.

데이터를 살펴보면 표본 크기가 연구마다 상당히 다양하며 Paule-Mandel 방법이 약간 편향될 수 있는 시나리오를 알 수 있습니다(4.1.2.1장 참조). 이를 염두에 두고 민감도 분석으로 다른 $\tau^2$ 추정기를 사용해 결과가 많이 달라지는지 확인할 수도 있습니다.

데이터 세트에는 0 셀이 포함되어 있지 않으므로 연속성 수정에 대해 걱정할 필요가 없으며 정확한 Mantel-Haenszel 방법을 바로 사용할 수 있습니다. 메타 분석 결과를 m.bin이라는 개체에 저장합니다.

```{r}
m.bin <- metabin(event.e = event.e, 
                 n.e = n.e,
                 event.c = event.c,
                 n.c = n.c,
                 studlab = author,
                 data = DepressionMortality,
                 sm = "RR",
                 method = "MH",
                 MH.exact = TRUE,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "PM",
                 hakn = TRUE,
                 title = "Depression and Mortality")
summary(m.bin)
```

통합 효과 크기는 RR = 2.02임을 알 수 있습니다. 통합 효과는 유의미하며($p< 0.001$), 우울증으로 고통받는 경우 사망 위험이 두 배로 증가한다는 것을 나타냅니다. 연구 간 이질성 분산에 대한 추정치는 $\tau^2 \about 0.19$입니다. $\tau^2$의 신뢰 구간에는 0이 포함되지 않으며 이는 연구 간의 상당한 이질성을 나타냅니다. 마지막으로 출력의 세부 정보 섹션을 살펴보면 Metabin 함수가 의도한 대로 풀링을 위해 Mantel-Haenszel 방법을 사용했음을 알 수 있습니다.

위에서 발표한 것처럼 $\tau^2$를 추정하는 데 사용된 방법이 결과에 영향을 미치는지 살펴보겠습니다. update.meta 함수를 사용하여 분석을 다시 실행하지만 이번에는 제한된 최대 우도 추정기를 사용합니다.

```{r}
m.bin_update <- update(m.bin, 
                            method.tau = "REML")
```

이제 TE.random을 검사하여 풀링 효과를 다시 살펴보겠습니다. 여기서 우리는 이진 결과의 메타 분석이 실제로 효과 크기의 로그 변환 버전을 사용하여 수행된다는 점을 기억해야 합니다. 결과를 제시할 때 Metabin은 편의를 위해 효과 크기 측정항목을 원래 형식으로 다시 변환합니다. 메타 분석 개체의 요소를 검사하는 경우에는 이 단계가 수행되지 않습니다.

로그 변환된 효과 크기를 재변환하려면 값을 지수화해야 합니다. 지수화는 로그 변환 데이터의 "길항제"로 볼 수 있으며 R에서 exp 함수를 사용하여 수행할 수 있습니다24. 이것을 실천해 봅시다.

```{r}
exp(m.bin_update$TE.random)
```
제한된 최대 우도 추정기를 사용한 통합 효과가 사실상 동일하다는 것을 알 수 있습니다. 이제 $\tau^2$의 추정치를 살펴보겠습니다.


```{r}
m.bin_update$tau2
```
이 값은 다소 벗어나지만 초기 결과의 유효성을 걱정할 정도는 아닙니다.

풀 승산비를 결정했다면 Metabin에 대한 호출은 완전히 동일해 보였을 것입니다. 우리가 변경해야 할 유일한 것은 "OR"로 설정되어야 하는 sm 인수입니다. 전체 함수 호출을 한 번 더 기록하는 대신 update.meta 함수를 다시 사용하여 풀링된 OR을 계산할 수 있습니다.

```{r}
m.bin_or <- update(m.bin, sm = "OR")
m.bin_or
```
출력에서 승산비를 사용한 합동 효과는 OR = 2.29임을 알 수 있습니다.

### 미리 계산된 이진 효과 크기 풀링
각 연구에서 위험 또는 승산비를 계산하는 데 필요한 원시 효과 크기 데이터를 추출하는 것이 때로는 불가능합니다. 예를 들어, 1차 연구에서는 승산비를 보고할 수 있지만 이 효과 크기의 기반이 되는 데이터는 보고하지 않을 수 있습니다. 저자가 원본 데이터를 제공하지 않는 경우 사전 계산된 효과 크기 데이터를 기반으로 메타 분석을 수행해야 할 수도 있습니다. 우리가 배웠듯이 이를 수행하는 데 사용할 수 있는 기능은 Metagen입니다.

이진 결과 데이터를 다룰 때 미리 계산된 효과 크기 데이터를 사용하는 것 외에 다른 옵션이 없다면 정말 주의해야 합니다. Metagen 함수는 효과 크기를 합치기 위해 역분산 방법을 사용하며 Mantel-Haenszel 접근법과 같은 더 나은 옵션을 사용할 수 없습니다. 그러나 다른 모든 것이 실패하더라도 여전히 실행 가능한 대안입니다.

DepressionMortality 데이터 세트를 사용하여 사전 계산된 효과 크기 메타 분석을 다루고 있음을 시뮬레이션해 보겠습니다. m.bin에서 TE 및 seTE 객체를 추출하여 각 연구의 효과 크기와 표준 오차를 얻을 수 있습니다. 우리는 이 정보를 DepressionMortality 데이터 세트에 저장합니다.


```{r}
DepressionMortality$TE <- m.bin$TE
DepressionMortality$seTE <- m.bin$seTE
```

이제 신뢰 구간의 하한과 상한은 알지만 표준 오차는 모르는 효과가 하나 있다고 가정해 보겠습니다. 이러한 시나리오를 시뮬레이션하기 위해 (1) 연구 7(Murphy et al., 1987)의 표준 오차를 누락된 것으로 정의하고(즉, 해당 값을 NA로 설정), (2) 두 개의 새로운 빈 열(하위 및 상한)을 정의합니다. (3) 연구 7에서 로그 변환된 "보고된" 신뢰 구간으로 하한값과 상한값을 채웁니다.

```{r}
# Set seTE of study 7 to NA
DepressionMortality$seTE[7] <- NA

# Create empty columns 'lower' and 'upper'
DepressionMortality[,"lower"] <- NA
DepressionMortality[,"upper"] <- NA

# Fill in values for 'lower' and 'upper' in study 7
# As always, binary effect sizes need to be log-transformed
DepressionMortality$lower[7] <- log(1.26)
DepressionMortality$upper[7] <- log(2.46)
```

이제 방금 생성한 데이터를 살펴보겠습니다.
```{r}
DepressionMortality[,c("author", "TE", "seTE", "lower", "upper")]
```
실제로 이와 같은 데이터 세트를 찾는 것은 드문 일이 아닙니다. 대부분의 연구에서는 로그-위험 비율을 계산하는 것이 가능할 수 있지만, 다른 몇몇 연구의 경우 우리가 흔히 가지고 있는 유일한 정보는 (로그 변환된) 위험 비율과 신뢰 구간뿐입니다.

다행스럽게도 Metagen을 사용하면 그러한 데이터도 통합할 수 있습니다. 하한인수와 상한인수에는 신뢰구간의 하한과 상한이 포함된 열의 이름만 제공하면 됩니다. 그런 다음 Metagen 함수는 이 정보를 사용하여 표준 오류를 사용할 수 없을 때 효과에 가중치를 부여합니다. 함수 호출은 다음과 같습니다:

```{r}
m.gen_bin <- metagen(TE = TE,
                     seTE = seTE,
                     lower = lower,
                     upper = upper,
                     studlab = author,
                     data = DepressionMortality,
                     sm = "RR",
                     method.tau = "PM",
                     fixed = FALSE,
                     random = TRUE,
                     title = "Depression Mortality (Pre-calculated)")

summary(m.gen_bin)
```

출력에서 우리는 모든 $K= 18$ 연구를 메타 분석에서 결합할 수 있음을 알 수 있습니다. 이는 Metagen이 연구 7에 제공된 하위 및 상위 정보를 사용했음을 의미합니다. 출력은 또한 역분산 방법을 사용한 결과를 보여줍니다. 이전의 Mantel-Haenszel 방법과 거의 동일하다.

### 발생률 비율
발생률(예: 발생률 비율, 3.3.3장)을 기반으로 한 효과 크기는 metainc 함수를 사용하여 통합할 수 있습니다. 이 함수의 인수는 Metabin과 매우 유사합니다.

* event.e: 치료/실험군에서 발생한 사건의 수.

* time.e: 치료/실험군에서 위험에 처한 사람-시간.

* event.c: 대조군의 이벤트 수입니다.

* time.c: 통제그룹에서 위험에 처한 사람-시간.

* method: 메타빈과 마찬가지로 기본 풀링 방법은 Mantel and Haenszel("MH")의 방법입니다. 또는 일반 역분산 풀링("역")을 사용할 수도 있습니다.

* sm: 요약 측정값. 발생률 비율("IRR")과 발생률 차이("IRD") 중에서 선택할 수 있습니다.

* incr: 0 셀의 연속성 수정을 위해 추가하려는 증분입니다.

Metabin과 달리, metainc는 기본적으로 연속성 보정을 사용하지 않습니다. 따라서 MH.exact를 TRUE로 지정할 필요가 없습니다. 연속성 수정은 일반적인 역분산 풀링 방법(방법 = "역")을 선택한 경우에만 수행됩니다.

실습 예에서는 EatingDisorderPrevention 데이터 세트를 사용합니다. 이 데이터는 섭식 장애 발생률에 대한 대학 기반 예방 개입의 효과를 조사한 메타 분석을 기반으로 합니다(Harrer et al. 2020). 위험에 처한 사람-시간은 이 데이터 세트에서 사람-년으로 표시됩니다.

언제나 그렇듯이 먼저 데이터를 살펴보겠습니다.

```{r}
library(dmetar)
library(tidyverse)
library(meta)

data(EatingDisorderPrevention)

glimpse(EatingDisorderPrevention)
```
우리는 효과 크기 측정 기준으로 발생률 비율을 사용하여 효과 크기 데이터를 모으기 위해 metainc를 사용합니다. Mantel-Haenszel 방법은 풀링에 사용되며 Paule-Mandel 추정기는 연구 간 이질성 분산을 계산하는 데 사용됩니다.

```{r}
m.inc <- metainc(event.e = event.e, 
                 time.e = time.e,
                 event.c = event.c,
                 time.c = time.c,
                 studlab = Author,
                 data = EatingDisorderPrevention,
                 sm = "IRR",
                 method = "MH",
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "PM",
                 hakn = TRUE,
                 title = "Eating Disorder Prevention")

summary(m.inc)
```

합동 효과는 IRR = 0.62임을 알 수 있습니다. 이 효과는 유의미합니다($p= 0.04$). 비록 이전 예보다 기존의 유의성 임계값에 다소 더 가깝습니다. 통합 효과를 바탕으로 예방적 중재를 통해 1년 이내에 섭식 장애 발병률이 38% 감소했다고 말할 수 있습니다. 마지막으로 이질성 분산 $\tau^2$의 추정치는 0이라는 것을 알 수 있습니다.

### 상관관계
일반 역분산 풀링 방법을 사용하는 Metacor 함수를 사용하여 상관관계를 풀링할 수 있습니다. 3.2.3.1장에서 우리는 상관 관계가 Fisher의 $z$여야 함을 다루었습니다.
-풀링 전에 변형되었습니다. 기본적으로 Metacor는 이 변환을 자동으로 수행합니다. 따라서 연구에서 보고된 원래의 변환되지 않은 상관 관계를 함수에 제공하는 것으로 충분합니다. Metacor 함수에는 관련 함수별 인수가 두 개만 있습니다.

* cor. (변환되지 않은) 상관 계수입니다.

* n. 연구의 관측치 수입니다.

Metacor의 기능을 설명하기 위해 HealthWellbeing 데이터 세트를 사용하겠습니다. 이 데이터 세트는 건강과 웰빙 사이의 연관성을 조사한 대규모 메타 분석을 기반으로 합니다(Ngamaba, Panagioti 및 Armitage 2017).

데이터를 살펴보겠습니다.

```{r}
library(dmetar)
library(tidyverse)
library(meta)

data(HealthWellbeing)
glimpse(HealthWellbeing)
```
우리는 이 메타 분석에서 연구 간 이질성이 상당할 것으로 예상하므로 무작위 효과 모델이 사용됩니다. $\tau^2$에는 제한된 최대 우도 추정기가 사용됩니다.

```{r}
m.cor <- metacor(cor = cor, 
                 n = n,
                 studlab = author,
                 data = HealthWellbeing,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Health and Wellbeing")
summary(m.cor)
```

우리는 건강과 웰빙 간의 통합 연관성이 $r= 0.36$이고 이 효과가 유의미하다는 것을 알 수 있습니다($p< 0.001$). Cohen의 관례를 사용하면 이는 중간 규모의 상관 관계로 간주될 수 있습니다.

출력에서 Metacor는 이미 Fisher의 $z$ 변환된 상관 관계를 원래 형식으로 다시 변환했습니다. 그러나 세부 정보 섹션의 마지막 줄을 보면 $z$-값이 실제로 효과를 모으는 데 사용되었음을 알 수 있습니다. 마지막으로, 이 메타 분석에 대해 추정된 이질성 분산이 0보다 훨씬 크다는 것을 알 수 있습니다.

### 평균
Metamean 함수를 사용하여 평균의 메타 분석을 수행할 수 있습니다. 이 함수는 일반적인 역분산 방법을 사용하여 데이터를 통합합니다. 메타평균을 사용할 때 원시 평균 또는 로그 변환 평균에 대한 메타 분석을 수행할지 먼저 결정해야 합니다.

확률 및 위험 비율과 달리 평균의 로그 변환은 일반적으로 필요하지 않습니다. 그러나 음수가 아닌 양(예: 높이)의 평균을 처리할 때와 일부 평균이 0에 가까울 때 변환을 사용하는 것이 좋습니다. 이는 sm 인수를 통해 제어됩니다. sm = "MRAW로 설정하면 원시 평균이 풀링됩니다. sm = "MLN"일 때 로그 변환이 수행됩니다. 함수별 인수는 다음과 같습니다.


* n: 관찰 횟수.

* mean: 평균.

* sd: 평균의 표준편차.

* sm: 풀링에 사용되는 요약 측정 유형입니다(위 참조).

실습 예제에서는 BdiScores 데이터 세트를 사용합니다. 이 데이터 세트에는 심리 치료 및 항우울제 시험에 참여한 우울증 환자의 샘플에서 측정된 Beck Depression Inventory II(Beck, Steer, and Brown 1996)의 평균 점수가 포함되어 있습니다(Furukawa et al. 2020).

```{r}
library(dmetar)
library(tidyverse)
library(meta)
data(BdiScores)

# We only need the first four columns
glimpse(BdiScores[,1:4])
```

우리의 목표는 이 연구 모음을 기반으로 전반적인 평균 우울증 점수를 계산하는 것입니다. 우리는 데이터 세트의 원시 평균을 모으기 위해 무작위 효과 모델과 제한된 최대 가능성 추정기를 사용합니다. 결과를 m.mean이라는 개체에 저장합니다.

```{r}
m.mean <- metamean(n = n,
                   mean = mean,
                   sd = sd,
                   studlab = author,
                   data = BdiScores,
                   sm = "MRAW",
                   fixed = FALSE,
                   random = TRUE,
                   method.tau = "REML",
                   hakn = TRUE,
                   title = "BDI-II Scores")
summary(m.mean)
```
랜덤 효과 모델을 가정한 합동 평균은 $m = 31.12$입니다. 또한 이 메타 분석에서 연구 간 이질성 분산 $\tau^2$이 0보다 훨씬 크다는 것을 알 수 있습니다.

### 비율
Metaprop 함수는 비율을 모으는 데 사용할 수 있습니다. 3.2.2장에서 메타 분석을 수행하기 전에 비율을 로짓 변환하는 것이 가장 좋다는 점을 이미 논의했습니다. sm = "PLOGIT"를 지정하면 Metaprop 함수가 자동으로 이 작업을 수행합니다. 원시 비율을 모아야 하는 경우 sm = "PRAW"를 사용할 수 있지만 이는 권장되지 않는다는 점을 기억하세요.

메타프롭이 비율을 모으는 기본 방법은 다소 특별합니다. 로짓 변환된 값을 사용하는 경우 함수는 풀링에 역분산 방법을 사용하지 않고 일반화된 선형 혼합 효과 모델(GLMM)을 구축합니다. 기본적으로 이 함수는 연구마다 실제 효과 크기가 다르다는 사실을 설명하기 위해 무작위 효과를 포함하는 로지스틱 회귀 모델을 데이터에 적합합니다.

이전에 "혼합 효과 모델"이라는 용어를 들어보셨을 것입니다. 이러한 모델은 다양한 연구 분야의 1차 연구에서 일반적으로 사용됩니다. 7장과 8장에서는 혼합효과 모형의 특수한 응용인 부분군 분석과 메타회귀에 대해 논의하면서 이 주제를 좀 더 깊이 살펴보겠습니다. 그러나 지금은 혼합 효과 모델이 무엇인지에 대한 일반적인 개념을 이해하는 것만으로도 충분합니다.

혼합 효과 모델은 "고정" 구성 요소와 "무작위" 구성 요소를 모두 포함하는 회귀 모델입니다. 고정 요소는 $\beta$ 가중치입니다. 매우 간단한 회귀 모델에는 두 개의 $\beta$ 항이 포함되어 있습니다. 절편 $\beta_0$ 및 회귀 항 $\beta_1 x$. 이들은 다른 수량 $x$를 통해 관찰된 데이터 $y$를 예측하기 위해 조합되어 사용됩니다. 이 예측은 거의 완벽하지 않으며 임의의 오류 $\epsilon_i$가 남습니다. 이를 종합하면 다음 공식이 제공됩니다.


$$\begin{equation}
{y}_i = {\beta_0} + {\beta_1}x_i +  \epsilon_i
\tag{4.16}
\end{equation}$$

중요한 점은 이 방정식의 $\beta$ 가중치 값이 각 관측값 $i$에 대해 동일하게 유지된다는 것입니다. $x$의 값은 관찰마다 다를 수 있지만 $\beta_0$ 및 $\beta_1$은 고정되어 있으므로 절대 그렇지 않습니다.

이 회귀 방정식은 무작위 효과를 추가하면 혼합 효과 모델로 바뀔 수 있습니다. 우리는 이 무작위 효과 항을 $u_i$로 표시합니다. 아래 첨자 $i$로 표시되는 것처럼 랜덤 효과 항은 각 관측값에 대해 서로 다른 값을 가질 수 있습니다. $u_i$ 항은 0을 중심으로 하며 고정 효과에 의해 생성된 추정치를 늘리거나 줄일 수 있습니다.

$$\begin{equation}
{y}_i = {\beta_0} + {\beta_1}x_i + u_i + \epsilon_i
\tag{4.17}
\end{equation}$$

메타 분석은 $\beta_1 x_i$ 항이 없는 이 모델의 특별한 유형으로 볼 수 있습니다. 모델에는 랜덤 효과 모델의 전체 효과 크기 $\mu$에 해당하는 절편 $\beta_0$만 포함되어 있습니다. $u_i$ 및 $\epsilon_i$ 부분은 메타 분석의 $\zeta_k$ 및 $\epsilon_k$ 오류 용어에 해당합니다. 이를 통해 메타 분석이 혼합 효과 회귀 모델과 동일하다는 것이 분명해졌습니다. 그러나 이 혼합 효과 모델에는 절편과 해당 절편에 연결된 무작위 효과만 포함됩니다. 따라서 이항 로짓-링크25를 사용하여 (일반화된) 로지스틱 혼합 효과 모델을 적용하여 합동 효과를 추정할 수 있습니다.

GLMM은 비율뿐만 아니라 승산비나 발생률 비율과 같은 이진 및 개수 데이터를 기반으로 하는 다른 결과 측정에도 적용될 수 있습니다(Stijnen, Hamza, and Özdemir 2010). GLMM은 이진 결과 데이터의 메타 분석에 보편적으로 권장되지는 않지만(Bakbergenuly 및 Kulinskaya 2018) 비율에 대해서는 사용이 옹호되었습니다(Schwarzer et al. 2019).

Metaprop의 일부로 GLMM을 사용하면 세 가지 의미가 있습니다. (1) 출력에 각 효과에 대한 메타 분석 가중치가 표시되지 않습니다. (2) $\tau^2$ 추정량은 "ML"로만 설정할 수 있습니다(최대 가능성 이후). GLMM을 추정하는 데 사용됩니다. (3) $\tau^2$ 추정에 대한 신뢰 구간은 없습니다. 이 정보가 필요한 경우 역분산 메타 분석 수행으로 전환할 수 있습니다. Metaprop에는 함수별 인수가 5개 있습니다.

* event. 이벤트 수.

* N. 관측치 수.

* method. 풀링 방법. GLMM(방법 = "GLMM") 또는 역분산 풀링(방법 = "Inverse")일 수 있습니다.

* incl 증분 0 셀의 연속성 수정을 위해 추가되는 증분입니다. 이는 역분산 풀링이 사용되는 경우에만 관련됩니다.

* sm. 사용할 요약 측정값입니다. sm = "PLOGIT"(기본값)을 설정하여 로짓 변환 비율을 사용하는 것이 좋습니다.

Metaprop 기능을 설명하기 위해 OpioidMisuse 데이터 세트를 사용합니다. 이 데이터는 미국 청소년과 젊은 성인을 대상으로 12개월간 처방 오피오이드 오용 발생률을 조사한 메타 분석에서 파생되었습니다(Jordan et al. 2017).

데이터 세트를 로드하고 살펴보겠습니다.

```{r}
library(dmetar)
library(meta)
library(tidyverse)

data(OpioidMisuse)
glimpse(OpioidMisuse)
```
우리는 GLMM과 로짓 변환 비율을 사용하여 유병률 데이터를 통합합니다.

```{r}
m.prop <- metaprop(event = event,
                   n = n,
                   studlab = author,
                   data = OpioidMisuse,
                   method = "GLMM",
                   sm = "PLOGIT",
                   fixed = FALSE,
                   random = TRUE,
                   hakn = TRUE,
                   title = "Opioid Misuse")
summary(m.prop)
```


결과에서 우리는 선택한 연구에서 통합된 12개월 동안 처방 오피오이드 오용 유병률이 $9.4$%이고 신뢰 구간 범위가 8.36~10.66%임을 알 수 있습니다.

앞에서 설명한 대로 출력에는 각 효과의 개별 가중치가 표시되지 않습니다. 같은 맥락에서 연구 간 이질성($\tau^2= 0.056$)에 대한 추정치를 얻었지만 이에 대한 신뢰 구간은 없습니다.

## 3.4. 요약
통계에서 모델은 관찰된 데이터가 생성되는 과정을 설명하는 단순화된 "이론"으로 볼 수 있습니다. 메타 분석에는 고정 효과 모델과 무작위 효과 모델이라는 두 가지 대체 모델이 있습니다.

고정 효과 모델은 하나의 실제 효과 크기가 있다고 가정하는 반면, 무작위 효과 모델에서는 실제 효과 크기가 메타 분석 내에서도 다양하다고 명시합니다. 따라서 무작위 효과 모델의 목표는 데이터의 기본이 되는 실제 효과 크기 분포의 평균을 찾는 것입니다.

연구 간 이질성 분산이라고도 알려진 실제 효과 크기 $\tau^2$의 분산은 무작위 효과 메타 분석에서 추정되어야 합니다. 이에 대한 여러 가지 방법이 있으며 어떤 방법이 가장 효과적인지는 상황에 따라 다릅니다.

통합 효과 크기를 계산하는 가장 일반적인 방법은 역분산 방법을 사용하는 것입니다. 그러나 이진 결과 데이터의 경우 Mantel-Haenszel 방법과 같은 다른 접근 방식이 바람직할 수 있습니다.

{meta} 패키지에는 사전 계산된 효과 크기 데이터의 메타 분석을 수행하는 기능과 다양한 유형의 "원시" 결과 데이터에 사용할 수 있는 기능 모음이 있습니다.
 
 
# 4. 연구 간 이질성

![Fig8](heterogeneity.jpg)

지금까지 우리는 메타 분석에서 효과 크기를 통합하는 방법을 이미 배웠습니다. 우리가 살펴보았듯이 고정 효과 모델과 무작위 효과 모델의 목적은 다양한 연구의 효과를 하나의 숫자로 종합하는 것입니다. 그러나 이는 사과와 오렌지를 비교하지 않는 경우에만 의미가 있습니다. 예를 들어, 메타 분석에서 계산하는 전체 효과는 작지만 효과 크기가 매우 높은 몇 가지 이상값이 여전히 있을 수 있습니다. 이러한 정보는 종합 효과에서는 손실되며 모든 연구에서 작은 효과 크기가 나온 것인지, 아니면 예외가 있었는지는 알 수 없습니다.

메타 분석 내에서 실제 효과 크기가 달라지는 정도를 연구 간 이질성이라고 합니다. 우리는 이미 무작위 효과 모델과 관련하여 마지막 장에서 이 개념을 간략하게 언급했습니다. 무작위 효과 모델은 연구 간 이질성으로 인해 연구의 실제 효과 크기가 달라지는 것으로 가정합니다. 따라서 여기에는 실제 효과의 차이를 정량화하는 $\tau^2$ 추정치가 포함됩니다. 이를 통해 실제 효과 크기 분포의 평균으로 정의된 통합 효과를 계산할 수 있습니다.

무작위 효과 모델을 사용하면 연구가 매우 이질적인 경우에도 항상 통합 효과 크기를 계산할 수 있습니다. 그러나 이 통합 효과가 의미 있는 방식으로 해석될 수 있는지 여부는 알려주지 않습니다. 통합 효과만으로는 메타 분석의 데이터를 제대로 표현하지 못하는 시나리오가 많이 있습니다.

이질성이 매우 높은 경우를 상상해 보십시오. 즉, 실제 효과 크기(예: 일부 치료의 경우)가 매우 긍정적인 것부터 부정적인 것까지 다양하다는 것을 의미합니다. 그러한 메타 분석의 통합 효과가 긍정적이라고 해서 실제로 부정적인 효과가 있는 일부 연구가 있었다는 것을 의미하지는 않습니다. 일부 연구에서는 치료가 부작용을 가져왔다는 사실이 사라졌습니다.

높은 이질성은 데이터에 실제 효과가 다른 두 개 이상의 하위 연구 그룹이 있다는 사실로 인해 발생할 수도 있습니다. 이러한 정보는 효과가 더 낮거나 높은 특정 맥락을 찾을 수 있게 해주기 때문에 연구자들에게 매우 가치가 있을 수 있습니다. 그러나 통합 효과를 따로 살펴보면 이 세부 사항을 놓칠 가능성이 높습니다. 극단적인 경우, 매우 높은 이질성은 연구에 공통점이 없고 통합 효과를 해석하는 것이 전혀 의미가 없다는 것을 의미할 수 있습니다.

따라서 메타분석가는 항상 분석된 연구의 변동을 고려해야 합니다. 모든 좋은 메타 분석은 전반적인 효과를 보고할 뿐만 아니라 이 추정치가 얼마나 신뢰할 수 있는지도 명시해야 합니다. 이것의 필수적인 부분은 연구 간 이질성을 정량화하고 분석하는 것입니다.

이번 장에서는 이질성을 측정하는 다양한 방법과 이를 해석하는 방법을 자세히 살펴보겠습니다. 또한 데이터의 이질성에 기여하는 연구를 탐지할 수 있는 몇 가지 도구도 다룰 것입니다. 마지막으로, "실제" 메타 분석에서 많은 양의 이질성을 다루는 방법을 논의합니다.


## 4.1. 이질성 측정
이질성 측정에 대한 논의를 시작하기 전에 먼저 이질성이 다른 것을 의미할 수 있다는 점을 명확히 해야 합니다. 예를 들어 Rücker와 동료(2008)는 기준선 또는 설계 관련 이질성과 통계적 이질성을 구별합니다.

* 기준선 또는 설계 관련 이질성은 연구의 인구 또는 연구 설계가 연구마다 다를 때 발생합니다. 우리는 "사과와 오렌지" 문제(1.3장)와 연구 질문을 정의하는 방법(1.4.1장)에 대해 이야기하면서 이러한 유형의 이질성을 논의했습니다. 어떤 유형의 모집단과 디자인이 메타 분석에 적합한지 결정하는 적절한 PICO를 설정함으로써 디자인 관련 이질성을 선험적으로 줄일 수 있습니다.

* 반면, 통계적 이질성은 메타분석에 포함된 효과크기 추정치의 확산과 정밀도에 영향을 받는 정량적 특성입니다. 기준선 이질성은 통계적 이질성(예: 포함된 모집단 간에 효과가 다른 경우)으로 이어질 수 있지만 반드시 그럴 필요는 없습니다. 포함된 연구 자체가 사실상 동일하더라도 메타 분석이 높은 통계적 이질성을 나타내는 것도 가능합니다. 이 가이드(및 대부분의 다른 메타 분석 텍스트)에서 "연구 간 이질성"이라는 용어는 통계적 이질성을 나타냅니다.

## 4.2. R의 이질성 평가
이질성 측정에 대해 배운 내용을 실제로 어떻게 사용할 수 있는지 살펴보겠습니다. 예시로서 m.gen 메타 분석 개체의 이질성을 좀 더 자세히 살펴보겠습니다(4.2.1장에서 이 개체를 생성했습니다).

Metagen 객체의 기본 출력에는 예측 구간이 포함되어 있지 않으므로 먼저 업데이트해야 합니다. 간단히 update.meta 함수를 사용하고 예측 간격을 추가로 인쇄하고 싶다고 알려줍니다.

```{r}
m.gen <- update(m.gen, prediction = TRUE)
```

이제 결과를 다시 검사할 수 있습니다
```{r}
summary(m.gen)
```


출력에는 이전에 정의한 모든 이질성 측정값에 대한 결과가 표시됩니다. 이질성 정량화 섹션부터 시작하겠습니다. 여기서는 $\tau^2= 0.08$임을 알 수 있습니다. $\tau^2 (0.03 - 0.35)$ 주변의 신뢰 구간에는 0이 포함되어 있지 않습니다. 이는 연구 간 이질성이 데이터에 존재함을 나타냅니다. $\tau$의 값은 0.29입니다. 이는 실제 효과 크기의 추정 표준 편차가 $SD= 0.29$라는 것을 의미하며, 효과 크기 척도 척도(여기서는 Hedges의 $g$)로 표현됩니다.

두 번째 줄을 보면 $I^2= 63%$이고 $H$($H^2$의 제곱근)가 1.64라는 것을 알 수 있습니다. 이는 데이터 변동의 절반 이상이 실제 효과 크기 차이에서 비롯된 것으로 추정된다는 것을 의미합니다. Higgins와 Thompson의 "경험 법칙"을 사용하면 이러한 이질성의 정도를 보통에서 큰 수준으로 특성화할 수 있습니다.

통합 효과 바로 아래에 예측 구간이 표시됩니다. 범위는 $g= -0.06$부터 $1.21$까지입니다. 이는 향후 일부 연구에서 현재 증거를 기반으로 부정적인 치료 효과를 발견할 가능성이 있음을 의미합니다. 그러나 그 간격이 상당히 넓기 때문에 매우 높은 효과도 가능하다는 것을 의미합니다.

마지막으로 Q와 이질성 테스트도 제시됩니다. Q=45.5임을 알 수 있습니다. 이는 이 분석에서 $K−1= 17$ 자유도를 기반으로 기대하는 것보다 훨씬 더 많은 것입니다. 결과적으로 이질성 테스트는 유의미합니다($p< 0.001$). 그러나 이전에 언급한 것처럼 알려진 결함이 있는 Q 테스트에만 평가를 기반으로 해서는 안 됩니다.


* 메타 분석의 이질성 정도 보고

* 예시에서 발견한 이질성의 정도를 보고하는 방법은 다음과 같습니다.

* “연구 간 이질성 분산은 $\tau^2 = 0.08$(95%CI: 0.03-0.35), $I^2$ 값은 63%(95%CI: 38-78%)로 추정되었습니다. . 예측 구간의 범위는 $g$ = -0.06에서 1.21까지였으며 이는 향후 연구에서 부정적인 개입 효과를 배제할 수 없음을 나타냅니다."


그렇다면 우리는 이러한 결과를 통해 무엇을 얻을 수 있을까요? 전반적으로 우리의 지표는 데이터에 중간 정도에서 상당한 이질성이 존재함을 나타냅니다. 메타 분석의 효과는 완전히 이질적이지는 않지만 연구 간 실제 효과 크기에는 분명히 약간의 차이가 있습니다.

그러므로 이러한 이질성을 일으키는 원인을 탐구하는 것이 좋은 생각일 수 있습니다. 효과 크기가 훨씬 더 크기 때문에 실제로 "적합"하지 않는 한두 가지 연구가 있을 수 있습니다. 이는 우리 분석의 이질성을 부풀릴 수 있으며 더 나쁜 것은 실제 효과를 과대평가하게 만들 수도 있다는 것입니다.

반면에, 예상치 못한 작은 효과 크기를 보고하는 매우 큰 표본 크기를 가진 한 연구에 의해 우리의 통합 효과가 큰 영향을 받을 수도 있습니다. 이는 통합 효과가 치료의 실제 이점을 과소평가한다는 의미일 수 있습니다.

이러한 문제를 해결하기 위해 이제 통합 결과의 견고성을 평가할 수 있는 절차인 특이치 및 영향 분석을 살펴보겠습니다.

* $I^2 > 50$% "가이드라인"

* 연구 간 이질성에 대한 추가 분석이 정확히 언제 필요한지 결정하는 엄격한 규칙은 없습니다. 실제로 때때로 사용되는 접근 방식은 $I^2$가 50%보다 큰 경우 이상값과 영향력 있는 사례를 확인하는 것입니다. 이 임계값에 도달하면 최소한 중간 정도의 이질성을 가정할 수 있으며 변동의 절반 이상은 실제 효과 크기 차이로 인한 것입니다.

* 이 "경험 법칙"은 다소 임의적이며 우리가 논의한 $I^2$의 문제를 알면 결코 완벽하지 않습니다. 그러나 메타 분석에서 통합 효과의 보다 강력한 버전을 얻으려고 노력할 때 선험적으로 일관된 방식으로 지정할 수 있기 때문에 실용적인 관점에서 여전히 도움이 될 수 있습니다.

* 무슨 수를 써서라도 결과가 마음에 든다는 이유로 엄격한 근거 없이 외래 및/또는 영향력 있는 사례를 제거하는 것은 피해야 합니다. 그러한 결과는 우리가 의식적으로 결과를 "바람직한" 방향으로 바꾸려고 노력하지 않더라도 "연구자 의제"(1.3장 참조)에 의해 심하게 편향될 것입니다.


## 4.2. 특이치 및 영향력 있는 사례
앞서 언급했듯이, 연구 간 이질성은 "적합"하지 않는 극단적인 효과 크기를 가진 하나 이상의 연구로 인해 발생할 수 있습니다. 이로 인해 통합 효과 추정치가 왜곡될 수 있으므로 분석에서 이러한 이상값을 제거한 후 통합 효과를 다시 검사하는 것이 좋습니다.

반면에 우리는 우리가 찾은 통합 효과 추정치가 견고한지, 즉 단일 연구에 크게 의존하지 않는지도 알고 싶습니다. 따라서 우리는 분석의 효과를 한 방향으로 크게 밀어붙이는 연구가 있는지도 알고 싶습니다. 이러한 연구를 영향력 있는 사례라고 하며 이 장의 뒷부분에서 이 주제에 대해 시간을 할애할 것입니다.

### 기본 이상치 제거
연구의 효과를 "외부"로 정의하는 방법에는 여러 가지가 있습니다(Viechtbauer 및 Cheung 2010). 쉽고 다소 "무차별적인" 접근 방식은 신뢰 구간이 합동 효과의 신뢰 구간과 겹치지 않는 경우 연구를 이상값으로 보는 것입니다. 특이치의 효과 크기가 너무 극단적이어서 전체 효과와 크게 다릅니다. 이러한 이상치를 탐지하기 위해 모든 연구를 검색할 수 있습니다.

* 95% 신뢰 구간의 상한이 통합 효과 신뢰 구간의 하한보다 낮은 경우(즉, 효과가 매우 작음)

* 95% 신뢰 구간의 하한이 통합 효과 신뢰 구간의 상한보다 높습니다(즉, 매우 큰 효과).

이 방법의 기본 아이디어는 매우 간단합니다. 샘플링 오류가 높은 연구는 통합 효과에서 크게 벗어날 것으로 예상됩니다. 그러나 이러한 연구의 신뢰 구간도 크기 때문에 신뢰 구간이 통합 효과의 신뢰 구간과 겹칠 가능성이 높아집니다.

그러나 연구의 표준 오류가 낮고 여전히 (예기치 않게) 통합 효과에서 크게 벗어나는 경우 신뢰 구간이 겹치지 않고 연구가 이상치로 분류될 가능성이 높습니다.

{dmetar} 패키지에는 이 간단한 이상값 제거 알고리즘을 구현하는 find.outliers라는 함수가 포함되어 있습니다. {meta} 개체에서 외부 연구를 검색하여 제거한 다음 결과를 다시 계산합니다.

find.outliers 함수에는 {meta} 메타 분석 함수에 의해 생성된 객체만 입력으로 필요합니다. m.gen 개체에 대해 어떤 결과를 얻었는지 살펴보겠습니다.

```{r}
find.outliers(m.gen)
```
find.outliers 함수가 "DanitzOrsillo"와 "Shapiro et al."이라는 두 가지 이상값을 감지한 것을 알 수 있습니다. 이 기능은 식별된 연구를 제외하면서 자동으로 분석을 다시 실행했습니다. 각 연구의 랜덤 효과 가중치(%W(random))를 표시하는 열에서 외곽 연구의 가중치가 0으로 설정되어 분석에서 제거되었음을 알 수 있습니다.

출력을 기반으로 두 연구를 제외하면 $I^2$ 이질성이 $I^2$= 63%에서 25%로 상당히 줄어드는 것을 알 수 있습니다. 이제 $\tau^2$ 주변의 신뢰 구간에도 0이 포함되며 이질성에 대한 Q-테스트는 더 이상 중요하지 않습니다. 결과적으로 우리 추정치의 예측 구간도 좁아졌습니다. 이제 양수 값만 포함되어 향후 연구 전반에 걸쳐 통합 효과의 견고성에 대한 훨씬 더 확실성을 제공합니다.


### 영향 분석
이제 우리는 메타 분석에서 이상치를 탐지하고 제거하는 기본적인 방법을 배웠습니다. 그러나 통합 효과의 견고성에 관한 우려를 야기할 수 있는 것은 극단적인 효과 크기 뿐만이 아닙니다. 일부 연구는 효과 크기가 특별히 높거나 낮지 않더라도 전반적인 결과에 여전히 매우 높은 영향을 미칠 수 있습니다.

예를 들어, 메타 분석에서 전반적인 효과를 찾을 수 있지만 그 중요성은 단일 대규모 연구에 따라 달라질 수 있습니다. 이는 영향력 있는 연구가 제거되면 통합 효과가 더 이상 통계적으로 유의하지 않음을 의미합니다. 이러한 정보는 우리의 결과가 얼마나 견고한지 대중에게 알리고자 할 때 매우 중요합니다.

외부 및 영향력 있는 연구는 중복되지만 의미가 약간 다릅니다. 이상값은 효과의 크기를 통해 정의되지만 반드시 메타 분석 결과에 상당한 영향을 미칠 필요는 없습니다. 이전에 정의된 이상값을 제거하면 평균 효과 크기나 데이터의 이질성이 실질적으로 변경되지 않는 것이 가능합니다.

반면에 영향력 있는 사례는 정의에 따라 효과가 얼마나 높거나 낮은지에 관계없이 통합 효과 또는 이질성에 큰 영향을 미치는 연구입니다. 물론 이것이 극단적인 효과 크기를 가진 연구가 영향력 있는 사례가 될 수 없다는 것을 의미하지는 않습니다. 실제로 지난 장의 예에서 설명한 것처럼 이상치도 영향력이 있는 경우가 많습니다. 그러나 반드시 그럴 필요는 없습니다.

영향력 있는 연구를 식별하는 몇 가지 기술이 있으며, 이는 이전에 논의한 기본 이상값 제거보다 조금 더 정교합니다. 그들은 Leave One-Out 방식을 기반으로 합니다. 이 접근 방식에서는 매번 하나의 연구를 제외하고 메타 분석 결과를 $K$ 번 다시 계산합니다.

이 데이터를 기반으로 다양한 영향 진단을 계산할 수 있습니다. 영향 진단을 통해 우리는 메타 분석의 전체 추정에 가장 큰 영향을 미치는 연구를 탐지할 수 있으며, 이 큰 영향이 우리의 통합 효과를 왜곡하는지 평가할 수 있습니다(Viechtbauer and Cheung 2010).

{dmetar} 패키지에는 InfluenceAnalytic이라는 함수가 포함되어 있는데, 이를 통해 하나의 함수를 사용하여 이러한 다양한 영향 진단을 계산할 수 있습니다. 이 함수는 {meta} 함수로 생성된 모든 유형의 메타 분석 개체에 사용할 수 있습니다.

InfluenceAnalytic 함수를 사용하는 것은 비교적 간단합니다. 영향 분석을 수행하려는 메타 분석 개체의 이름만 지정하면 됩니다. 여기서는 다시 m.gen 객체를 사용합니다.

InfluenceAnalytic은 기본적으로 고정 효과 모델을 사용하기 때문에 무작위 효과 모델이 사용되도록 random = TRUE도 설정해야 합니다. 함수는 함수에 의해 생성된 플롯 유형을 주로 제어하는 다른 인수를 사용할 수도 있습니다. 이러한 인수는 함수 문서에 자세히 설명되어 있습니다.

함수 결과를 m.gen.inf라는 개체에 저장합니다.


```{r}
m.gen.inf <- InfluenceAnalysis(m.gen, random = TRUE)
```
InfluenceAnalytic 함수는 Baujat 플롯, Viechtbauer 및 Cheung(2010)에 따른 영향 진단, 효과 크기 및 $I^2$ 값으로 정렬된 Leave-One-Out 메타 분석 결과 등 네 가지 영향 진단 플롯을 생성합니다. 플롯 기능을 사용하여 이러한 각 플롯을 개별적으로 열 수 있습니다. 하나씩 살펴보겠습니다.

### 바우자 플롯
Baujat 플롯은 플롯 함수를 사용하고 두 번째 인수에 "baujat"를 지정하여 인쇄할 수 있습니다.

```{r}
plot(m.gen.inf, "baujat")
```
Baujat 플롯(Baujat et al. 2002)은 메타 분석에서 이질성에 지나치게 기여하는 연구를 탐지하기 위한 진단 플롯입니다. 플롯은 가로 축에 전체 이질성(Cochran의 Q로 측정)에 대한 각 연구의 기여도를 표시하고 세로 축에 통합 효과 크기에 대한 영향을 표시합니다.

이 “영향력” 값은 Leave-One-Out 방식을 통해 결정되며, 연구가 메타분석에 포함될 때와 포함되지 않을 때의 전체 효과의 표준화된 차이를 나타냅니다.

플롯의 오른쪽에 있는 연구는 메타 분석의 전반적인 이질성에 크게 기여하기 때문에 잠재적으로 관련성이 있는 사례로 간주될 수 있습니다. 그림의 오른쪽 상단에 있는 연구는 추정된 이질성과 통합 효과 모두에 큰 영향을 미치기 때문에 특히 영향력이 있을 수 있습니다.

여러분도 알고 계시겠지만, 플롯의 오른쪽에서 찾은 두 연구는 이전에 이미 발견한 연구입니다("DanitzOrsillo" 및 "Shapiro et al."). 이러한 연구는 전체 결과에 큰 영향을 미치지 않지만(아마도 표본 크기가 작기 때문에) 메타 분석에서 발견된 이질성을 실질적으로 추가합니다.

### 영향 진단
다음 플롯에는 각 연구에 대한 여러 영향 진단이 포함되어 있습니다. 다음 코드를 사용하여 플롯할 수 있습니다.

```{r}
plot(m.gen.inf, "influence")
```

플롯에는 각 연구에 대해 다양한 영향 측정값이 표시됩니다. 이러한 측정은 우리의 메타 분석 모델에 잘 맞는 연구와 그렇지 않은 연구를 특성화하는 데 사용됩니다. 진단의 의미를 이해하기 위해 왼쪽에서 오른쪽, 위에서 아래로 간단히 살펴보겠습니다.

### Leave-One-Out 메타분석 결과
마지막으로, Leave-One-Out 방법을 사용하여 수행된 모든 메타 분석의 전반적인 효과와 $I^2$ 이질성을 플롯할 수도 있습니다. 우리는 두 개의 포리스트 플롯(6.2장에서 더 잘 알게 될 플롯 유형)을 인쇄할 수 있습니다. 하나는 통합 효과 크기로 정렬되고 다른 하나는 Leave-One-Out 메타의 $I^2$ 값으로 정렬됩니다. 복수. 플롯을 생성하는 코드는 다음과 같습니다.

```{r}
plot(m.gen.inf, "es")
plot(m.gen.inf, "i2")
```

이 두 개의 포리스트 플롯에서는 매번 하나의 연구가 생략되어 다시 계산된 통합 효과를 볼 수 있습니다. 두 플롯 모두 중앙에 점선이 있는 음영 영역이 있습니다. 이는 원래 통합 효과 크기와 추정된 통합 효과 자체의 95% 신뢰 구간을 나타냅니다.

첫 번째 플롯은 효과 크기(낮음에서 높음)에 따라 정렬됩니다. 여기서는 다양한 연구가 제거될 때 전체 효과 추정치가 어떻게 변경되는지 확인합니다. 두 개의 외롭고 영향력 있는 연구인 "DanitzOrsillo"와 "Shapiro et al." 이후 효과 크기가 매우 높기 때문에 이를 제거하면 전체 효과가 가장 작다는 것을 알 수 있습니다.

두 번째 플롯은 $I^2$로 측정된 이질성(낮음에서 높음)에 따라 정렬됩니다. 이 플롯은 "DanitzOrsillo" 및 "Shapiro et al." 연구를 생략함으로써 가장 낮은 $I^2$ 이질성에 도달했음을 보여줍니다. 이는 이 두 연구가 우리가 메타 분석에서 발견한 연구 간 이질성의 주요 "범인"이라는 우리의 발견을 확증합니다.

전체적으로 이 예의 이상치 및 영향 분석 결과는 동일한 방향을 가리킵니다. 영향력 있는 이상치일 가능성이 있는 두 가지 연구가 있습니다. 이 두 연구는 효과 크기 추정치와 정확도를 왜곡할 수 있습니다. 따라서 우리는 두 연구를 제외한 민감도 분석 결과도 수행하고 보고해야 합니다.

gosh.diagnostics 함수가 식별한 세 가지 연구를 제거하면서 메타 분석을 다시 실행하면 어떤 일이 발생하는지 살펴보겠습니다.

```{r}
update(m.gen, exclude = c(3, 4, 16)) %>% 
  summary()
```


* 영향분석 결과 보고

* “DanitzOrsillo”, “de Vibe et al.”이라고 판단했다고 가정해 보겠습니다. 그리고 “Shapiro et al.” 우리의 메타 분석에 영향력 있는 연구입니다. 이 경우 이러한 연구를 제외한 민감도 분석 결과도 보고하는 것이 합리적이다.

* 독자들이 영향력 있는 연구 제거와 관련된 변화를 쉽게 볼 수 있도록 원래 결과와 민감도 분석 결과가 모두 표시되는 표를 만들 수 있습니다. 이 표에는 최소한 통합 효과, 신뢰 구간 및
p-값뿐만 아니라 예측 구간, $I^2$ 통계(및 해당 신뢰 구간)와 같은 몇 가지 이질성 측정값도 포함됩니다.

* 또한 어떤 연구가 영향력 있는 사례로 제거되었는지 지정하여 다른 사람들이 새로운 결과가 어떤 데이터를 기반으로 하는지 이해할 수 있도록 하는 것도 중요합니다. 다음은 이전의 m.gen 메타 분석에서 이러한 테이블이 어떻게 보이는지에 대한 예입니다.

* 이상값으로 제거됨: DanitzOrsillo, de Vibe, Shapiro.

* 이 유형의 테이블은 다른 민감도 분석 결과를 포함하는 추가 행을 추가할 수도 있으므로 매우 편리합니다. 예를 들어, 비뚤림 위험이 낮은 연구(1.4.5장)만 고려한 분석을 수행하는 경우 결과를 세 번째 행에 보고할 수 있습니다.

## 4.3. 요약
메타 분석에서는 통합 효과 크기뿐만 아니라 이러한 평균 효과의 기반이 되는 데이터의 이질성에도 주의를 기울여야 합니다. 전체 효과는 일부 연구의 실제 효과가 우리의 점 추정치와 크게 다를 수 있다는 점을 포착하지 못합니다.

Cochran의 Q는 일반적으로 데이터의 변동성을 정량화하는 데 사용됩니다. Q가 $\chi^2$ 분포를 따른다는 것을 알고 있기 때문에 이 측정을 통해 샘플링 오류만으로 예상할 수 있는 것보다 더 많은 변동이 존재하는지 감지할 수 있습니다. 이러한 초과 변동성은 연구 효과 크기의 실제 차이를 나타냅니다.

그러나 $Q$의 통계 테스트는 현재 사용 중인 데이터 유형에 따라 크게 달라집니다. 이질성의 정도를 평가하기 위해 $Q$에만 의존해서는 안 됩니다. 추가로 사용될 수 있는 $I^2$, $\tau$ 또는 예측 간격과 같은 다른 측정값이 있습니다.

메타 분석의 평균 효과는 데이터에 이상치가 있는 경우 편향될 수 있습니다. 이상값이 메타분석 결과에 항상 큰 영향을 미치는 것은 아닙니다. 하지만 그럴 때 우리는 영향력 있는 사례에 대해 이야기합니다.

외부 및 영향력 있는 케이스를 식별하는 다양한 방법이 있습니다. 그러한 연구가 발견되면, 결과 해석이 변경되는지 확인하기 위해 메타 분석을 다시 계산하는 것이 좋습니다.

# 4. Forest plots
![Fig9](forest2.jpg)

지난 장에서 우리는 R에서 효과 크기를 통합하는 방법과 메타 분석에서 이질성을 평가하는 방법을 배웠습니다. 이제 우리는 이전 단계에서 얻은 결과를 시각화하는 좀 더 즐거운 메타 분석 부분에 이르렀습니다.

메타 분석을 시각화하는 가장 일반적인 방법은 포리스트 플롯을 이용하는 것입니다. 이러한 플롯은 관찰된 효과, 신뢰 구간 및 일반적으로 각 연구의 가중치를 그래픽으로 표시합니다. 또한 메타 분석에서 계산한 통합 효과도 표시됩니다. 전반적으로 이를 통해 다른 사람들은 포함된 연구의 정밀도와 확산, 그리고 통합 효과가 관찰된 효과 크기와 어떻게 관련되는지 신속하게 조사할 수 있습니다.

{meta} 패키지에는 R에서 직접 아름다운 숲 플롯을 매우 쉽게 생성할 수 있는 내장 함수가 있습니다. 이 함수는 광범위한 기능을 갖고 있으며 플롯의 모양을 원하는 대로 변경할 수 있습니다. 이 삼림 플롯 기능과 이를 실제로 사용하는 방법이 이 장의 주요 초점이 될 것입니다. 또한 메타 분석 결과를 시각화하는 대안적인 접근 방식에 대해서도 간략하게 논의하겠습니다.

## 5.1. Forest Plot이란 무엇입니까?
그림 6.1은 Forest Plot의 주요 구성 요소를 보여줍니다. 왼쪽에는 Forest Plot표에 메타 분석에 포함된 각 연구의 이름이 표시됩니다. 각 연구에 대해 효과 크기의 그래픽 표현이 일반적으로 플롯 중앙에 제공됩니다. 이 시각화는 x축에 대한 연구의 점 추정치를 보여줍니다. 이 점 추정치는 관찰된 효과 크기에 대해 계산된 신뢰 구간의 범위를 나타내는 선으로 보완됩니다. 일반적으로 점 추정치는 사각형으로 둘러싸여 있습니다. 이 사각형의 크기는 효과 크기의 가중치(4.1.1장)에 의해 결정됩니다. 가중치가 더 큰 연구에는 더 큰 사각형이 주어지고, 가중치가 낮은 연구에는 더 작은 사각형이 제공됩니다.

일반적으로 산림 도표에는 메타 분석을 수행하는 데 사용된 효과 크기 데이터도 포함되어야 합니다. 이는 다른 사람들에게 결과를 복제하는 데 필요한 데이터를 제공합니다.

![Fig10](fig9.png)


Figure 6.1: Key elements of a forest plot.
플롯 하단의 다이아몬드 모양은 평균 효과를 나타냅니다. 다이아몬드의 길이는 x축에서 합동 결과의 신뢰 구간을 상징합니다. 일반적으로 forest plot에는 효과가 없는 x축 지점을 나타내는 수직 기준선도 포함됩니다. 다음 예에서 볼 수 있듯이 $I^2$ 또는 $\tau^2$와 같은 이질성 측정값도 표시하여 forest plot를 향상할 수 있습니다.

산림 도표의 효과 크기와 신뢰 구간은 일반적으로 선형 척도로 표시됩니다. 그러나 요약 측정값이 비율(예: 승산비 또는 위험비)인 경우 x축에 로그 척도를 대신 사용하는 것이 일반적입니다. 이는 1 주변의 값이 1보다 훨씬 낮거나 높은 값보다 더 밀접하게 결합되어 있음을 의미합니다.

이러한 효과 크기 지표는 "선형" 방식으로 해석될 수 없기 때문에 비율에 대해 의미가 있습니다(즉, RR = 0.50의 "반대"는 1.5가 아니라 2입니다. 3.3.2장 참조). 이러한 효과 크기에 대한 기준선은 일반적으로 1이며 이는 효과가 없음을 나타냅니다.

## 5.2 Forest Plots in R
forest 함수를 사용하여 모든 유형의 {meta} 메타 분석 개체(예: Metagen, Metacont 또는 Metabin의 결과)에 대한 포레스트 플롯을 생성할 수 있습니다. {meta} 객체와 함께 forest를 제공하기만 하면 플롯이 생성됩니다. 일반적으로 이러한 숲 그림은 기본적으로 이미 매우 좋아 보이지만 이 함수에는 모양을 더욱 조정하기 위한 수많은 추가 인수도 있습니다. 이러한 인수는 모두 함수 문서(?forest를 실행하여 액세스할 수 있음)에 설명되어 있습니다. 더 중요한 목록은 다음과 같습니다.

* sortvar. 포레스트 플롯에서 연구가 정렬되는 메타 분석 데이터 세트의 변수입니다. 예를 들어 효과 크기별로 결과를 정렬하려면 sortvar = TE 코드를 사용할 수 있습니다.

* comb.fixed. 고정 효과 모형 추정치가 도표에 포함되어야 하는지 여부를 나타내는 논리적입니다.

* comb.random.. 랜덤 효과 모형 추정치가 도표에 포함되어야 하는지 여부를 나타내는 논리적입니다.

* text.fixed.. 고정 효과 모델에 따른 통합 효과에 대한 레이블입니다. 기본적으로 "고정 효과 모델"이 인쇄됩니다.

* text.random. 랜덤 효과 모델에 따른 통합 효과에 대한 레이블입니다. 기본적으로 "랜덤 효과 모델"이 인쇄됩니다.

*  prediction. 예측 구간을 플롯에 추가해야 하는지 여부를 나타내는 논리적입니다.

* label.left 및 label.right. 산림 플롯의 왼쪽과 오른쪽에 라벨이 추가되었습니다. 예를 들어, 이쪽에 대한 효과가 처리를 선호하도록 지정하는 데 사용할 수 있습니다(예: label.left = "처리를 선호함").

* smlab. 플롯 상단에 표시되는 레이블입니다. 이는 어떤 효과 크기 측정항목이 사용되었는지 표시하는 데 사용할 수 있습니다.

* xlim. 대칭 산림 플롯을 생성하기 위한 x축 또는 문자 "s"의 한계입니다. 이는 결과가 0에서 크게 벗어나거나 이상값을 표시하려는 경우 특히 관련이 있는 주장입니다. 예를 들어 x축 범위를 0에서 2까지로 설정하려는 경우 코드는 xlim = c(0,2)입니다.

*  ref.. 플롯의 기준선. 사용한 요약 측정값에 따라 기본적으로 0 또는 1입니다.

* leftcols and rightcols. 여기에서 포리스트 플롯의 왼쪽과 오른쪽에 표시할 변수를 지정할 수 있습니다. 함수가 기본적으로 사용하는 몇 가지 내장 요소가 있습니다. 예를 들어, "studlab"은 연구 레이블을 나타내고, "효과"는 관찰된 효과 크기를 나타내며, effect.ci는 효과 크기와 신뢰 구간을 나타냅니다. 처음에 {meta} 함수에 제공한 data.frame에 사용자 정의 열이 포함되어 있는 한 사용자 정의 열을 추가하는 것도 가능합니다. 이 경우에는 컬럼 이름을 문자열로 추가하기만 하면 됩니다.

* leftlabs 및 rightlabs. 산림 도표의 왼쪽과 오른쪽에 표시되는 열에 사용해야 하는 레이블입니다.

* print.I2 및 print.I2.ci. $I^2$인지 여부를 나타내는 논리적
 값과 그 신뢰 구간이 인쇄되어야 합니다. 이는 기본적으로 TRUE입니다.

* print.tau2 및 print.tau. $\tau^2$ 및 $\tau$ 값을 인쇄해야 하는지 여부를 나타내는 논리적입니다. $\tau^2$ 값이 기본적으로 인쇄됩니다.

* col.square, col.diamond 및 col.predict. 정사각형, 다이아몬드형, 예측 구간의 색상(예: '파란색')입니다.

첫 번째 forest plot을 생성할 시간입니다. 이 예에서는 이전 예에서도 사용한 m.gen 객체를 플로팅합니다. 효과 크기에 따라 포리스트 플롯의 연구를 정렬하고 왼쪽에 예측 구간과 사용자 정의 레이블을 추가합니다. forest 함수는 기본적으로 τ$\tau^2$ 값을 인쇄하는데 여기서는 이를 원하지 않으므로 print.tau2를 FALSE로 설정합니다.

이것이 우리 코드의 최종 모습입니다:

```{r}

summary(m.gen)

forest(m.gen, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))
```

숲이 우리에게 제공하는 줄거리는 이미 꽤 괜찮아 보입니다. 또한 합동 효과 주변의 예측 구간을 나타내는 검은색 선이 플롯에 추가된 것을 볼 수 있습니다.

각 연구의 편향 위험을 표시하는 열을 추가하여 플롯을 향상할 수 있습니다. m.gen을 생성하는 데 사용한 ThirdWave 데이터 세트에는 각 연구의 편향 평가 위험이 저장되는 RiskOfBias라는 열이 포함되어 있습니다.

Metagen을 사용하여 메타 분석을 계산할 때(4.2.1장) 함수가 자동으로 이 데이터를 m.gen에 저장했습니다. 따라서 leftcols 인수를 사용하여 플롯에 열을 추가할 수 있습니다. 그 결과 다음 코드가 생성됩니다.

```{r}
forest(m.gen, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftcols = c("studlab", "TE", "seTE", "RiskOfBias"),
            leftlabs = c("Author", "g", "SE", "Risk of Bias"))
```

이제 각 연구의 편향 위험 정보가 포레스트 플롯에 추가되었음을 알 수 있습니다.

### 레이아웃 유형
포리스트 함수에는 두 개의 "사전 패키지된" 레이아웃이 있는데, 이를 사용하여 수많은 인수를 지정하지 않고도 포리스트 플롯을 특정 형식으로 가져올 수 있습니다. 그 중 하나는 미국 의학 협회 저널(Journal of the American Medical Association)의 지침에 따라 산림 플롯을 제공하는 "JAMA" 레이아웃입니다. 의학 저널에 메타 분석을 게시하려는 경우 이 레이아웃을 사용할 수 있습니다.

```{r}
forest(m.gen, layout = "JAMA")
```

다른 레이아웃은 Cochrane의 Review Manager 5에서 생성된 것과 유사한 산림 플롯을 생성하는 "RevMan5"입니다.

```{r}
forest(m.gen, layout = "RevMan5")
```

### Saving the Forest Plots
forest에 의해 생성된 forest plot은 PDF, PNG 또는 확장 가능한 벡터 그래픽(SVG) 파일로 저장할 수 있습니다. 기본 R 또는 {ggplot2} 패키지를 통해 생성된 다른 플롯과 달리 포리스트의 출력은 파일로 저장할 때 자동으로 크기가 조정되지 않습니다. 이는 숲의 구획이 때때로 두 면 또는 네 면에서 잘려지는 것을 의미하며, 모든 것이 보이도록 너비와 높이를 수동으로 조정해야 합니다.

pdf, png 및 svg 기능을 사용하여 R 코드를 통해 플롯을 저장할 수 있습니다. 우리는 다음 코드의 출력이 문서에 저장되어야 함을 R에 알려주는 이러한 함수 중 하나에 대한 호출부터 시작해야 합니다. 그런 다음 포리스트 함수에 대한 호출을 추가합니다. 마지막 줄에는 생성된 출력을 위에서 지정한 파일에 저장하는 dev.off()를 포함해야 합니다.

세 가지 함수 모두 파일 이름을 포함해야 하는 파일 인수를 지정해야 합니다. 그러면 파일이 자동으로 해당 이름으로 작업 디렉터리에 저장됩니다. 또한 width 및 height 인수를 사용하여 플롯의 크기를 제어할 수 있으며 이는 출력이 잘릴 때 도움이 될 수 있습니다.

초기 forest plot을 "forestplot"이라는 이름으로 저장한다고 가정하면 다음 코드를 사용하여 PDF, PNG 및 SVG 파일을 생성할 수 있습니다.


pdf(file = "forestplot.pdf", width = 8, height = 7)

forest(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()



png(file = "forestplot.png", width = 2800, height = 2400, res = 300)

forest(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()



svg(file = "forestplot.svg", width = 8, height = 7)

forest(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()



## 5.3. 휘장 플롯
산림 도표는 메타 분석을 시각화하는 가장 일반적인 방법입니다. 대부분의 출판된 메타 분석에는 산림 도표가 포함되어 있으며 많은 연구자들이 이러한 분석이 어떻게 해석되는지 이해하고 있습니다. 산림 플롯은 결과에 대해 포괄적이고 쉽게 이해할 수 있는 요약을 제공하므로 메타 분석 보고서에도 이를 포함하는 것이 좋습니다.

그러나 산림 플롯이 결과를 설명하는 유일한 방법은 아닙니다. 예를 들어 드레이퍼리 플롯(Rücker and Schwarzer 2021)을 통해 메타 분석을 시각화할 수도 있습니다. 포레스트 플롯의 단점은 고정된 유의성 임계값(일반적으로 p< 0.05)을 가정하여 신뢰 구간만 표시할 수 있다는 것입니다. 연구자들은 효과가 중요한지 여부를 결정하는 것은 이러한 신뢰 구간을 기반으로 합니다.

최근 몇 년 동안 p-값의 사용을 둘러싸고 논란이 있어왔고(Wellek 2017), 일부에서는 p-값을 기반으로 한 가설 검정이 많은 연구 분야에서 "복제 위기"에 기여했다고 주장했습니다(Nuzzo 2014).

드레이퍼리 도표는 p-값 함수를 기반으로 합니다. 이러한 p-값 함수는 분석 결과를 해석할 때 p<0.05 유의성 임계값에만 의존하는 것을 방지하기 위해 제안되었습니다(Infanger 및 Schmidt-Trucksäss 2019).

따라서 p-값 함수는 95% 신뢰 구간만 계산하는 대신 다양한 p 값에 대한 신뢰 구간을 보여주는 연속 곡선을 제공합니다. 드레이퍼리 플롯에서는 각 연구와 평균 효과에 대한 신뢰 곡선이 그려집니다. x축은 효과 크기 측정항목을 나타내고 y축은 가정된 p-값을 나타냅니다.

{meta}의 drapery 함수를 통해 커튼 플롯을 생성할 수 있습니다. 숲과 마찬가지로 이 함수는 {meta} 메타 분석 개체를 제공하면 자동으로 플롯을 생성합니다. 몇 가지 추가 주장이 있는데, 가장 중요한 것은 다음과 같습니다.


* type: y축에 표시할 값의 유형을 정의합니다. 이는 테스트 통계의 경우 "zvalue"(기본값)일 수 있습니다.
p-값("p값").

* Study.results: 논리적, 각 연구의 결과가 플롯에 포함되어야 하는지 여부를 나타냅니다. FALSE인 경우 요약 효과만 인쇄됩니다.

* label: 이 인수를 "studlab"으로 설정하면 연구 라벨이 플롯에 포함됩니다.

* legend: 범례를 인쇄해야 하는지 여부를 나타내는 논리적입니다.

* pos.legend. 범례의 위치. "오른쪽 아래", "아래", "왼쪽 아래", "왼쪽", "왼쪽 위", "위", "오른쪽 위", "오른쪽" 또는 "가운데" 중 하나입니다.

m.gen 메타분석 객체를 사용하여 예시에서 drapery 기능을 시험해 보겠습니다.

```{r}
drapery(m.gen, 
        labels = "studlab",
        type = "pval", 
        legend = FALSE)
```

결과 플롯에는 각 효과 크기에 대한 p-값 곡선이 모두 거꾸로 된 V 모양으로 포함됩니다. 굵은 선은 랜덤 효과 모델에 따른 평균 효과를 나타냅니다. 플롯에서 음영 처리된 영역은 예측 구간을 나타내며, 이는 합동 효과의 신뢰 구간보다 상당히 넓습니다.

p-값 함수의 "피크"는 메타 분석에서 효과 크기의 정확한 값을 나타냅니다. y축 아래로 내려갈수록 p-값은 더 작아지고, 수평선 점선으로 표시된 기존 유의성 임계값에 도달할 때까지 신뢰 구간은 점점 더 넓어집니다.

플롯을 기반으로 p가 이미 매우 작을 때(<0.01) x축에서 굵은 선이 0에 도달한다는 점을 고려하면 합동 효과 크기가 0보다 크다는 것을 상당히 확신할 수 있음을 알 수 있습니다.

Rückeret al. (2021)에서는 산림 부지 외에 휘장 부지도 주로 활용하도록 권고하고 있다. 단순히 숲을 커튼 플롯으로 바꾸는 것은 좋은 생각이 아닐 수 있습니다. 왜냐하면 후자에는 결과를 재현하기 위해 다른 사람들이 필요할 수 있는 효과 크기 정보가 많이 포함되어 있지 않기 때문입니다.

## 5.5 요약
메타분석 결과를 Forest Plot을 통해 시각화하는 것이 관례입니다.

산림 도표에는 각 연구의 효과 크기와 신뢰 구간에 대한 그래픽 표현이 포함되어 있으며 계산된 전체 효과도 표시됩니다. 또한 풀링에 사용된 효과 크기 데이터도 포함되어 있습니다.

예를 들어 각 연구에서 받은 품질 등급과 같은 다른 종류의 정보를 산림 도표에 추가하는 것도 가능합니다.

산림 도표는 고정된 유의성 임계값(보통 p< 0.05)을 가정한 결과만 표시할 수 있습니다. 다양한 유의성 임계값에 대한 결과가 어떻게 변경되는지 시각화하기 위해 커튼 플롯을 추가로 생성할 수 있습니다.



# 6. Subgroup Analyses

![Fig11](fassade.jpg)


## 6.1. 소개
5장에서 우리는 연구 간 이질성의 개념과 그것이 메타 분석에서 왜 그렇게 중요한지에 대해 논의했습니다. 또한 이상값 및 영향 분석의 일부로 어떤 연구가 관찰된 이질성에 기여하는지 식별할 수 있는 방법도 배웠습니다. 이러한 분석에서 우리는 순전히 통계적인 관점에서 메타 분석에 접근합니다. 우리는 데이터의 상당한 이질성을 "측정"하므로 적합하지 않은 통계적 특성이 있는 연구(즉, 외래 및 영향력 있는 연구)를 제외하여 모델의 견고성을 향상합니다.

이 접근 방식은 사후 절차로 볼 수 있습니다. 이상값 및 영향 분석은 데이터를 본 후 수행되며, 종종 우리가 찾은 결과 때문에 수행됩니다. 또한 그들은 데이터 자체 외에는 어떤 것에도 주의를 기울이지 않습니다. 영향 분석 방법을 사용하면 일부 연구가 우리 모델의 기대치를 제대로 따르지 않는다는 것을 알 수 있지만 이것이 왜 그런지는 알 수 없습니다. 아마도 이번 연구가 약간 다른 연구 방법이나 치료법을 사용했기 때문일 수도 있습니다. 그러나 연구의 영향력만으로는 이를 알 수 없습니다.

당신이 의학적 치료의 효과를 조사하는 메타 분석을 수행한다고 상상해 보십시오. 당신은 전반적으로 치료가 효과가 없다는 것을 알게 됩니다. 그러나 상당한 치료 효과가 확인된 연구는 3편이 있다. 영향 분석에서 이러한 연구를 탐지하는 것이 가능할 수도 있지만 이것이 왜 영향력이 있는지는 알려주지 않습니다. 세 가지 연구 모두 다른 모든 연구에서 사용된 치료법과 약간 다른 치료법을 사용했을 수 있으며, 이 작은 세부 사항이 치료법의 효과에 큰 영향을 미쳤을 수 있습니다. 이는 획기적인 발견이 될 것입니다. 그러나 이상치 분석과 영향력 분석만으로는 만들 수 없는 분석이다.

이는 데이터에서 특정 이질성 패턴이 발견되는 이유를 식별할 수 있는 다른 접근 방식이 필요하다는 점을 분명히 합니다. 중재자 분석이라고도 알려진 하위 그룹 분석은 이를 수행하는 한 가지 방법입니다. 이를 통해 우리는 특정 유형의 연구가 다른 유형보다 낮거나 높은 효과를 생성하는 이유를 설명하면서 특정 가설을 테스트할 수 있습니다.

1.4.2장에서 배운 것처럼 하위 그룹 테스트는 선험적으로 정의되어야 합니다. 메타 분석을 시작하기 전에 관찰된 효과 크기에 영향을 미칠 수 있는 다양한 연구 특성을 정의하고 이에 따라 각 연구를 코딩해야 합니다. 효과 크기가 다른 이유는 셀 수 없이 많지만, 분석의 맥락에서 중요한 것으로 제한해야 합니다.

예를 들어, 어떤 유형의 약물이 다른 약물보다 더 높은 효과를 나타내는지 조사할 수 있습니다. 또는 추적 기간이 다소 짧은 연구와 긴 연구를 비교할 수도 있습니다. 또한 연구가 수행된 문화 지역에 따라 관찰된 효과가 다른지 조사할 수도 있습니다. 메타 분석가로서 특정 주제에 대한 전문 지식을 갖추는 것이 도움이 됩니다. 이를 통해 해당 분야의 다른 과학자나 실무자와 실제로 관련이 있는 질문을 찾을 수 있기 때문입니다.

하위 그룹 분석의 기본 아이디어는 메타 분석이 평균 효과 크기를 계산하는 것뿐만 아니라 증거의 변화를 조사하는 도구가 될 수도 있다는 것입니다. 하위 집단 분석에서 우리는 이질성을 단순히 귀찮은 일이 아니라 과학적 가설로 설명할 수도 있고 설명할 수 없는 흥미로운 변이로 봅니다. 최선의 경우, 이는 우리 주변 세계에 대한 이해를 넓힐 수 있거나 적어도 미래의 의사 결정을 안내하는 실용적인 통찰력을 얻을 수 있습니다.

이 장에서는 하위 그룹 분석의 이면에 있는 통계 모델과 이를 R에서 직접 수행할 수 있는 방법을 설명합니다.



![Fig12](fig10.png)

Figure 7.1: Visualization of the fixed-effects (plural) model, assuming a random-effects model within subgroups.

고정 수준을 갖는 부분군 변수의 몇 가지 예

* 연령층: 어린이, 청소년, 성인, 노인.

* 문화적 배경: 서양, 비서구.

* 대조군: 대체치료, 최소치료, 무치료.

* 결과 측정에 사용된 도구: 자가 보고, 전문가 평가.

* 연구 품질: 높음, 낮음, 불명확함.

* 종 : 식물, 동물.

* 설정: 학교, 병원, 개인 가정.

하위 그룹의 구체적인 선택과 정의는 메타 분석의 목적과 범위에 따라 조정될 수 있고 조정되어야 합니다.

## 6.2. R의 하위군 분석
R에서 배운 내용을 구현할 시간입니다. {meta} 패키지를 사용하여 하위 그룹 분석을 수행하는 것은 비교적 간단합니다. {meta}의 모든 메타분석 함수에서는 하위그룹 인수를 지정할 수 있습니다28. 이는 어떤 효과 크기가 어떤 하위 그룹에 속하는지 알려주고 하위 그룹 분석을 실행합니다. 하위 그룹 인수는 문자, 요인, 논리 또는 숫자 변수를 허용합니다. 우리가 주의해야 할 유일한 것은 동일한 하위 그룹의 연구에 완전히 동일한 레이블이 있다는 것입니다.

이 예에서는 m.gen 메타 분석 개체를 다시 사용합니다. 메타 분석을 계산하는 데 사용한 ThirdWave 데이터 세트에는 하위 그룹 정보가 포함된 몇 개의 열이 포함되어 있습니다. 여기서 우리는 비뚤림 위험이 높은 연구와 낮은 연구 사이에 효과 크기 차이가 있는지 조사하고 싶습니다. 편향 위험 정보는 RiskOfBias 열에 저장됩니다.

먼저 이 칼럼을 살펴보겠습니다. 우리 코드에서는 데이터 세트의 처음 몇 행만 표시되도록 head 함수를 사용합니다.

```{r}
# Show first entries of study name and 'RiskOfBias' column
head(ThirdWave[,c("Author", "RiskOfBias")])
```
데이터 세트의 모든 연구에는 편향 평가 위험을 지정하는 레이블이 있음을 알 수 있습니다. Metagen을 사용하여 메타 분석을 계산할 때 이 정보는 m.gen 개체에 내부적으로 저장되었습니다. 따라서 하위 그룹 분석을 수행하려면 update.meta 함수를 사용하고, 함수에 m.gen 객체를 제공하고, subgroup 인수를 사용하여 데이터 세트에서 하위 그룹 레이블이 포함된 열을 지정할 수 있습니다.

이전에는 하위 그룹 전체에 걸쳐 $\tau^2$의 공통 추정치를 사용하거나 사용하지 않고 하위 그룹 분석을 수행할 수 있다는 점도 다루었습니다. 이는 tau.common을 TRUE 또는 FALSE로 설정하여 {meta}에서 제어할 수 있습니다. 지금은 각 하위 그룹의 연구 간 이질성 분산에 대한 별도의 추정치를 사용하겠습니다.

이 예에서는 고정 효과(복수) 모델을 적용하고 하위 그룹 내의 연구가 무작위 효과 모델을 사용하여 통합된다고 가정합니다. m.gen에 무작위 효과 모델에 대한 결과가 포함되어 있다는 점을 고려하면(comb.fixed를 FALSE로 설정하고 Comb.random을 TRUE로 설정했기 때문에) 변경할 사항이 없습니다. 원래 메타 분석은 무작위 효과 모델을 사용하여 수행되었기 때문에 update.meta는 하위 그룹 내의 연구도 무작위 효과 모델을 사용하여 통합되어야 한다고 자동으로 가정합니다.

따라서 결과 코드는 다음과 같습니다.

```{r}
update(m.gen, 
            subgroup = RiskOfBias, 
            tau.common = FALSE)
```

출력에는 하위 그룹에 대한 결과라는 새 섹션이 표시됩니다. 출력의 이 부분은 각 하위 그룹에 대해 별도로 통합된 효과 크기를 표시합니다. 편향 위험이 높은 $k= 7$ 연구가 있고, 편향 위험이 낮은 연구는 11개입니다. 추정된 연구 간 이질성은 편향 위험이 높은 연구에서는 $I^2= 77%로 상당히 다르지만 위험이 낮은 연구에서는 26%에 불과합니다.

하위 그룹의 효과 크기도 다릅니다. $g= 0.43$를 사용하면 편향 위험이 낮은 연구의 효과 추정치는 편향 위험이 높은 연구보다 작습니다. 편향된 연구가 치료 효과를 과대평가할 가능성이 더 높기 때문에 이는 일반적인 발견입니다.

그런데 그 차이가 통계적으로 유의미한가요? 부분군 차이 검정 결과를 보면 이를 확인할 수 있습니다. 이는 2개의 하위 그룹이 있는 예에서 1개의 자유도를 기반으로 하는 Q-테스트를 보여줍니다. 검정의 p-값은 0.09로 기존 유의성 임계값보다 크지만 여전히 추세 수준에서는 차이가 있음을 나타냅니다.

두 하위 그룹 모두에서 공통 $\tau^2$ 추정치를 가정하면 결과를 확인할 수도 있습니다. tau.common을 TRUE로 설정하기만 하면 됩니다.

```{r}
update(m.gen, subgroup = RiskOfBias, tau.common = TRUE)
```


결과에서 추정된 연구 간 이질성 분산은 $\tau^2= 0.069$이고 두 하위 그룹에서 동일하다는 것을 알 수 있습니다. 두 가지 Q-테스트가 제공됩니다. 하나는 그룹 간(실제 하위 그룹 테스트)이고 다른 하나는 하위 그룹 내 이질성에 대한 것입니다.

일반적인 메타 분석과 마찬가지로 후자는 하위 그룹에 과도한 변동성이 있음을 나타냅니다(p=0.001). 하위그룹 차이 테스트는 비뚤림 위험이 낮은 연구와 높은 연구 사이에 유의미한 차이가 없음을 다시 나타냅니다(p= 0.181).

이제 우리는 $\tau^2$의 독립적 또는 공통 추정치를 가정하여 결과를 탐색했습니다. 두 하위 그룹의 이질성이 동일하다고 가정할 타당한 이유를 알지 못하고 각 하위 그룹에 최소 $k= 7$ 연구가 있으므로 $\tau^2$의 별도 추정이 적절할 수 있습니다. 그러나 적어도 우리의 예에서는 결과 해석이 두 접근 방식 모두 유사하다는 것을 확인했습니다.
 
### 부분군 분석 결과 보고

* 하위그룹 분석의 결과는 일반적으로 각 하위그룹의 추정된 효과와 이질성을 표시하는 표로 보고되며, 하위그룹 차이에 대한 검정의 p-값도 표시됩니다.

![Fig13](fig11.png)


둘 이상의 하위 그룹 분석이 수행된 경우 테이블에 추가 행을 추가할 수 있습니다.

## 6.3. 요약
메타 분석의 이질성을 평가하는 방법은 다양하지만 이러한 접근 방식으로는 데이터에서 과도한 변동성이 발견되는 이유를 알 수 없습니다. 부분군 분석을 통해 일부 연구의 실제 효과 크기가 다른 연구보다 높거나 낮은 이유에 대한 가설을 테스트할 수 있습니다.

부분군 분석의 경우 일반적으로 고정 효과(복수) 모델을 가정합니다. 하위 그룹 내의 연구는 대부분의 경우 무작위 효과 모델을 사용하여 통합됩니다. 그 후, 전체 하위 그룹 결과를 기반으로 한 Q-테스트를 사용하여 그룹이 크게 다른지 확인합니다.

하위 그룹 분석 모델은 다양한 범주 자체가 고정되어 있다고 가정하기 때문에 "고정 효과" 모델이라고 합니다. 하위 그룹 수준은 가능한 범주의 세계에서 무작위 추첨으로 표시되지 않습니다. 이는 부분군 변수가 취할 수 있는 유일한 값을 나타냅니다.

하위 그룹 분석을 계산할 때 하위 그룹 내에서 결과를 통합하기 위해 연구 간 이질성에 대한 별도의 추정치 또는 공통 추정치를 사용해야 하는지 결정해야 합니다.

하위그룹 분석은 만병통치약이 아닙니다. 하위 그룹 차이를 탐지하는 데 필요한 통계적 검정력이 부족한 경우가 많습니다. 따라서 부분군 차이에 대한 검정이 유의하지 않다고 해서 부분군이 동일한 결과를 생성한다는 의미는 아닙니다.
 

# 7. Publication Bias

![Fig15](pub_bias.jpg)

마지막 장을 되돌아보면 우리는 이미 광범위한 메타 분석 기술을 다루었음을 알 수 있습니다. 우리는 효과 크기를 통합하는 방법을 배웠을 뿐만 아니라 이제 연구 결과의 견고성을 평가하고 이질성 패턴을 검사하고 효과가 다른 이유에 대한 가설을 테스트하는 방법도 알고 있습니다.

이러한 모든 접근 방식은 메타 분석에서 유효한 결론을 도출하는 데 도움이 될 수 있습니다. 그러나 이는 우리가 아직 이의를 제기하지 않은 데이터의 성격에 관한 암묵적인 가정에 기초하고 있습니다. 메타 분석을 수행할 때 우리는 수집한 데이터가 포괄적이거나 적어도 조사 중인 연구 분야를 대표한다는 점을 전제로 합니다.

1.4.3장에서 우리는 메타 분석이 일반적으로 연구 분야를 적절하게 설명하는 단일 효과 크기를 도출하기 위해 사용 가능한 모든 증거를 포함하려고 시도한다고 언급했습니다. 통계적 관점에서 우리는 분석에서 몇 가지 연구가 누락된 것을 용인할 수 있습니다. 그러나 이러한 연구가 우연히 "제외"된 경우에만 가능합니다.

불행하게도 메타 분석은 기존의 모든 증거를 포함할 수 없는 경우가 많습니다. 설상가상으로, 수집된 데이터에서 일부 연구가 "무작위로" 완전히 누락되지 않았다고 가정할 만한 타당한 이유도 있습니다. 우리의 세계는 불완전하며 과학적 실천을 지배하는 인센티브와 "규칙"도 불완전합니다. 이는 연구가 우리의 메타 분석에 포함되는지 여부를 결정할 수 있는 체계적 편향이 있음을 의미합니다.

이 문제의 좋은 예는 최근의 약물요법 연구 일화에서 찾을 수 있습니다. 1990년대만 해도 우울증 환자 치료에 항우울제(선택적 세로토닌 재흡수 억제제(SSRI) 등)가 효과적이라는 사실은 확보된 지식으로 여겨졌다. 이 증거의 대부분은 항우울제를 알약 위약과 비교하는 발표된 약물요법 시험의 메타 분석에서 제공되었습니다. 항우울제 시장이 수십억 달러에 달하고 꾸준히 성장하고 있다는 점을 고려할 때, 항우울제의 효과에 관한 질문은 중요한 문제입니다.

이는 Irving Kirsch와 동료들이 쓴 The Emperor's New Drugs(2002)라는 기사에서 야기된 혼란을 이해하는 데 도움이 될 수 있습니다. 이 기사에서는 상황이 결국 그렇게 밝아 보이지 않을 수 있다고 주장했습니다.


Kirsch와 동료들은 "정보자유법"에 근거하여 제약회사가 미국 식품의약국(FDA)에 제공한 이전에 발표되지 않은 항우울제 시험 데이터를 얻었습니다. 그들은 이 미공개 데이터도 고려했을 때 위약에 비해 항우울제의 이점이 기껏해야 미미하고 임상적으로 무시할 수 있는 수준이라는 사실을 발견했습니다. Kirsch와 동료들은 이는 기업들이 긍정적인 결과가 있는 연구만 발표하고 "실망스러운" 증거가 있는 연구는 보류되었기 때문이라고 주장했습니다(Kirsch 2010).

논쟁의 여지가 있는 논쟁이 이어졌고 Kirsch의 주장은 오늘날까지 논란의 여지가 남아 있습니다. 우리는 어느 한쪽을 선택하기 위해서가 아니라 누락된 연구가 메타분석 추론의 타당성에 미칠 수 있는 잠재적인 위협을 설명하기 위해 이 예를 선택했습니다. 메타분석 문헌에서 이러한 문제는 일반적으로 출판 편향이라는 용어로 요약됩니다.

출판 편향 문제는 메타 분석의 모든 결과가 그 기반이 되는 데이터만큼만 좋을 수 있다는 점을 강조합니다. 메타분석 기술은 현재 가지고 있는 데이터로만 작동할 수 있습니다. 따라서 수집된 데이터가 왜곡되면 아무리 최고의 통계 모델이라도 내재된 편향만 재현할 뿐입니다. 아마도 이 책의 시작 부분에서 "파일 서랍" 문제(1.3장 참조)에 대해 논의했던 이 근본적인 경고를 이미 다루었다는 것을 기억하실 것입니다. 실제로 "파일 서랍 문제"와 "출판 편향"이라는 용어는 종종 동의어로 사용됩니다.

메타 분석 결과에 대한 출판 편향 및 관련 문제의 결과는 엄청날 수 있습니다. 이는 우리가 치료의 효과를 과대평가하거나, 부정적인 부작용을 간과하거나, 실제로 유효하지 않은 이론에 대한 믿음을 강화하게 만들 수 있습니다.

따라서 이 장에서는 출판 편향이 우리의 연구 결과를 왜곡할 수 있는 다양한 형태와 형태에 대해 논의할 것입니다. 또한 메타 분석가로서 데이터의 출판 편향 위험을 조사하는 데 사용할 수 있는 몇 가지 접근 방식을 살펴보겠습니다. 그리고 우선 출판 편견을 완화할 수 있는 방법을 알아보세요.


## 7.1. 출판 편향이란 무엇입니까?
출판 편향은 연구가 출판될 확률이 결과에 의해 영향을 받을 때 존재합니다(Rothstein, Sutton, Borenstein 2005, 2장 및 5장). 연구 결과가 통계적으로 유의하거나 초기 가설을 확증하는 경우 연구 결과가 대중에게 공개될 가능성이 더 높다는 증거가 널리 퍼져 있습니다(Schmucker et al. 2014; Scherer et al. 2018; Chan et al. 2014; Dechartres et al. 알. 2018).

적격한 연구를 검색할 때 일반적으로 동료 검토 기사, 사전 인쇄, 서적 또는 기타 접근 가능한 보고서를 통해 어떤 형태로든 공개된 증거로 제한됩니다. 출판 편향이 있는 경우 이는 데이터 세트에서 일부 연구가 누락되었음을 의미할 뿐만 아니라 누락된 연구가 바람직하지 않은 결과를 가지고 있을 가능성이 높다는 것을 의미합니다.

메타 분석 기술을 사용하면 모집단의 평균 효과 크기에 대한 편견 없는 추정치를 찾을 수 있습니다. 그러나 표본 자체가 왜곡되면 통계적 관점에서 '참'인 효과 추정이라도 현실을 대표하지 못할 것입니다. 이는 빙산의 크기를 추정하려고 하지만 그 끝 부분만 측정하는 것과 같습니다. 비록 우리가 수면 위의 높이를 완벽하게 정확하게 측정할 수 있다고 하더라도 우리의 결과는 필연적으로 틀릴 것입니다.

출판 편향은 실제로 많은 보고 편향 중 하나일 뿐입니다. 다음을 포함하여 메타 분석에서 얻은 증거를 왜곡할 수 있는 몇 가지 다른 요인도 있습니다(Page et al. 2020).

* 인용 편향: 출판되더라도 부정적이거나 결론이 나지 않는 연구 결과는 관련 문헌에서 인용될 가능성이 적습니다. 예를 들어, 이로 인해 참조 검색을 통해 검색하기가 더 어려워집니다.

* 시차 편향: 긍정적인 결과가 나온 연구는 불리한 결과가 나온 연구보다 일찍 발표되는 경우가 많습니다. 이는 최근에 수행된 연구에서 긍정적인 결과가 나온 경우가 종종 있지만, 중요하지 않은 결과가 나온 경우는 그렇지 않은 경우가 많다는 것을 의미합니다.

* 다중 출판 편향: “성공적인” 연구의 결과는 여러 저널 기사에 보고될 가능성이 높으며, 이로 인해 적어도 하나의 기사를 더 쉽게 찾을 수 있습니다. 여러 기사에 걸쳐 연구 결과를 보고하는 관행을 '살라미 슬라이싱'이라고도 합니다.

* 언어 편향: 대부분의 분야에서 증거가 출판되는 주요 언어는 영어입니다. 다른 언어로 된 출판물은 검색될 가능성이 적습니다. 특히 연구자가 번역 없이는 내용을 이해할 수 없는 경우에는 더욱 그렇습니다. 영어로 된 연구가 다른 언어로 출판된 연구와 체계적으로 다른 경우 편견이 발생할 수도 있습니다.

* 결과 보고 편향: 많은 연구, 특히 임상 시험에서는 관심 있는 결과를 두 개 이상 측정합니다. 일부 연구자들은 이를 활용하여 긍정적인 결과를 얻은 결과만 보고하고, 가설을 확인하지 못한 결과는 삭제합니다. 이것은 또한 편견으로 이어질 수 있습니다. 기술적으로 말하면 연구가 발표되었지만 그 (바람직하지 않은) 결과는 보고되지 않았기 때문에 메타 분석에서 여전히 누락될 것입니다.

비보고 편향은 기존 증거를 찾는 것을 더 어렵게 만드는 체계적 요인으로 볼 수 있습니다. 그러나 관련 조사 결과를 모두 포함하더라도 결과에는 여전히 결함이 있을 수 있습니다. 연구자들이 연구 결과를 분석하고 보고할 때 적용한 의심스러운 연구 관행(QRP)으로 인해 편견이 존재할 수도 있습니다(Simonsohn, Simmons, Nelson 2020).

우리는 이미 “연구자 자유도”라는 개념을 이전에 언급했습니다(1.3장). QRP는 연구자들이 이러한 자유도를 남용하여 결과를 원하는 방향으로 "구부리는" 관행으로 정의할 수 있습니다. 불행하게도 QRP를 구성하는 요소에 대한 명확한 합의가 이루어지지 않았습니다. 그러나 일반적으로 제안되는 몇 가지 예가 있습니다.

가장 눈에 띄는 QRP 중 하나는 p-해킹(p-hacking)으로, 기존의 유의성 임계값인 p< 0.05에 도달할 때까지 분석을 조정합니다. 여기에는 이상값 제거 방법, 하위 그룹 분석 또는 누락된 데이터 처리가 포함될 수 있습니다.

또 다른 QRP는 HARKing(Kerr 1998)으로, 결과가 알려진 후 가설을 세우는 것을 의미합니다. HARKing의 한 가지 방법은 탐색적 분석의 결과가 연구의 선험적 가설이었다고 가정하는 것입니다. 예를 들어, 연구자는 데이터 세트에 대해 다양한 테스트를 실행한 다음 중요한 모든 테스트에 대한 가설을 "발명"할 수 있습니다. 이는 연구의 잘못된 발견 비율을 부풀려 허위 발견의 위험을 증가시키는 심각한 결함이 있는 접근 방식입니다(몇 가지 문제를 예로 들면). HARKing의 또 다른 유형은 데이터가 뒷받침하지 않는 모든 가설을 삭제하는 것인데, 이는 궁극적으로 결과 보고 편향으로 이어질 수 있습니다.


## 7.2. 메타 분석에서 출판 편향 해결

출판 편향, 기타 보고 편향 및 QRP가 메타 분석의 타당성에 강력하고 해로운 영향을 미칠 수 있다는 것은 매우 분명합니다. 일반적으로 편향의 정확한 크기를 아는 것이 사실상 불가능하거나 편향이 존재하는지 여부를 아는 것이 사실상 불가능하기 때문에 이는 큰 문제가 됩니다.

메타 분석에서는 QRP뿐만 아니라 출판 및 보고 편견으로 인한 왜곡 위험을 어느 정도 줄일 수 있는 기술을 적용할 수 있습니다. 이러한 접근 방식 중 일부는 연구 검색과 관련이 있고 다른 접근 방식은 통계적 방법입니다.

### 소규모 연구 효과 방법
메타 분석에서 출판 편향을 평가하고 수정하는 다양한 소규모 연구 효과 방법이 있습니다. 많은 기술은 수년 동안 전통적이었습니다. 이름에서 알 수 있듯이 이러한 접근 방식은 특히 소규모 연구와 관련이 있습니다. 통계적 관점에서 이는 표준 오류가 높은 연구로 해석됩니다. 소규모 연구 효과 방법은 소규모 연구가 출판 편향에 빠질 가능성이 더 높다고 가정합니다.

이 가정은 세 가지 핵심 아이디어를 기반으로 합니다(Borenstein et al. 2011, 30장 참조).

* 자원과 시간이 많이 소요되기 때문에 결과의 유의성 여부에 관계없이 대규모 연구가 발표될 가능성이 높습니다.

* 중간 규모의 연구는 출판되지 않을 위험이 더 큽니다. 그러나 통계적 검정력이 중간 정도인 경우에도 이는 여전히 중요한 결과를 생성하는 데 충분합니다. 이는 "바람직하지 않은"(즉, 중요하지 않은) 결과를 제공했기 때문에 일부 연구만 출판되지 않음을 의미합니다.

* 소규모 연구는 중요하지 않은 결과를 생성하여 "파일 서랍"에 남을 위험이 가장 큽니다. 소규모 연구에서는 매우 큰 효과만 유의미하게 나타납니다. 이는 효과 크기가 매우 높은 소규모 연구만 출판될 것임을 의미합니다.

우리는 이러한 가정 뒤에 있는 것으로 알려진 메커니즘이 매우 간단하다는 것을 알 수 있습니다. 본질적으로 중요한 효과만 출판되기 때문에 출판 편향이 존재한다고 말합니다. 표본 크기가 클수록 유의미한 결과를 얻을 확률이 높아지므로 출판 편향이 소규모 연구에 불균형적으로 영향을 미칠 것입니다.



### the Funnel Plot
이 가이드 앞부분(3.1장)에서 우리는 연구의 표본 크기와 표준 오류가 밀접하게 관련되어 있다는 것을 배웠습니다. 효과 크기의 표준 오차가 클수록 신뢰 구간이 넓어지고 효과가 통계적으로 유의하지 않을 확률이 높아집니다. 따라서 작은 연구 효과가 표준 오차가 큰 연구에 크게 영향을 미칠 것이라고 가정하는 것이 합리적입니다.

우리가 수집한 데이터가 출판 편향으로 인해 부담을 받고 있다고 가정해 보겠습니다. 이 경우, 표준오차가 큰 연구는 표준오차가 낮은 연구보다 효과크기가 더 크다고 가정할 수 있습니다. 이는 효과가 낮은 소규모 연구는 중요하지 않아 출판을 고려하지 않았기 때문입니다. 결과적으로 우리는 이를 메타 분석에 포함하지 않았습니다.

깔대기형 플롯을 통해 소규모 연구 효과를 검사하는 것이 일반적입니다. 깔때기 도표는 연구의 관찰된 효과 크기를 y축의 표준 오차 측정값에 대해 x축으로 표시한 산점도입니다. 일반적으로 깔대기 도표의 y축은 반전됩니다. 즉, y축의 "높은" 값은 낮은 표준 오차를 나타냅니다.

출판 편향이 없는 경우 이러한 플롯의 데이터 포인트는 대략 대칭적이고 거꾸로 된 깔때기를 형성해야 합니다. 이것이 깔때기 도표라고 불리는 이유입니다. 플롯의 상단 부분에 있는 연구(표준 오류가 낮은 연구)는 서로 밀접하게 놓여 있어야 하며 합동 효과 크기에서 멀지 않아야 합니다. 그림의 아래쪽 부분에서는 표준 오류가 증가함에 따라 깔때기가 "열리며" 효과 크기가 합동 효과의 왼쪽과 오른쪽으로 더 많이 분산될 것으로 예상됩니다.

3.1장에서 효과 크기의 행동에 대해 배운 내용을 되돌아보고 4.1.1장(그림 4.1)에서 고정 효과 모델을 논의하면 연구가 깔때기를 형성해야 하는 이유를 더 쉽게 알 수 있습니다. 표준 오차는 연구의 정확성을 나타냅니다. 표준 오차가 감소함에 따라 관찰된 효과 크기가 실제 효과 크기에 대한 점점 더 좋은 추정치가 될 것으로 기대합니다. 표준 오차가 높으면 효과 크기의 정밀도가 낮으므로 모집단의 실제 효과와 멀리 떨어져 있을 가능성이 훨씬 더 높습니다.

이제 우리는 깔때기 도표를 직접 생성하여 이를 더욱 구체적으로 만들 것입니다. {meta} 패키지에서 funnel.meta 함수를 사용하여 메타 분석 개체에 대한 깔때기 도표를 인쇄할 수 있습니다. 여기에서는 m.gen 메타 분석 개체에 대한 깔때기 플롯을 생성합니다. xlim과 Studlab이라는 두 가지 추가 인수를 지정합니다. 첫 번째는 플롯의 x축 한계를 제어하는 반면, 후자는 연구 레이블을 포함하도록 함수에 지시합니다. 퍼널을 실행한 후 제목 함수를 호출하면 플롯에 제목이 추가됩니다.

우리의 코드는 다음과 같습니다:

```{r}
# Load 'meta' package
library(meta)

# Produce funnel plot
funnel(m.gen,
            xlim = c(-0.5, 2),
            studlab = TRUE)

# Add title
title("Funnel Plot (Third Wave Psychotherapies)")
```


논의된 바와 같이, 결과 깔때기 플롯은 x축에 각 연구의 효과 크기(표준화된 평균 차이로 표현됨)를 표시하고 y축에 표준 오차(큰 것부터 작은 것까지)를 표시합니다. 해석을 용이하게 하기 위해 플롯에는 연구에서 따를 것으로 예상되는 이상적인 깔때기 모양도 포함됩니다. 깔때기 중앙의 수직선은 평균 효과 크기를 나타냅니다. m.gen을 생성할 때 무작위 효과 모델을 사용했기 때문에 깔대기 플롯에서도 무작위 효과 추정값을 사용합니다.

소규모 연구 효과가 없는 경우, 우리의 연구는 플롯에 표시된 깔때기로 묘사된 모양을 대략 따라야 합니다. 우리의 예에서도 그러합니까? 글쎄,별로. 표준 오차가 낮은 연구는 추정된 실제 효과에 더 집중되어 있지만 패턴 전체는 비대칭으로 보입니다. 이는 도표의 오른쪽 하단에 효과 크기가 매우 높은 세 개의 소규모 연구(Shapiro, Kang 및 Danitz-Orsillo의 연구)가 있기 때문입니다.

그러나 이러한 연구는 플롯의 왼쪽 하단 모서리에 해당 항목이 없습니다. 효과가 매우 높은 연구의 균형을 맞추기 위해 효과 크기가 매우 낮거나 부정적인 소규모 연구는 없습니다. 또 다른 걱정스러운 세부 사항은 우리 샘플에서 가장 정밀한 연구인 de Vibe의 연구도 퍼널 패턴을 잘 따르지 않는 것 같다는 것입니다. 그 효과 크기는 예상보다 상당히 작습니다.

전반적으로 데이터 세트는 퍼널 플롯에서 출판 편향을 나타낼 수 있는 비대칭 패턴을 보여줍니다. 세 가지 작은 연구는 유의미해질 만큼 높은 효과를 발견한 운이 좋았을 수 있으며, 비슷한 표준 오류가 있지만 크기가 작아서 중요하지 않은 효과가 있어 컷에 포함되지 않은 미발표 연구도 있습니다. .

비대칭 패턴이 통계적 유의성과 어떻게 관련되는지 조사하는 좋은 방법은 윤곽이 강화된 깔때기 도표를 생성하는 것입니다(Peters et al. 2008). 이러한 도표는 출판 편향을 다른 형태의 비대칭과 구별하는 데 도움이 될 수 있습니다. 등고선 강화 깔때기 도표에는 도표에 있는 각 연구의 유의 수준을 나타내는 색상이 포함됩니다. funnel.meta 함수에서 윤곽선 인수에 원하는 유의성 임계값을 제공하여 윤곽선을 추가할 수 있습니다. 일반적으로 이는 0.9, 0.95 및 0.99입니다.
p <0.1, 0.05 및 0.01. col.contour 인수를 사용하면 윤곽선의 색상을 지정할 수도 있습니다. 마지막으로, 나중에 범례 기능을 사용하여 플롯에 범례를 추가하고 다양한 색상의 의미를 지정할 수 있습니다. x 및 y 인수를 사용하여 플롯에 범례를 배치하고, 범례에 레이블을 제공하고, fill 인수를 사용하여 채우기 색상을 추가할 수 있습니다.

그 결과 다음 코드가 생성됩니다.

```{r}
# Define fill colors for contour
col.contour = c("gray75", "gray85", "gray95")

# Generate funnel plot (we do not include study labels here)
funnel(m.gen, xlim = c(-0.5, 2),
            contour = c(0.9, 0.95, 0.99),
            col.contour = col.contour)

# Add a legend
legend(x = 1.6, y = 0.01, 
       legend = c("p < 0.1", "p < 0.05", "p < 0.01"),
       fill = col.contour)

# Add a title
title("Contour-Enhanced Funnel Plot (Third Wave Psychotherapies)")
```
이제 깔대기 플롯에 세 개의 음영 영역이 포함되어 있는 것을 볼 수 있습니다. 우리는 p< 0.05 및 p< 0.01 영역에 특히 관심이 있습니다. 왜냐하면 이 영역에 속하는 효과 크기가 전통적으로 중요한 것으로 간주되기 때문입니다.

등고선 영역을 추가하면 빛을 발하게 됩니다. 이는 표준 오차가 크더라도 세 가지 소규모 연구 모두 중요한 효과가 있음을 보여줍니다. 유의미하지 않은 유사한 표준 오류가 있는 연구는 단 하나뿐입니다. 대칭성을 높이기 위해 플롯의 왼쪽 하단 모서리에 누락된 연구를 "대체"한다면 이러한 연구는 플롯의 중요하지 않은 영역에 놓이게 됩니다. 그렇지 않으면 실제로 상당한 부정적인 영향을 미칠 수 있습니다.

더 큰 연구에서는 패턴이 약간 다르게 보입니다. p> 0.05이고 효과 분포가 덜 편향된 여러 연구가 있음을 알 수 있습니다. 하지만 문제가 될 수 있는 점은 엄격히 유의하지는 않지만 하나의 연구를 제외한 모든 연구가 유의성 임계값에 매우 가깝다는 것입니다(즉, 0.1 >p> 0.05 영역에 있음). 이들 연구는 단순히 원 논문에서 효과크기를 다르게 계산하여 유의미한 결과를 얻었을 가능성이 있다. 아니면 추세 수준에서 중요한 효과를 발견한 것이 이미 연구 결과를 발표할 만큼 충분히 설득력이 있었을 수도 있습니다.

요약하면, 윤곽이 강화된 깔대기 도표를 검사하면 깔때기 도표에 비대칭성이 있고 이는 출판 편향으로 인해 발생할 수 있다는 초기 예감을 확증합니다. 그러나 성급하게 결론을 내리지 말고 깔때기 도표를 조심스럽게 해석하는 것이 중요합니다. 출판 편향은 유입경로 비대칭의 여러 가지 이유 중 하나일 뿐이라는 점을 명심해야 합니다.
### 깔때기 도표 비대칭에 대한 대체 설명

출판 편향이 비대칭 깔때기 도표로 이어질 수 있지만 비슷한 패턴을 생성할 수 있는 "양성"이라기보다는 다른 원인도 있습니다(Page et al. 2020).

* 비대칭성은 연구 간 이질성으로 인해 발생할 수도 있습니다. 깔때기 도표는 효과 크기의 분산이 연구의 샘플링 오류로 인해 발생한다고 가정하지만 연구가 서로 다른 실제 효과의 추정자가 될 수 있다는 사실을 통제하지는 않습니다.

* 소규모 연구에서는 연구 절차가 달랐을 가능성이 있으며, 이로 인해 더 높은 효과가 나타날 수 있습니다. 예를 들어, 임상 연구에서는 표본 크기가 작을 때 모든 참가자가 의도한 대로 치료를 받는지 확인하는 것이 더 쉽습니다. 대규모 연구에서는 그렇지 않을 수 있으며, 이로 인해 치료 충실도가 낮아지고 결과적으로 효과도 낮아집니다. 그러한 대안적 설명이 타당한지 평가하기 위해 포함된 연구의 특성을 조사하는 것이 합리적일 수 있습니다.

* 품질이 낮은 연구에서는 비뚤림 위험이 높기 때문에 효과 크기가 더 큰 경향이 있다는 것이 일반적인 발견입니다. 대규모 연구에는 더 많은 투자가 필요하므로 방법론도 더욱 엄격해질 가능성이 높습니다. 이는 출판 편향이 없더라도 깔때기 도표 비대칭으로 이어질 수도 있습니다.

* 마지막으로, 깔때기 도표 비대칭이 단순히 우연히 발생할 가능성이 있습니다.

우리는 (윤곽 강화) 깔때기 플롯을 육안으로 검사하면 결과가 출판 편견의 영향을 받을 수 있음을 나타내는 몇 가지 "위험 신호"를 이미 제공할 수 있음을 알 수 있습니다.

그러나 Funnel Plot을 명확하게 보는 것만으로는 해석하는 데에도 한계가 있습니다. 결과가 "너무 비대칭"인 경우 명시적인 규칙이 없습니다. 즉, 깔때기 도표의 추론이 항상 어느 정도 주관적이라는 의미입니다. 따라서 깔대기형 플롯의 비대칭 여부를 정량적으로 평가하는 것이 도움이 됩니다. 이는 일반적으로 다음에 논의할 Egger의 회귀 테스트를 통해 달성됩니다.


### Egger의 회귀 테스트
Egger의 회귀 테스트(Egger et al. 1997)는 깔때기 플롯의 비대칭성을 테스트하는 데 일반적으로 사용되는 정량적 방법입니다. 깔대기 플롯의 육안 검사와 마찬가지로 소규모 연구 효과만 식별할 수 있으며 출판 편향이 존재하는지 직접적으로 알 수는 없습니다. 이 테스트는 간단한 선형 회귀 모델을 기반으로 하며 그 공식은 다음과 같습니다.

$$\begin{equation}
\frac{\hat\theta_k}{SE_{\hat\theta_k}} = \beta_0 + \beta_1 \frac{1}{SE_{\hat\theta_k}}
\tag{9.1}
\end{equation}$$

이 공식의 응답 y는 메타 분석에서 관찰된 효과 크기 $\hat\theta_k$를 표준 오류로 나눈 것입니다. 결과 값은 z-점수와 동일합니다. 이 점수는 효과 크기가 중요한지 직접적으로 알려줍니다. z> 1.96 또는 < -1.96이면 효과가 유의미하다는 것을 알 수 있습니다(p< 0.05). 이 반응은 연구의 표준 오류의 역수로 회귀되며 이는 정밀도와 동일합니다.

그러나 Egger 테스트를 사용할 때 우리는 회귀 가중치 $\beta_1$의 크기와 유의성이 아니라 절편에 관심이 있습니다. 깔대기 비대칭성을 평가하기 위해 $\hat\beta_0$의 크기를 검사하고 0과 크게 다른지 여부를 검사합니다. 이 경우 Egger의 테스트는 깔때기 플롯 비대칭성을 나타냅니다.

회귀 절편의 크기가 깔때기 도표의 비대칭성에 대해 알려주는 이유를 잠시 살펴보겠습니다. 모든 선형 회귀 모델에서 절편은 다른 모든 예측 변수가 0일 때 y 값을 나타냅니다. 모델의 예측 변수는 연구의 정밀도이므로 절편은 정밀도가 0일 때(즉, 연구의 표준 오차가 무한히 큰 경우) 예상되는 z-점수를 표시합니다.

출판 편향이 없으면 예상되는 z-점수는 0 주위에 분산되어야 합니다. 이는 표준 오차가 매우 큰 연구의 경우 신뢰 구간이 매우 커서 |z| 값에 도달하는 것이 거의 불가능하기 때문입니다. > 1.96. 그러나 예를 들어 출판 편향으로 인해 퍼널 플롯이 비대칭인 경우 효과 크기가 매우 높은 소규모 연구가 데이터에서 상당히 과도하게 표현되어 놀라울 정도로 높은 정밀도의 낮은 연구로 이어질 것으로 예상됩니다.
z 값은 1.96보다 크거나 같습니다. 이러한 왜곡으로 인해 정밀도가 0인 경우 예측된 y 값은 0보다 훨씬 커져 중요한 절편이 생성됩니다.

아래 플롯은 깔때기 플롯 비대칭이 회귀 기울기에 미치는 영향과 기본 Egger 테스트의 절편을 보여줍니다.

![Fig16](fig12.png)
![Fig17](fig13.png)

![Fig18](fig14.png)


![Fig19](fig15.png)

이러한 회귀 모델을 m.gen의 데이터에 적용하면 어떤 결과를 얻을 수 있는지 살펴보겠습니다. R을 사용하면 m.gen의 원본 데이터를 추출하여 응답 y와 예측 변수 x를 계산할 수 있습니다. 아래 코드에서는 파이프(2.5.3장)와 {tidyverse}의 일부인 mutate 함수를 사용하여 이 작업을 수행합니다. 그런 다음 선형 모델 함수 lm을 사용하여 정밀도 x에 대한 z 점수 y를 회귀합니다. 파이프의 마지막 부분에서는 결과 요약을 요청합니다.

```{r}
# Load required package
library(tidyverse)

m.gen$data %>% 
  mutate(y = TE/seTE, x = 1/seTE) %>% 
  lm(y ~ x, data = .) %>% 
  summary()
```
결과에서 회귀 모델의 절편은 $\hat\beta_0$ = 4.11임을 알 수 있습니다. 이는 0보다 훨씬 크며(t = 4.677, p< 0.001) 깔때기 도표의 데이터가 실제로 비대칭임을 나타냅니다. 전반적으로 이는 소규모 연구 효과가 있다는 초기 연구 결과를 확증합니다. 그러나 다시 한번 말씀드리지만 이러한 패턴이 출판 편향으로 인해 발생한 것인지는 확실하지 않습니다.

Egger의 절편 테스트를 수행하는 더 편리한 방법은 {meta}의 Metabias 기능을 사용하는 것입니다. 이 함수에는 입력으로 메타 분석 개체만 필요하며 method.bias 인수를 "linreg"로 설정해야 합니다. m.gen에 이 함수를 적용하면 이전과 같은 결과를 얻을 수 있습니다.

```{r}
metabias(m.gen, method.bias = "linreg")
```

### Reporting the Results of Egger’s Test

Egger 테스트의 경우 일반적으로 절편 값, 95% 신뢰 구간, t 및 p 값을 보고하는 것으로 충분합니다. {dmetar} 패키지에는 eggers.test라는 편의 함수가 포함되어 있습니다. 이 함수는 Metabias에 대한 래퍼이며 Egger의 테스트 결과를 보고에 적합한 형식으로 제공합니다. {dmetar}가 설치되어 있지 않은 경우 온라인에서 함수의 소스 코드를 찾을 수 있습니다. 예는 다음과 같습니다.



## 7.3. 요약
* 출판 편향은 출판된 문헌, 즉 우리의 메타 분석에서 일부 연구가 체계적으로 누락되었을 때 발생합니다. 엄밀히 정의하면, 출판 편향은 연구가 출판될 확률이 결과에 따라 달라질 때 존재합니다. 그러나 다양한 보고 편향도 있습니다. 이러한 보고 편향은 메타 분석에서 결과가 나올 가능성에도 영향을 미칩니다. 예로는 인용 편향, 언어 편향, 결과 보고 편향 등이 있습니다.

* 예를 들어 의심스러운 연구 관행(QRP)으로 인해 출판된 증거가 편향될 수도 있습니다. 두 가지 일반적인 QRP는 p-hacking과 HARKing이며 둘 다 메타 분석에서 효과를 과대평가할 위험을 증가시킬 수 있습니다.

* 많은 출판 편향 방법은 소규모 연구 효과에 기초하고 있습니다. 이러한 접근법은 놀라울 정도로 높은 효과 크기를 지닌 소규모 연구만이 유의미한 결과를 얻었고 따라서 출판을 위해 선택되었다고 가정합니다. 이로 인해 비대칭 깔때기 모양이 나타나며 이는 출판 편향의 징후일 수 있습니다. 그러나 반드시 그럴 필요는 없습니다. 소규모 연구 효과의 다양한 "양성" 원인도 가능합니다.

* 상대적으로 새로운 방법인 p-곡선은 데이터에서 유의미한(p< 0.05) 효과의 패턴을 보는 것만으로 증거 가치를 제어할 수 있다는 아이디어에 기반합니다. 이는 실제 효과의 유무를 테스트하는 데 사용할 수 있으며 그 크기를 추정할 수 있습니다.

* 선택 모델은 매우 다양한 방법이며 다양한 출판 편향 프로세스를 모델링하는 데 사용할 수 있습니다. 그러나 가정된 모델이 적절할 때만 유효한 결과를 제공하며 종종 매우 많은 수의 연구가 필요합니다. 매우 간단한 선택 모델인 3개 매개변수 모델은 더 작은 데이터 세트에도 사용할 수 있습니다.

* 출판 편향 방법은 다른 모든 방법보다 지속적으로 우수한 성능을 발휘하지 않습니다. 따라서 항상 여러 가지 기법을 적용하고 수정된 효과 크기를 주의 깊게 해석하는 것이 좋습니다. 미발표 증거에 대한 철저한 검색은 현재 통계 접근 방식보다 훨씬 더 나은 방법으로 출판 편견의 위험을 완화합니다.




# 8. 연속형 변수 메타 분석 예제

## 8.1. 연속형 변수 Example of Meta Analysis in R
메타 라이브러리를 사용하여 R에서 메타 분석의 예를 제공합니다.

```{r}
library(meta)
data("Fleiss1993cont")

head(Fleiss1993cont)
```

우리는 다음과 같은 Fleiss1993cont 데이터 세트를 사용하여 작업할 것입니다.

* 정신 건강 치료가 의료 활용에 미치는 영향에 대한 메타 분석.

* 지속적인 결과를 제공하는 메타 분석을 위한 Fleiss(1993)의 데이터 예.

* Fleiss JL(1993): 메타분석의 통계적 기초. 의학 연구의 통계적 방법, 2, 121-45

* study: 연구 라벨

* year : 출판 연도

* n.psyc: 심리치료 그룹의 관찰 수

* mean.psyc: 심리치료 그룹의 추정 평균

* sd.psyc: 심리치료군의 표준편차

* n.cont: 대조군의 관측치 수

* mean.cont: 대조군의 추정 평균

* sd.cont: 대조군의 표준편차

### 메타분석 결과
```{r}
# meta-analysis with continuout outcome
# comb.fixed/comb.random: indicator whether a fix/random effect mata-analysis to be conducted.
# sm: Three different types of summary measures to choose,standardized mean difference (SMD),mean difference (MD), ratio of means (ROM)
res.flesiss =  metacont(n.psyc, mean.psyc, sd.psyc, 
                        n.cont, mean.cont, sd.cont,
                        comb.fixed = T, comb.random = T, studlab = study,
                        data = Fleiss1993cont, sm = "SMD") 
res.flesiss
```
### forest
```{r}
forest(res.flesiss, leftcols = c('studlab'))
```

메타 분석의 통합 결과에 따르면 고정 효과 모델과 무작위 효과 모델 모두 대조군에 비해 중재 그룹의 상당한 이점을 제공합니다(입원 기간이 낮을수록 좋음). Cochran의 Q 테스트에 대한 p-값은 0.45로, 이질성이 없음을 나타냅니다.

### Funnel Plot
```{r}

funnel(res.flesiss)
```

* 메타바이어스(metabias): 순위 상관관계 또는 선형 회귀 방법을 기반으로 깔때기 도표 비대칭성을 테스트합니다.
* 출판 편향을 확인하려면 Egger 테스트를 사용하세요. 문자열 'Egger' 또는 'linreg'를 사용할 수 있습니다.


```{r}
metabias(res.flesiss, method.bias = 'linreg', k.min = 5, plotit = T)
```
p-값은 0.973으로 출판 편향이 없음을 의미합니다. 그러나 이 메타 분석에는 k=5개의 연구가 포함되어 있습니다. Egger의 검정은 연구 수가 적을 때(즉, k<10) 편견을 탐지하는 통계적 검정력이 부족할 수 있습니다.


## 8.2.연속형 변수: 다른 케이스

이 절에서 사용하는 자료는 패키지 metafor 에 주어진 Raudenbush (2009) 에 제시된 자료이다. 아래의 코드는 패키지는 metafor 의 홈페이지에 실린 것을 그대로 사용하였다.

자료는 Raudenbush and Bryk (1985) 에서 이용한 19 개의 연구에 보고된 자료이며 연구 목적은 교사들의 관심이 학생들의 IQ 수준에 영향을 미치는 정도를 알아보는 것이다. 아 자료에서는 효과의 크기와 분산이 미리 계산되어 있다.

### 자료
먼저 패키지는 metafor 를 부른다.


```{r}
library(metafor)
```

분석에 이용할 자료 dat 를 생성한다.

자료 dat에서 중요한 변수는 다음과 같다.

yi: 효과 크기의 추정치 (θ^i)
vi: 효과 크기에 대한 추정치의 분산 (v^2i)


```{r}
library(kableExtra)
dat <- dat.raudenbush1985
knitr::kable(dat, booktabs = TRUE, row.names = FALSE, caption = "Raudenbush (2009) data") %>% 
    kable_styling(bootstrap_options = "striped", full_width = T)
```


데이터 프레임에는 다음 열이 포함되어 있습니다.

* study	numeric	study number

* author: 인성 연구 저자(들)

* year: 숫자로 출판된 연도

* weaks: 기대 유도 이전의 접촉 주 수

* setting: 테스트가 그룹으로 진행되는지 개별적으로 진행되는지 여부에 대한 문자

* tester: 테스트 관리자가 인식했는지, 맹인인지 여부를 나타내는 문자

* n1i : 실험군의 수치적 표본크기

* n2i: 대조군의 수치적 표본 크기

* yi: 수치 표준화 평균 차이

* vi: 수치 대응 샘플링 분산



### 고정효과 모형
고정효과 모형을 이용한 메타분석은 함수 rma를 이용하며 옵션으로 method="FE"를 지정한다.

```{r}
res.FE <- rma(yi, vi, data = dat, digits = 3, method = "FE")
res.FE
```

고정효과 모형을 적용한 결과는 다음과 같다.

* $\hat\theta$=0.060
* se($\hat\theta$)=0.036
* $\hat\theta$에 대한 95% 신뢰구간: (−0.011,0.132)
* 가설검정 H0:$\hat\theta$=0에 대한 p-값 = 0.098
* $Q^2$=35.830


### 임의효과 모형
임의효과 모형을 이용한 메타분석은 함수 rma를 이용하며 옵션을 지정하지 않으면 디폴트(default)로 임의효과 모형을 적용한다.



```{r}
res.RE <- rma(yi, vi, data = dat, digits = 3)
res.RE
```

임의효과 모형을 적용한 결과는 다음과 같다.

* $\hat\theta$=0.084
* se($\hat\theta$)=0.052
* $\theta$에 대한 95% 신뢰구간: (−0.018,0.185)
* 가설검정 H0:$\theta$=0에 대한 p-값 = 0.105
* $Q$=35.830
* $tau^2$=0.019
* $I^2$=41.86%
* $H^2$=1.72

### 2.4 집단간의 변동을 추정하는 여러 가지 방법

집단간의 변동 $\tau^2$를 추정하는 방법은 다음과 같이 다양한 방법이 있다. 특별하게 지정하지 않으면 제한적인 최대가능도함수(Restriced Maximum Likelihood Estimation; REML)을 이용한다.

Code	Estimator
DL	DerSimonian-Laird
PM	Paule-Mandel
REML	Restricted Maximum-Likelihood
ML	Maximum-likelihood
HS	Hunter-Schmidt
SJ	Sidik-Jonkman
HE	Hedges
EB	Empirical Bayes

다음은 집단간의 변동 $\tau^2$를 추정할 때 Empirical Bayes를 이용한 예이다.


```{r}
rma(yi, vi, data = dat, digits = 3, method = "EB")
```


### 숲그림
숲그림(forest plot)은 메타분석시 서로 다른 연구들의 효과크기 추정값과 신뢰구간을 비교하기 쉽게 보여주는 그림이다. 아래는 함수 forest를 사용하여 숲그림을 그린 예이다. slab=paste(author, year, sep=", ")은 각 연구의 저자와 년도를 묶어서 연구를 구별해주라는 옵션이다.

```{r}
res <- rma(yi, vi, data = dat, digits = 3, slab = paste(author, year, sep = ", "))
forest(res)
```
### 깔때기 그림
깔때기 그림(funnel plot)은 연구의 효과크기와 그 표준편차의 산포도를 보여주는 그림이다. 수직선은 메타분석의 추정량($\hat\theta$=0.084)이며 삼각형의 두 변은 y축의 표준오차 값에 1.96을 곱한 크기를 죄우로 벌려준 값이다

($\hat\theta$−1.96se,$\hat\theta$+1.96se)
.

깔때기 밖에 있는 연구들은 일종의 편향(publication bias..etc)를 가진다고 예상할 수 있다.


```{r}
funnel(res)
```


## 8.3. 이항변수 메타분석


이항변수, 즉 반응의 결과가 두 개의 항목(성공/실패, 유병/무병 등)으로 결과가 나타나는 연구에서는 성공 비율의 비교가 주 목적이다. 비율의 비교는 다음과 같은 다양한 측도가 있다.

비율의 차이 (difference in proportions; RD)
$\theta$=pt−pc

상대위험 또는 로그 상대위험 (relative risk, risk ratio; RR )

$\theta$=pt/pc

오즈비 또는 로그 오즈비 ( odd ratio; OR)

$\theta$=pt(1−pc)pc(1−pt)

비율을 비교하는 연구의 결과는 다음과 같은 2x2 분할표(contingency table)로 요약이 가능하다.


### 자료
이용할 자료는 폐결핵(tuberculosis)의 예방을 위한 BCG 백신의 효과를 연구한 13 연구들의 결과이다 (Colditz et al. (1994)). 아래 나오는 R 프로그램은 패키지 metafor에 대한 설명 논문의 프로그램을 그대로 사용하였다 (Viechtbauer and Others (2010))

```{r}
data("dat.bcg", package = "metafor")
knitr::kable(dat.bcg, booktabs = TRUE, row.names = FALSE, caption = "BCG data") %>% kable_styling(bootstrap_options = "striped", 
    full_width = T)
```
The data frame contains the following columns:

trial	numeric	trial number
author	character	author(s)
year	numeric	publication year
tpos:	numeric	number of TB positive cases in the treated (vaccinated) group
tneg:	numeric	number of TB negative cases in the treated (vaccinated) group
cpos:	numeric	number of TB positive cases in the control (non-vaccinated) group
cneg:	numeric	number of TB negative cases in the control (non-vaccinated) group
ablat:	numeric	absolute latitude of the study location (in degrees)
alloc:	character	method of treatment allocation (random, alternate, or systematic assignment)


데이터 dat.bcg 에서 분할표에 대응하는 변수는 다음과 같다.
BCG data for 2 x 2 contingency table
Figure 3.2: BCG data for 2 x 2 contingency table

ai = tpos
bi = tneg
ci = cpos
di = cneg

### 효과의 크기와 분산 계산
함수 escal을 이용하면 효과의 크기와 분산을 계산할 수 있다. 아래 R 문장은 각 연구에 대하여 로그 상대위험(measure = "RR")와 그 분산을 계산하는 명령이다.

```{r}
dat1 <- escalc(measure = "RR", ai = tpos, bi = tneg, ci = cpos, di = cneg, data = dat.bcg, 
    append = TRUE)
```


###임의효과 모형

```{r}
res1.RE <- rma(yi, vi, data = dat1, digits = 3)
res1.RE
```

### 숲그림
```{r}
res1 <- rma(yi, vi, data = dat1, digits = 3, slab = paste(author, year, sep = ", "))
forest(res1)
```
### 깔때기 그림
```{r}
funnel(res1)
```

